{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import make_scorer\n",
    "import lightgbm as lgb\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.inspection import permutation_importance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_permutation_importance(perm_dict, X, title):\n",
    "    sorted_importances_idx = perm_dict[\"importances_mean\"].argsort()\n",
    "    importances = pd.DataFrame(\n",
    "        perm_dict[\"importances\"][sorted_importances_idx].T,\n",
    "        columns=X.columns[sorted_importances_idx],\n",
    "    )\n",
    "    ax = importances.plot.box(vert=False, whis=10)\n",
    "    ax.set_title(title)\n",
    "    ax.axvline(x=0, color=\"k\", linestyle=\"--\")\n",
    "    ax.set_xlabel(\"Decrease in accuracy score\")\n",
    "    ax.figure.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mape(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "\n",
    "# Create a scorer object using the custom MAPE function\n",
    "mape_scorer = make_scorer(mape, greater_is_better=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation\n",
    "In this notebook, we will be treating, scaling and overall preparing the data so that it can be trained on different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "housePrices = pd.read_csv(\"csv_files/housePricesTrain.csv\")\n",
    "housePrices = housePrices.drop(columns=[\"Id\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on previous analysis, we will be droping outlier values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "housePrices = housePrices[housePrices[\"SalePrice\"] <= 450000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reduced = housePrices.drop(columns=[\"SalePrice\"])\n",
    "y_train = housePrices[\"SalePrice\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reduced = X_reduced.fillna(\n",
    "    0\n",
    ")  # Substituiremos os valores NaN por '0', para que a ordem seja preservada\n",
    "# nas variáveis categóricas.\n",
    "\n",
    "# Dicionário\n",
    "mapping = {\n",
    "    \"Po\": 1,\n",
    "    \"Fa\": 2,\n",
    "    \"TA\": 3,\n",
    "    \"Gd\": 4,\n",
    "    \"Ex\": 5,\n",
    "    \"No\": 1,\n",
    "    \"Mn\": 2,\n",
    "    \"Av\": 3,\n",
    "    \"Unf\": 1,\n",
    "    \"LwQ\": 2,\n",
    "    \"Rec\": 3,\n",
    "    \"BLQ\": 4,\n",
    "    \"ALQ\": 5,\n",
    "    \"GLQ\": 6,\n",
    "    \"RFn\": 2,\n",
    "    \"Fin\": 3,\n",
    "}\n",
    "##\n",
    "#       Ex   Excellent          GLQ   Good Living Quarters         Fin\tFinished\n",
    "#       Gd   Good               ALQ   Average Living Quarters      RFn\tRough Finished\n",
    "#       TA   Average/Typical    Rec   Average Rec Room\n",
    "##       Fa   Fair               LwQ   Low Quality\n",
    "##       Po   Poor               Unf   Unfinished\n",
    "##\n",
    "##\n",
    "\n",
    "X_reduced = X_reduced.replace(mapping)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dummies = pd.get_dummies(X_reduced)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_dummies)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = SelectKBest(score_func=f_regression, k=20)\n",
    "\n",
    "\n",
    "selector.fit(X_dummies, y_train)\n",
    "selector.fit_transform(X_dummies, y_train)\n",
    "selected = selector.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_scores = dict(zip(X_dummies.columns[selected], selector.scores_))\n",
    "\n",
    "feature_scores_dict = pd.DataFrame.from_dict(\n",
    "    feature_scores, orient=\"index\"\n",
    ").sort_values(by=0, ascending=False)\n",
    "feature_scores_dict = feature_scores_dict.rename(columns={0: \"ANOVA score\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ANOVA score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MasVnrArea</th>\n",
       "      <td>2521.659557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1stFlrSF</th>\n",
       "      <td>1249.382006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FullBath</th>\n",
       "      <td>793.796820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neighborhood_NridgHt</th>\n",
       "      <td>777.413344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtQual</th>\n",
       "      <td>649.002390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <td>579.493863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Foundation_PConc</th>\n",
       "      <td>352.503614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HeatingQC</th>\n",
       "      <td>327.089819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FireplaceQu</th>\n",
       "      <td>212.744691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <td>199.798517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fireplaces</th>\n",
       "      <td>158.082762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <td>98.770175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KitchenQual</th>\n",
       "      <td>81.858646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageArea</th>\n",
       "      <td>69.247510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YearBuilt</th>\n",
       "      <td>49.295374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OverallQual</th>\n",
       "      <td>10.568441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExterQual</th>\n",
       "      <td>8.769422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GrLivArea</th>\n",
       "      <td>0.252517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageCars</th>\n",
       "      <td>0.153126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageFinish</th>\n",
       "      <td>0.098295</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      ANOVA score\n",
       "MasVnrArea            2521.659557\n",
       "1stFlrSF              1249.382006\n",
       "FullBath               793.796820\n",
       "Neighborhood_NridgHt   777.413344\n",
       "BsmtQual               649.002390\n",
       "TotalBsmtSF            579.493863\n",
       "Foundation_PConc       352.503614\n",
       "HeatingQC              327.089819\n",
       "FireplaceQu            212.744691\n",
       "TotRmsAbvGrd           199.798517\n",
       "Fireplaces             158.082762\n",
       "YearRemodAdd            98.770175\n",
       "KitchenQual             81.858646\n",
       "GarageArea              69.247510\n",
       "YearBuilt               49.295374\n",
       "OverallQual             10.568441\n",
       "ExterQual                8.769422\n",
       "GrLivArea                0.252517\n",
       "GarageCars               0.153126\n",
       "GarageFinish             0.098295"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_scores_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Kbest = X_dummies[X_dummies.columns[selected]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>ExterQual</th>\n",
       "      <th>BsmtQual</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>HeatingQC</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>FullBath</th>\n",
       "      <th>KitchenQual</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <th>Fireplaces</th>\n",
       "      <th>FireplaceQu</th>\n",
       "      <th>GarageFinish</th>\n",
       "      <th>GarageCars</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>Neighborhood_NridgHt</th>\n",
       "      <th>Foundation_PConc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>196.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>856</td>\n",
       "      <td>5</td>\n",
       "      <td>856</td>\n",
       "      <td>1710</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>548</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1262</td>\n",
       "      <td>5</td>\n",
       "      <td>1262</td>\n",
       "      <td>1262</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>460</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>162.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>920</td>\n",
       "      <td>5</td>\n",
       "      <td>920</td>\n",
       "      <td>1786</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>608</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>1915</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>756</td>\n",
       "      <td>4</td>\n",
       "      <td>961</td>\n",
       "      <td>1717</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>642</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>350.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1145</td>\n",
       "      <td>5</td>\n",
       "      <td>1145</td>\n",
       "      <td>2198</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>836</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>6</td>\n",
       "      <td>1999</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>953</td>\n",
       "      <td>5</td>\n",
       "      <td>953</td>\n",
       "      <td>1647</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>460</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>6</td>\n",
       "      <td>1978</td>\n",
       "      <td>1988</td>\n",
       "      <td>119.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1542</td>\n",
       "      <td>3</td>\n",
       "      <td>2073</td>\n",
       "      <td>2073</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>7</td>\n",
       "      <td>1941</td>\n",
       "      <td>2006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1152</td>\n",
       "      <td>5</td>\n",
       "      <td>1188</td>\n",
       "      <td>2340</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>252</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>5</td>\n",
       "      <td>1950</td>\n",
       "      <td>1996</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1078</td>\n",
       "      <td>4</td>\n",
       "      <td>1078</td>\n",
       "      <td>1078</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>240</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>5</td>\n",
       "      <td>1965</td>\n",
       "      <td>1965</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1256</td>\n",
       "      <td>4</td>\n",
       "      <td>1256</td>\n",
       "      <td>1256</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>276</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1446 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      OverallQual  YearBuilt  YearRemodAdd  MasVnrArea  ExterQual  BsmtQual  \\\n",
       "0               7       2003          2003       196.0          4         4   \n",
       "1               6       1976          1976         0.0          3         4   \n",
       "2               7       2001          2002       162.0          4         4   \n",
       "3               7       1915          1970         0.0          3         3   \n",
       "4               8       2000          2000       350.0          4         4   \n",
       "...           ...        ...           ...         ...        ...       ...   \n",
       "1455            6       1999          2000         0.0          3         4   \n",
       "1456            6       1978          1988       119.0          3         4   \n",
       "1457            7       1941          2006         0.0          5         3   \n",
       "1458            5       1950          1996         0.0          3         3   \n",
       "1459            5       1965          1965         0.0          4         3   \n",
       "\n",
       "      TotalBsmtSF  HeatingQC  1stFlrSF  GrLivArea  FullBath  KitchenQual  \\\n",
       "0             856          5       856       1710         2            4   \n",
       "1            1262          5      1262       1262         2            3   \n",
       "2             920          5       920       1786         2            4   \n",
       "3             756          4       961       1717         1            4   \n",
       "4            1145          5      1145       2198         2            4   \n",
       "...           ...        ...       ...        ...       ...          ...   \n",
       "1455          953          5       953       1647         2            3   \n",
       "1456         1542          3      2073       2073         2            3   \n",
       "1457         1152          5      1188       2340         2            4   \n",
       "1458         1078          4      1078       1078         1            4   \n",
       "1459         1256          4      1256       1256         1            3   \n",
       "\n",
       "      TotRmsAbvGrd  Fireplaces  FireplaceQu  GarageFinish  GarageCars  \\\n",
       "0                8           0            0             2           2   \n",
       "1                6           1            3             2           2   \n",
       "2                6           1            3             2           2   \n",
       "3                7           1            4             1           3   \n",
       "4                9           1            3             2           3   \n",
       "...            ...         ...          ...           ...         ...   \n",
       "1455             7           1            3             2           2   \n",
       "1456             7           2            3             1           2   \n",
       "1457             9           2            4             2           1   \n",
       "1458             5           0            0             1           1   \n",
       "1459             6           0            0             3           1   \n",
       "\n",
       "      GarageArea  Neighborhood_NridgHt  Foundation_PConc  \n",
       "0            548                     0                 1  \n",
       "1            460                     0                 0  \n",
       "2            608                     0                 1  \n",
       "3            642                     0                 0  \n",
       "4            836                     0                 1  \n",
       "...          ...                   ...               ...  \n",
       "1455         460                     0                 1  \n",
       "1456         500                     0                 0  \n",
       "1457         252                     0                 0  \n",
       "1458         240                     0                 0  \n",
       "1459         276                     0                 0  \n",
       "\n",
       "[1446 rows x 20 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_Kbest"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a next step, we will be exploring the correlation between the K selected features. Our goal here is trying to spot any strong collinearity relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/25/8m9ycrtx2kv84b8szslr4jfc0000gp/T/ipykernel_45864/2875824191.py:5: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  np.triu(np.ones(correlations.shape), k=1).astype(np.bool)\n"
     ]
    }
   ],
   "source": [
    "correlations = X_Kbest.corr()\n",
    "\n",
    "# Step 1: Drop diagonal entries\n",
    "corr_df = correlations.where(\n",
    "    np.triu(np.ones(correlations.shape), k=1).astype(np.bool)\n",
    ")\n",
    "\n",
    "# Step 2: Unstack to get a Series of correlation values\n",
    "corr_series = corr_df.unstack()\n",
    "\n",
    "# Step 3: Sort the Series in descending order\n",
    "corr_series_sorted = corr_series.sort_values(ascending=False)\n",
    "\n",
    "# Print the sorted correlation values\n",
    "corr_series_sortedDF = pd.DataFrame(corr_series_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: >"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(\n",
    "    correlations,\n",
    "    annot=True,\n",
    "    cmap=\"rocket_r\",\n",
    "    fmt=\".2f\",\n",
    "    annot_kws={\"size\": 6},\n",
    "    mask=correlations < 0.6,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlflow.start_run(\n",
    "#    run_name=\"RUN_1\",\n",
    "#    experiment_id=experiment_id,\n",
    "#    tags={\"version\": \"v1\", \"priority\": \"P1\"},\n",
    "#    description=\"KBestSelector\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean average percentage error will be our standard metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = {\n",
    "    \"R-squared\": make_scorer(r2_score),\n",
    "    \"Adjusted R-squared\": make_scorer(r2_score, greater_is_better=False),\n",
    "    \"Mape\": mape_scorer,\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "\n",
    "We will start with a simple linear regression with ElasticNet penalty terms. This will serve as a baseline for comparison; Our goal is finding out what score can I get with the least amount of effort in terms of feature engineering. There will be a little bit of hyperparameter tinkering as I will be using gridsearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"l1_ratio\": [0.1, 0.3, 0.5, 0.7, 0.9],\n",
    "    \"alpha\": [1, 10, 100, 1000],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridSearch = GridSearchCV(\n",
    "    estimator=ElasticNet(max_iter=50000),\n",
    "    param_grid=param_grid,\n",
    "    scoring=scoring,\n",
    "    verbose=3,\n",
    "    n_jobs=-1,\n",
    "    cv=5,\n",
    "    refit=\"Mape\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END alpha=1, l1_ratio=0.1; Adjusted R-squared: (test=-0.892) Mape: (test=-9.172) R-squared: (test=0.892) total time=   0.1s\n",
      "[CV 2/5] END alpha=1, l1_ratio=0.1; Adjusted R-squared: (test=-0.837) Mape: (test=-11.102) R-squared: (test=0.837) total time=   0.1s\n",
      "[CV 4/5] END alpha=1, l1_ratio=0.1; Adjusted R-squared: (test=-0.886) Mape: (test=-9.672) R-squared: (test=0.886) total time=   0.1s\n",
      "[CV 1/5] END alpha=1, l1_ratio=0.3; Adjusted R-squared: (test=-0.898) Mape: (test=-9.094) R-squared: (test=0.898) total time=   0.0s\n",
      "[CV 4/5] END alpha=1, l1_ratio=0.3; Adjusted R-squared: (test=-0.890) Mape: (test=-9.446) R-squared: (test=0.890) total time=   0.0s\n",
      "[CV 5/5] END alpha=1, l1_ratio=0.1; Adjusted R-squared: (test=-0.746) Mape: (test=-10.671) R-squared: (test=0.746) total time=   0.0s\n",
      "[CV 3/5] END alpha=1, l1_ratio=0.1; Adjusted R-squared: (test=-0.847) Mape: (test=-10.254) R-squared: (test=0.847) total time=   0.1s\n",
      "[CV 5/5] END alpha=1, l1_ratio=0.3; Adjusted R-squared: (test=-0.742) Mape: (test=-10.559) R-squared: (test=0.742) total time=   0.0s\n",
      "[CV 2/5] END alpha=1, l1_ratio=0.3; Adjusted R-squared: (test=-0.842) Mape: (test=-10.980) R-squared: (test=0.842) total time=   0.0s\n",
      "[CV 1/5] END alpha=1, l1_ratio=0.5; Adjusted R-squared: (test=-0.904) Mape: (test=-9.056) R-squared: (test=0.904) total time=   0.1s\n",
      "[CV 2/5] END alpha=1, l1_ratio=0.5; Adjusted R-squared: (test=-0.848) Mape: (test=-10.878) R-squared: (test=0.848) total time=   0.0s\n",
      "[CV 3/5] END alpha=1, l1_ratio=0.5; Adjusted R-squared: (test=-0.854) Mape: (test=-10.046) R-squared: (test=0.854) total time=   0.0s\n",
      "[CV 4/5] END alpha=1, l1_ratio=0.5; Adjusted R-squared: (test=-0.893) Mape: (test=-9.320) R-squared: (test=0.893) total time=   0.0s\n",
      "[CV 1/5] END alpha=1, l1_ratio=0.7; Adjusted R-squared: (test=-0.909) Mape: (test=-9.077) R-squared: (test=0.909) total time=   0.0s\n",
      "[CV 5/5] END alpha=1, l1_ratio=0.5; Adjusted R-squared: (test=-0.736) Mape: (test=-10.456) R-squared: (test=0.736) total time=   0.0s\n",
      "[CV 2/5] END alpha=1, l1_ratio=0.7; Adjusted R-squared: (test=-0.852) Mape: (test=-10.779) R-squared: (test=0.852) total time=   0.0s\n",
      "[CV 3/5] END alpha=1, l1_ratio=0.7; Adjusted R-squared: (test=-0.852) Mape: (test=-10.007) R-squared: (test=0.852) total time=   0.0s\n",
      "[CV 4/5] END alpha=1, l1_ratio=0.7; Adjusted R-squared: (test=-0.894) Mape: (test=-9.387) R-squared: (test=0.894) total time=   0.0s\n",
      "[CV 1/5] END alpha=10, l1_ratio=0.1; Adjusted R-squared: (test=-0.698) Mape: (test=-15.340) R-squared: (test=0.698) total time=   0.0s\n",
      "[CV 2/5] END alpha=10, l1_ratio=0.1; Adjusted R-squared: (test=-0.648) Mape: (test=-18.985) R-squared: (test=0.648) total time=   0.0s\n",
      "[CV 2/5] END alpha=1, l1_ratio=0.9; Adjusted R-squared: (test=-0.854) Mape: (test=-10.862) R-squared: (test=0.854) total time=   0.1s\n",
      "[CV 3/5] END alpha=10, l1_ratio=0.1; Adjusted R-squared: (test=-0.662) Mape: (test=-16.872) R-squared: (test=0.662) total time=   0.0s\n",
      "[CV 1/5] END alpha=1, l1_ratio=0.9; Adjusted R-squared: (test=-0.909) Mape: (test=-9.480) R-squared: (test=0.909) total time=   0.1s\n",
      "[CV 5/5] END alpha=1, l1_ratio=0.7; Adjusted R-squared: (test=-0.725) Mape: (test=-10.485) R-squared: (test=0.725) total time=   0.1s\n",
      "[CV 4/5] END alpha=10, l1_ratio=0.1; Adjusted R-squared: (test=-0.710) Mape: (test=-17.589) R-squared: (test=0.710) total time=   0.0s\n",
      "[CV 1/5] END alpha=10, l1_ratio=0.3; Adjusted R-squared: (test=-0.739) Mape: (test=-13.827) R-squared: (test=0.739) total time=   0.0s\n",
      "[CV 3/5] END alpha=1, l1_ratio=0.9; Adjusted R-squared: (test=-0.836) Mape: (test=-10.198) R-squared: (test=0.836) total time=   0.0s\n",
      "[CV 4/5] END alpha=1, l1_ratio=0.9; Adjusted R-squared: (test=-0.891) Mape: (test=-9.861) R-squared: (test=0.891) total time=   0.0s\n",
      "[CV 5/5] END alpha=10, l1_ratio=0.1; Adjusted R-squared: (test=-0.653) Mape: (test=-16.718) R-squared: (test=0.653) total time=   0.0s\n",
      "[CV 5/5] END alpha=1, l1_ratio=0.9; Adjusted R-squared: (test=-0.702) Mape: (test=-10.981) R-squared: (test=0.702) total time=   0.1s\n",
      "[CV 2/5] END alpha=10, l1_ratio=0.3; Adjusted R-squared: (test=-0.688) Mape: (test=-17.422) R-squared: (test=0.688) total time=   0.0s\n",
      "[CV 4/5] END alpha=10, l1_ratio=0.3; Adjusted R-squared: (test=-0.750) Mape: (test=-16.049) R-squared: (test=0.750) total time=   0.0s\n",
      "[CV 3/5] END alpha=10, l1_ratio=0.3; Adjusted R-squared: (test=-0.701) Mape: (test=-15.438) R-squared: (test=0.701) total time=   0.0s\n",
      "[CV 3/5] END alpha=1, l1_ratio=0.3; Adjusted R-squared: (test=-0.851) Mape: (test=-10.141) R-squared: (test=0.851) total time=   0.0s\n",
      "[CV 5/5] END alpha=10, l1_ratio=0.3; Adjusted R-squared: (test=-0.683) Mape: (test=-15.425) R-squared: (test=0.683) total time=   0.0s\n",
      "[CV 1/5] END alpha=10, l1_ratio=0.5; Adjusted R-squared: (test=-0.784) Mape: (test=-12.246) R-squared: (test=0.784) total time=   0.0s\n",
      "[CV 3/5] END alpha=10, l1_ratio=0.5; Adjusted R-squared: (test=-0.745) Mape: (test=-13.774) R-squared: (test=0.745) total time=   0.0s\n",
      "[CV 2/5] END alpha=10, l1_ratio=0.5; Adjusted R-squared: (test=-0.733) Mape: (test=-15.494) R-squared: (test=0.733) total time=   0.0s\n",
      "[CV 4/5] END alpha=10, l1_ratio=0.5; Adjusted R-squared: (test=-0.793) Mape: (test=-14.205) R-squared: (test=0.793) total time=   0.0s\n",
      "[CV 5/5] END alpha=10, l1_ratio=0.5; Adjusted R-squared: (test=-0.713) Mape: (test=-13.926) R-squared: (test=0.713) total time=   0.0s\n",
      "[CV 2/5] END alpha=10, l1_ratio=0.7; Adjusted R-squared: (test=-0.782) Mape: (test=-13.233) R-squared: (test=0.782) total time=   0.0s\n",
      "[CV 3/5] END alpha=10, l1_ratio=0.7; Adjusted R-squared: (test=-0.793) Mape: (test=-12.032) R-squared: (test=0.793) total time=   0.0s\n",
      "[CV 4/5] END alpha=10, l1_ratio=0.7; Adjusted R-squared: (test=-0.838) Mape: (test=-12.068) R-squared: (test=0.838) total time=   0.0s\n",
      "[CV 1/5] END alpha=10, l1_ratio=0.7; Adjusted R-squared: (test=-0.833) Mape: (test=-10.645) R-squared: (test=0.833) total time=   0.0s\n",
      "[CV 5/5] END alpha=10, l1_ratio=0.7; Adjusted R-squared: (test=-0.740) Mape: (test=-12.254) R-squared: (test=0.740) total time=   0.0s\n",
      "[CV 2/5] END alpha=10, l1_ratio=0.9; Adjusted R-squared: (test=-0.835) Mape: (test=-11.178) R-squared: (test=0.835) total time=   0.0s\n",
      "[CV 1/5] END alpha=100, l1_ratio=0.1; Adjusted R-squared: (test=-0.204) Mape: (test=-29.288) R-squared: (test=0.204) total time=   0.0s\n",
      "[CV 3/5] END alpha=10, l1_ratio=0.9; Adjusted R-squared: (test=-0.845) Mape: (test=-10.332) R-squared: (test=0.845) total time=   0.0s\n",
      "[CV 1/5] END alpha=10, l1_ratio=0.9; Adjusted R-squared: (test=-0.889) Mape: (test=-9.210) R-squared: (test=0.889) total time=   0.0s\n",
      "[CV 2/5] END alpha=100, l1_ratio=0.1; Adjusted R-squared: (test=-0.181) Mape: (test=-33.289) R-squared: (test=0.181) total time=   0.0s\n",
      "[CV 5/5] END alpha=100, l1_ratio=0.1; Adjusted R-squared: (test=-0.203) Mape: (test=-29.040) R-squared: (test=0.203) total time=   0.0s\n",
      "[CV 3/5] END alpha=100, l1_ratio=0.1; Adjusted R-squared: (test=-0.194) Mape: (test=-30.106) R-squared: (test=0.194) total time=   0.0s\n",
      "[CV 4/5] END alpha=10, l1_ratio=0.9; Adjusted R-squared: (test=-0.884) Mape: (test=-9.778) R-squared: (test=0.884) total time=   0.0s\n",
      "[CV 2/5] END alpha=100, l1_ratio=0.3; Adjusted R-squared: (test=-0.221) Mape: (test=-32.262) R-squared: (test=0.221) total time=   0.0s\n",
      "[CV 4/5] END alpha=100, l1_ratio=0.1; Adjusted R-squared: (test=-0.201) Mape: (test=-31.128) R-squared: (test=0.201) total time=   0.0s\n",
      "[CV 1/5] END alpha=100, l1_ratio=0.3; Adjusted R-squared: (test=-0.247) Mape: (test=-28.274) R-squared: (test=0.247) total time=   0.0s\n",
      "[CV 3/5] END alpha=100, l1_ratio=0.3; Adjusted R-squared: (test=-0.235) Mape: (test=-29.132) R-squared: (test=0.235) total time=   0.0s\n",
      "[CV 4/5] END alpha=100, l1_ratio=0.3; Adjusted R-squared: (test=-0.248) Mape: (test=-30.118) R-squared: (test=0.248) total time=   0.0s\n",
      "[CV 5/5] END alpha=10, l1_ratio=0.9; Adjusted R-squared: (test=-0.747) Mape: (test=-10.730) R-squared: (test=0.747) total time=   0.0s\n",
      "[CV 1/5] END alpha=100, l1_ratio=0.5; Adjusted R-squared: (test=-0.315) Mape: (test=-26.662) R-squared: (test=0.315) total time=   0.0s\n",
      "[CV 3/5] END alpha=100, l1_ratio=0.5; Adjusted R-squared: (test=-0.299) Mape: (test=-27.576) R-squared: (test=0.299) total time=   0.0s\n",
      "[CV 5/5] END alpha=100, l1_ratio=0.3; Adjusted R-squared: (test=-0.246) Mape: (test=-28.114) R-squared: (test=0.246) total time=   0.0s\n",
      "[CV 2/5] END alpha=100, l1_ratio=0.5; Adjusted R-squared: (test=-0.284) Mape: (test=-30.606) R-squared: (test=0.284) total time=   0.0s\n",
      "[CV 4/5] END alpha=100, l1_ratio=0.5; Adjusted R-squared: (test=-0.319) Mape: (test=-28.502) R-squared: (test=0.319) total time=   0.0s\n",
      "[CV 2/5] END alpha=100, l1_ratio=0.7; Adjusted R-squared: (test=-0.393) Mape: (test=-27.488) R-squared: (test=0.393) total time=   0.0s\n",
      "[CV 5/5] END alpha=100, l1_ratio=0.5; Adjusted R-squared: (test=-0.311) Mape: (test=-26.634) R-squared: (test=0.311) total time=   0.0s\n",
      "[CV 4/5] END alpha=100, l1_ratio=0.7; Adjusted R-squared: (test=-0.442) Mape: (test=-25.567) R-squared: (test=0.442) total time=   0.0s\n",
      "[CV 3/5] END alpha=100, l1_ratio=0.7; Adjusted R-squared: (test=-0.410) Mape: (test=-24.712) R-squared: (test=0.410) total time=   0.0s\n",
      "[CV 1/5] END alpha=100, l1_ratio=0.7; Adjusted R-squared: (test=-0.432) Mape: (test=-23.675) R-squared: (test=0.432) total time=   0.0s\n",
      "[CV 1/5] END alpha=100, l1_ratio=0.9; Adjusted R-squared: (test=-0.678) Mape: (test=-16.094) R-squared: (test=0.678) total time=   0.0s\n",
      "[CV 5/5] END alpha=100, l1_ratio=0.7; Adjusted R-squared: (test=-0.422) Mape: (test=-23.931) R-squared: (test=0.422) total time=   0.0s\n",
      "[CV 3/5] END alpha=100, l1_ratio=0.9; Adjusted R-squared: (test=-0.642) Mape: (test=-17.571) R-squared: (test=0.642) total time=   0.0s\n",
      "[CV 2/5] END alpha=100, l1_ratio=0.9; Adjusted R-squared: (test=-0.628) Mape: (test=-19.740) R-squared: (test=0.628) total time=   0.0s\n",
      "[CV 5/5] END alpha=100, l1_ratio=0.9; Adjusted R-squared: (test=-0.637) Mape: (test=-17.347) R-squared: (test=0.637) total time=   0.0s\n",
      "[CV 4/5] END alpha=100, l1_ratio=0.9; Adjusted R-squared: (test=-0.690) Mape: (test=-18.315) R-squared: (test=0.690) total time=   0.0s\n",
      "[CV 2/5] END alpha=1000, l1_ratio=0.1; Adjusted R-squared: (test=-0.018) Mape: (test=-37.229) R-squared: (test=0.018) total time=   0.0s\n",
      "[CV 4/5] END alpha=1000, l1_ratio=0.1; Adjusted R-squared: (test=-0.007) Mape: (test=-35.039) R-squared: (test=0.007) total time=   0.0s\n",
      "[CV 1/5] END alpha=1000, l1_ratio=0.1; Adjusted R-squared: (test=-0.023) Mape: (test=-33.199) R-squared: (test=0.023) total time=   0.0s\n",
      "[CV 3/5] END alpha=1000, l1_ratio=0.1; Adjusted R-squared: (test=-0.023) Mape: (test=-33.860) R-squared: (test=0.023) total time=   0.0s\n",
      "[CV 1/5] END alpha=1000, l1_ratio=0.3; Adjusted R-squared: (test=-0.030) Mape: (test=-33.062) R-squared: (test=0.030) total time=   0.0s\n",
      "[CV 2/5] END alpha=1000, l1_ratio=0.3; Adjusted R-squared: (test=-0.024) Mape: (test=-37.088) R-squared: (test=0.024) total time=   0.0s\n",
      "[CV 5/5] END alpha=1000, l1_ratio=0.1; Adjusted R-squared: (test=-0.025) Mape: (test=-32.598) R-squared: (test=0.025) total time=   0.0s\n",
      "[CV 3/5] END alpha=1000, l1_ratio=0.3; Adjusted R-squared: (test=-0.030) Mape: (test=-33.729) R-squared: (test=0.030) total time=   0.0s\n",
      "[CV 5/5] END alpha=1000, l1_ratio=0.3; Adjusted R-squared: (test=-0.032) Mape: (test=-32.473) R-squared: (test=0.032) total time=   0.0s\n",
      "[CV 4/5] END alpha=1000, l1_ratio=0.3; Adjusted R-squared: (test=-0.015) Mape: (test=-34.900) R-squared: (test=0.015) total time=   0.0s\n",
      "[CV 1/5] END alpha=1000, l1_ratio=0.5; Adjusted R-squared: (test=-0.042) Mape: (test=-32.820) R-squared: (test=0.042) total time=   0.0s\n",
      "[CV 2/5] END alpha=1000, l1_ratio=0.5; Adjusted R-squared: (test=-0.034) Mape: (test=-36.836) R-squared: (test=0.034) total time=   0.0s\n",
      "[CV 3/5] END alpha=1000, l1_ratio=0.5; Adjusted R-squared: (test=-0.041) Mape: (test=-33.495) R-squared: (test=0.041) total time=   0.0s\n",
      "[CV 4/5] END alpha=1000, l1_ratio=0.5; Adjusted R-squared: (test=-0.027) Mape: (test=-34.653) R-squared: (test=0.027) total time=   0.0s\n",
      "[CV 5/5] END alpha=1000, l1_ratio=0.5; Adjusted R-squared: (test=-0.043) Mape: (test=-32.251) R-squared: (test=0.043) total time=   0.0s\n",
      "[CV 1/5] END alpha=1000, l1_ratio=0.7; Adjusted R-squared: (test=-0.068) Mape: (test=-32.269) R-squared: (test=0.068) total time=   0.0s\n",
      "[CV 2/5] END alpha=1000, l1_ratio=0.7; Adjusted R-squared: (test=-0.058) Mape: (test=-36.271) R-squared: (test=0.058) total time=   0.0s\n",
      "[CV 3/5] END alpha=1000, l1_ratio=0.7; Adjusted R-squared: (test=-0.065) Mape: (test=-32.966) R-squared: (test=0.065) total time=   0.0s\n",
      "[CV 4/5] END alpha=1000, l1_ratio=0.7; Adjusted R-squared: (test=-0.056) Mape: (test=-34.096) R-squared: (test=0.056) total time=   0.0s\n",
      "[CV 5/5] END alpha=1000, l1_ratio=0.7; Adjusted R-squared: (test=-0.069) Mape: (test=-31.748) R-squared: (test=0.069) total time=   0.0s\n",
      "[CV 1/5] END alpha=1000, l1_ratio=0.9; Adjusted R-squared: (test=-0.180) Mape: (test=-29.829) R-squared: (test=0.180) total time=   0.0s\n",
      "[CV 2/5] END alpha=1000, l1_ratio=0.9; Adjusted R-squared: (test=-0.159) Mape: (test=-33.834) R-squared: (test=0.159) total time=   0.0s\n",
      "[CV 4/5] END alpha=1000, l1_ratio=0.9; Adjusted R-squared: (test=-0.177) Mape: (test=-31.649) R-squared: (test=0.177) total time=   0.0s\n",
      "[CV 3/5] END alpha=1000, l1_ratio=0.9; Adjusted R-squared: (test=-0.171) Mape: (test=-30.628) R-squared: (test=0.171) total time=   0.0s\n",
      "[CV 5/5] END alpha=1000, l1_ratio=0.9; Adjusted R-squared: (test=-0.180) Mape: (test=-29.521) R-squared: (test=0.180) total time=   0.0s\n"
     ]
    }
   ],
   "source": [
    "gridSearch.fit(X_scaled, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>param_l1_ratio</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_R-squared</th>\n",
       "      <th>split1_test_R-squared</th>\n",
       "      <th>split2_test_R-squared</th>\n",
       "      <th>split3_test_R-squared</th>\n",
       "      <th>split4_test_R-squared</th>\n",
       "      <th>mean_test_R-squared</th>\n",
       "      <th>std_test_R-squared</th>\n",
       "      <th>rank_test_R-squared</th>\n",
       "      <th>split0_test_Adjusted R-squared</th>\n",
       "      <th>split1_test_Adjusted R-squared</th>\n",
       "      <th>split2_test_Adjusted R-squared</th>\n",
       "      <th>split3_test_Adjusted R-squared</th>\n",
       "      <th>split4_test_Adjusted R-squared</th>\n",
       "      <th>mean_test_Adjusted R-squared</th>\n",
       "      <th>std_test_Adjusted R-squared</th>\n",
       "      <th>rank_test_Adjusted R-squared</th>\n",
       "      <th>split0_test_Mape</th>\n",
       "      <th>split1_test_Mape</th>\n",
       "      <th>split2_test_Mape</th>\n",
       "      <th>split3_test_Mape</th>\n",
       "      <th>split4_test_Mape</th>\n",
       "      <th>mean_test_Mape</th>\n",
       "      <th>std_test_Mape</th>\n",
       "      <th>rank_test_Mape</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.067440</td>\n",
       "      <td>0.022774</td>\n",
       "      <td>0.003356</td>\n",
       "      <td>0.001273</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'alpha': 1, 'l1_ratio': 0.1}</td>\n",
       "      <td>0.892241</td>\n",
       "      <td>0.837254</td>\n",
       "      <td>0.847481</td>\n",
       "      <td>0.886263</td>\n",
       "      <td>0.746113</td>\n",
       "      <td>0.841870</td>\n",
       "      <td>0.052402</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.892241</td>\n",
       "      <td>-0.837254</td>\n",
       "      <td>-0.847481</td>\n",
       "      <td>-0.886263</td>\n",
       "      <td>-0.746113</td>\n",
       "      <td>-0.841870</td>\n",
       "      <td>0.052402</td>\n",
       "      <td>17</td>\n",
       "      <td>-9.171965</td>\n",
       "      <td>-11.101695</td>\n",
       "      <td>-10.253828</td>\n",
       "      <td>-9.672421</td>\n",
       "      <td>-10.671097</td>\n",
       "      <td>-10.174202</td>\n",
       "      <td>0.688440</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.038308</td>\n",
       "      <td>0.006749</td>\n",
       "      <td>0.003257</td>\n",
       "      <td>0.002014</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'alpha': 1, 'l1_ratio': 0.3}</td>\n",
       "      <td>0.898202</td>\n",
       "      <td>0.842495</td>\n",
       "      <td>0.851388</td>\n",
       "      <td>0.889869</td>\n",
       "      <td>0.742379</td>\n",
       "      <td>0.844867</td>\n",
       "      <td>0.055537</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.898202</td>\n",
       "      <td>-0.842495</td>\n",
       "      <td>-0.851388</td>\n",
       "      <td>-0.889869</td>\n",
       "      <td>-0.742379</td>\n",
       "      <td>-0.844867</td>\n",
       "      <td>0.055537</td>\n",
       "      <td>18</td>\n",
       "      <td>-9.093959</td>\n",
       "      <td>-10.979831</td>\n",
       "      <td>-10.140777</td>\n",
       "      <td>-9.445774</td>\n",
       "      <td>-10.558913</td>\n",
       "      <td>-10.043851</td>\n",
       "      <td>0.694368</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.037971</td>\n",
       "      <td>0.006514</td>\n",
       "      <td>0.002239</td>\n",
       "      <td>0.002011</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'alpha': 1, 'l1_ratio': 0.5}</td>\n",
       "      <td>0.903991</td>\n",
       "      <td>0.847551</td>\n",
       "      <td>0.853727</td>\n",
       "      <td>0.892721</td>\n",
       "      <td>0.736115</td>\n",
       "      <td>0.846821</td>\n",
       "      <td>0.059463</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.903991</td>\n",
       "      <td>-0.847551</td>\n",
       "      <td>-0.853727</td>\n",
       "      <td>-0.892721</td>\n",
       "      <td>-0.736115</td>\n",
       "      <td>-0.846821</td>\n",
       "      <td>0.059463</td>\n",
       "      <td>20</td>\n",
       "      <td>-9.056415</td>\n",
       "      <td>-10.878045</td>\n",
       "      <td>-10.045838</td>\n",
       "      <td>-9.320131</td>\n",
       "      <td>-10.455631</td>\n",
       "      <td>-9.951212</td>\n",
       "      <td>0.681372</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.047332</td>\n",
       "      <td>0.013470</td>\n",
       "      <td>0.002050</td>\n",
       "      <td>0.000969</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>{'alpha': 1, 'l1_ratio': 0.7}</td>\n",
       "      <td>0.908932</td>\n",
       "      <td>0.852125</td>\n",
       "      <td>0.852133</td>\n",
       "      <td>0.894047</td>\n",
       "      <td>0.725042</td>\n",
       "      <td>0.846456</td>\n",
       "      <td>0.064767</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.908932</td>\n",
       "      <td>-0.852125</td>\n",
       "      <td>-0.852133</td>\n",
       "      <td>-0.894047</td>\n",
       "      <td>-0.725042</td>\n",
       "      <td>-0.846456</td>\n",
       "      <td>0.064767</td>\n",
       "      <td>19</td>\n",
       "      <td>-9.076683</td>\n",
       "      <td>-10.778818</td>\n",
       "      <td>-10.007080</td>\n",
       "      <td>-9.386946</td>\n",
       "      <td>-10.484789</td>\n",
       "      <td>-9.946863</td>\n",
       "      <td>0.641227</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.051835</td>\n",
       "      <td>0.006752</td>\n",
       "      <td>0.001106</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>{'alpha': 1, 'l1_ratio': 0.9}</td>\n",
       "      <td>0.909323</td>\n",
       "      <td>0.854427</td>\n",
       "      <td>0.836400</td>\n",
       "      <td>0.891065</td>\n",
       "      <td>0.701880</td>\n",
       "      <td>0.838619</td>\n",
       "      <td>0.073078</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.909323</td>\n",
       "      <td>-0.854427</td>\n",
       "      <td>-0.836400</td>\n",
       "      <td>-0.891065</td>\n",
       "      <td>-0.701880</td>\n",
       "      <td>-0.838619</td>\n",
       "      <td>0.073078</td>\n",
       "      <td>15</td>\n",
       "      <td>-9.479717</td>\n",
       "      <td>-10.862342</td>\n",
       "      <td>-10.197964</td>\n",
       "      <td>-9.861464</td>\n",
       "      <td>-10.980818</td>\n",
       "      <td>-10.276461</td>\n",
       "      <td>0.574902</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.006734</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>0.002567</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'alpha': 1000, 'l1_ratio': 0.1}</td>\n",
       "      <td>0.023207</td>\n",
       "      <td>0.017943</td>\n",
       "      <td>0.023292</td>\n",
       "      <td>0.007427</td>\n",
       "      <td>0.024914</td>\n",
       "      <td>0.019357</td>\n",
       "      <td>0.006411</td>\n",
       "      <td>20</td>\n",
       "      <td>-0.023207</td>\n",
       "      <td>-0.017943</td>\n",
       "      <td>-0.023292</td>\n",
       "      <td>-0.007427</td>\n",
       "      <td>-0.024914</td>\n",
       "      <td>-0.019357</td>\n",
       "      <td>0.006411</td>\n",
       "      <td>1</td>\n",
       "      <td>-33.199112</td>\n",
       "      <td>-37.229292</td>\n",
       "      <td>-33.860348</td>\n",
       "      <td>-35.039317</td>\n",
       "      <td>-32.598478</td>\n",
       "      <td>-34.385309</td>\n",
       "      <td>1.636544</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.005848</td>\n",
       "      <td>0.003317</td>\n",
       "      <td>0.001317</td>\n",
       "      <td>0.000590</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'alpha': 1000, 'l1_ratio': 0.3}</td>\n",
       "      <td>0.029846</td>\n",
       "      <td>0.023889</td>\n",
       "      <td>0.029567</td>\n",
       "      <td>0.014642</td>\n",
       "      <td>0.031557</td>\n",
       "      <td>0.025900</td>\n",
       "      <td>0.006194</td>\n",
       "      <td>19</td>\n",
       "      <td>-0.029846</td>\n",
       "      <td>-0.023889</td>\n",
       "      <td>-0.029567</td>\n",
       "      <td>-0.014642</td>\n",
       "      <td>-0.031557</td>\n",
       "      <td>-0.025900</td>\n",
       "      <td>0.006194</td>\n",
       "      <td>2</td>\n",
       "      <td>-33.062336</td>\n",
       "      <td>-37.087716</td>\n",
       "      <td>-33.728662</td>\n",
       "      <td>-34.899547</td>\n",
       "      <td>-32.472953</td>\n",
       "      <td>-34.250243</td>\n",
       "      <td>1.631856</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.003189</td>\n",
       "      <td>0.000248</td>\n",
       "      <td>0.000917</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'alpha': 1000, 'l1_ratio': 0.5}</td>\n",
       "      <td>0.041572</td>\n",
       "      <td>0.034400</td>\n",
       "      <td>0.040649</td>\n",
       "      <td>0.027372</td>\n",
       "      <td>0.043275</td>\n",
       "      <td>0.037454</td>\n",
       "      <td>0.005866</td>\n",
       "      <td>18</td>\n",
       "      <td>-0.041572</td>\n",
       "      <td>-0.034400</td>\n",
       "      <td>-0.040649</td>\n",
       "      <td>-0.027372</td>\n",
       "      <td>-0.043275</td>\n",
       "      <td>-0.037454</td>\n",
       "      <td>0.005866</td>\n",
       "      <td>3</td>\n",
       "      <td>-32.819572</td>\n",
       "      <td>-36.836136</td>\n",
       "      <td>-33.494709</td>\n",
       "      <td>-34.653019</td>\n",
       "      <td>-32.250895</td>\n",
       "      <td>-34.010866</td>\n",
       "      <td>1.623429</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.004242</td>\n",
       "      <td>0.000484</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>{'alpha': 1000, 'l1_ratio': 0.7}</td>\n",
       "      <td>0.067860</td>\n",
       "      <td>0.058007</td>\n",
       "      <td>0.065490</td>\n",
       "      <td>0.055863</td>\n",
       "      <td>0.069490</td>\n",
       "      <td>0.063342</td>\n",
       "      <td>0.005426</td>\n",
       "      <td>17</td>\n",
       "      <td>-0.067860</td>\n",
       "      <td>-0.058007</td>\n",
       "      <td>-0.065490</td>\n",
       "      <td>-0.055863</td>\n",
       "      <td>-0.069490</td>\n",
       "      <td>-0.063342</td>\n",
       "      <td>0.005426</td>\n",
       "      <td>4</td>\n",
       "      <td>-32.269221</td>\n",
       "      <td>-36.271314</td>\n",
       "      <td>-32.966001</td>\n",
       "      <td>-34.096200</td>\n",
       "      <td>-31.747684</td>\n",
       "      <td>-33.470084</td>\n",
       "      <td>1.606347</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.004158</td>\n",
       "      <td>0.000908</td>\n",
       "      <td>0.000910</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>{'alpha': 1000, 'l1_ratio': 0.9}</td>\n",
       "      <td>0.180098</td>\n",
       "      <td>0.159470</td>\n",
       "      <td>0.171479</td>\n",
       "      <td>0.176669</td>\n",
       "      <td>0.180424</td>\n",
       "      <td>0.173628</td>\n",
       "      <td>0.007776</td>\n",
       "      <td>16</td>\n",
       "      <td>-0.180098</td>\n",
       "      <td>-0.159470</td>\n",
       "      <td>-0.171479</td>\n",
       "      <td>-0.176669</td>\n",
       "      <td>-0.180424</td>\n",
       "      <td>-0.173628</td>\n",
       "      <td>0.007776</td>\n",
       "      <td>5</td>\n",
       "      <td>-29.828901</td>\n",
       "      <td>-33.834230</td>\n",
       "      <td>-30.628189</td>\n",
       "      <td>-31.648796</td>\n",
       "      <td>-29.520628</td>\n",
       "      <td>-31.092149</td>\n",
       "      <td>1.556252</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_alpha  \\\n",
       "0        0.067440      0.022774         0.003356        0.001273           1   \n",
       "1        0.038308      0.006749         0.003257        0.002014           1   \n",
       "2        0.037971      0.006514         0.002239        0.002011           1   \n",
       "3        0.047332      0.013470         0.002050        0.000969           1   \n",
       "4        0.051835      0.006752         0.001106        0.000090           1   \n",
       "..            ...           ...              ...             ...         ...   \n",
       "15       0.006734      0.001900         0.002567        0.000247        1000   \n",
       "16       0.005848      0.003317         0.001317        0.000590        1000   \n",
       "17       0.003189      0.000248         0.000917        0.000030        1000   \n",
       "18       0.004242      0.000484         0.000977        0.000033        1000   \n",
       "19       0.004158      0.000908         0.000910        0.000121        1000   \n",
       "\n",
       "   param_l1_ratio                            params  split0_test_R-squared  \\\n",
       "0             0.1     {'alpha': 1, 'l1_ratio': 0.1}               0.892241   \n",
       "1             0.3     {'alpha': 1, 'l1_ratio': 0.3}               0.898202   \n",
       "2             0.5     {'alpha': 1, 'l1_ratio': 0.5}               0.903991   \n",
       "3             0.7     {'alpha': 1, 'l1_ratio': 0.7}               0.908932   \n",
       "4             0.9     {'alpha': 1, 'l1_ratio': 0.9}               0.909323   \n",
       "..            ...                               ...                    ...   \n",
       "15            0.1  {'alpha': 1000, 'l1_ratio': 0.1}               0.023207   \n",
       "16            0.3  {'alpha': 1000, 'l1_ratio': 0.3}               0.029846   \n",
       "17            0.5  {'alpha': 1000, 'l1_ratio': 0.5}               0.041572   \n",
       "18            0.7  {'alpha': 1000, 'l1_ratio': 0.7}               0.067860   \n",
       "19            0.9  {'alpha': 1000, 'l1_ratio': 0.9}               0.180098   \n",
       "\n",
       "    split1_test_R-squared  split2_test_R-squared  split3_test_R-squared  \\\n",
       "0                0.837254               0.847481               0.886263   \n",
       "1                0.842495               0.851388               0.889869   \n",
       "2                0.847551               0.853727               0.892721   \n",
       "3                0.852125               0.852133               0.894047   \n",
       "4                0.854427               0.836400               0.891065   \n",
       "..                    ...                    ...                    ...   \n",
       "15               0.017943               0.023292               0.007427   \n",
       "16               0.023889               0.029567               0.014642   \n",
       "17               0.034400               0.040649               0.027372   \n",
       "18               0.058007               0.065490               0.055863   \n",
       "19               0.159470               0.171479               0.176669   \n",
       "\n",
       "    split4_test_R-squared  mean_test_R-squared  std_test_R-squared  \\\n",
       "0                0.746113             0.841870            0.052402   \n",
       "1                0.742379             0.844867            0.055537   \n",
       "2                0.736115             0.846821            0.059463   \n",
       "3                0.725042             0.846456            0.064767   \n",
       "4                0.701880             0.838619            0.073078   \n",
       "..                    ...                  ...                 ...   \n",
       "15               0.024914             0.019357            0.006411   \n",
       "16               0.031557             0.025900            0.006194   \n",
       "17               0.043275             0.037454            0.005866   \n",
       "18               0.069490             0.063342            0.005426   \n",
       "19               0.180424             0.173628            0.007776   \n",
       "\n",
       "    rank_test_R-squared  split0_test_Adjusted R-squared  \\\n",
       "0                     4                       -0.892241   \n",
       "1                     3                       -0.898202   \n",
       "2                     1                       -0.903991   \n",
       "3                     2                       -0.908932   \n",
       "4                     6                       -0.909323   \n",
       "..                  ...                             ...   \n",
       "15                   20                       -0.023207   \n",
       "16                   19                       -0.029846   \n",
       "17                   18                       -0.041572   \n",
       "18                   17                       -0.067860   \n",
       "19                   16                       -0.180098   \n",
       "\n",
       "    split1_test_Adjusted R-squared  split2_test_Adjusted R-squared  \\\n",
       "0                        -0.837254                       -0.847481   \n",
       "1                        -0.842495                       -0.851388   \n",
       "2                        -0.847551                       -0.853727   \n",
       "3                        -0.852125                       -0.852133   \n",
       "4                        -0.854427                       -0.836400   \n",
       "..                             ...                             ...   \n",
       "15                       -0.017943                       -0.023292   \n",
       "16                       -0.023889                       -0.029567   \n",
       "17                       -0.034400                       -0.040649   \n",
       "18                       -0.058007                       -0.065490   \n",
       "19                       -0.159470                       -0.171479   \n",
       "\n",
       "    split3_test_Adjusted R-squared  split4_test_Adjusted R-squared  \\\n",
       "0                        -0.886263                       -0.746113   \n",
       "1                        -0.889869                       -0.742379   \n",
       "2                        -0.892721                       -0.736115   \n",
       "3                        -0.894047                       -0.725042   \n",
       "4                        -0.891065                       -0.701880   \n",
       "..                             ...                             ...   \n",
       "15                       -0.007427                       -0.024914   \n",
       "16                       -0.014642                       -0.031557   \n",
       "17                       -0.027372                       -0.043275   \n",
       "18                       -0.055863                       -0.069490   \n",
       "19                       -0.176669                       -0.180424   \n",
       "\n",
       "    mean_test_Adjusted R-squared  std_test_Adjusted R-squared  \\\n",
       "0                      -0.841870                     0.052402   \n",
       "1                      -0.844867                     0.055537   \n",
       "2                      -0.846821                     0.059463   \n",
       "3                      -0.846456                     0.064767   \n",
       "4                      -0.838619                     0.073078   \n",
       "..                           ...                          ...   \n",
       "15                     -0.019357                     0.006411   \n",
       "16                     -0.025900                     0.006194   \n",
       "17                     -0.037454                     0.005866   \n",
       "18                     -0.063342                     0.005426   \n",
       "19                     -0.173628                     0.007776   \n",
       "\n",
       "    rank_test_Adjusted R-squared  split0_test_Mape  split1_test_Mape  \\\n",
       "0                             17         -9.171965        -11.101695   \n",
       "1                             18         -9.093959        -10.979831   \n",
       "2                             20         -9.056415        -10.878045   \n",
       "3                             19         -9.076683        -10.778818   \n",
       "4                             15         -9.479717        -10.862342   \n",
       "..                           ...               ...               ...   \n",
       "15                             1        -33.199112        -37.229292   \n",
       "16                             2        -33.062336        -37.087716   \n",
       "17                             3        -32.819572        -36.836136   \n",
       "18                             4        -32.269221        -36.271314   \n",
       "19                             5        -29.828901        -33.834230   \n",
       "\n",
       "    split2_test_Mape  split3_test_Mape  split4_test_Mape  mean_test_Mape  \\\n",
       "0         -10.253828         -9.672421        -10.671097      -10.174202   \n",
       "1         -10.140777         -9.445774        -10.558913      -10.043851   \n",
       "2         -10.045838         -9.320131        -10.455631       -9.951212   \n",
       "3         -10.007080         -9.386946        -10.484789       -9.946863   \n",
       "4         -10.197964         -9.861464        -10.980818      -10.276461   \n",
       "..               ...               ...               ...             ...   \n",
       "15        -33.860348        -35.039317        -32.598478      -34.385309   \n",
       "16        -33.728662        -34.899547        -32.472953      -34.250243   \n",
       "17        -33.494709        -34.653019        -32.250895      -34.010866   \n",
       "18        -32.966001        -34.096200        -31.747684      -33.470084   \n",
       "19        -30.628189        -31.648796        -29.520628      -31.092149   \n",
       "\n",
       "    std_test_Mape  rank_test_Mape  \n",
       "0        0.688440               4  \n",
       "1        0.694368               3  \n",
       "2        0.681372               2  \n",
       "3        0.641227               1  \n",
       "4        0.574902               6  \n",
       "..            ...             ...  \n",
       "15       1.636544              20  \n",
       "16       1.631856              19  \n",
       "17       1.623429              18  \n",
       "18       1.606347              17  \n",
       "19       1.556252              16  \n",
       "\n",
       "[20 rows x 31 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option(\"display.max_rows\", 10)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "gridSearch_results = pd.DataFrame(gridSearch.cv_results_)\n",
    "gridSearch_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_Mape</th>\n",
       "      <th>mean_test_R-squared</th>\n",
       "      <th>mean_test_Adjusted R-squared</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-10.174202</td>\n",
       "      <td>0.841870</td>\n",
       "      <td>-0.841870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-10.043851</td>\n",
       "      <td>0.844867</td>\n",
       "      <td>-0.844867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-9.951212</td>\n",
       "      <td>0.846821</td>\n",
       "      <td>-0.846821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-9.946863</td>\n",
       "      <td>0.846456</td>\n",
       "      <td>-0.846456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-10.276461</td>\n",
       "      <td>0.838619</td>\n",
       "      <td>-0.838619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-34.385309</td>\n",
       "      <td>0.019357</td>\n",
       "      <td>-0.019357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-34.250243</td>\n",
       "      <td>0.025900</td>\n",
       "      <td>-0.025900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-34.010866</td>\n",
       "      <td>0.037454</td>\n",
       "      <td>-0.037454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-33.470084</td>\n",
       "      <td>0.063342</td>\n",
       "      <td>-0.063342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-31.092149</td>\n",
       "      <td>0.173628</td>\n",
       "      <td>-0.173628</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_test_Mape  mean_test_R-squared  mean_test_Adjusted R-squared\n",
       "0       -10.174202             0.841870                     -0.841870\n",
       "1       -10.043851             0.844867                     -0.844867\n",
       "2        -9.951212             0.846821                     -0.846821\n",
       "3        -9.946863             0.846456                     -0.846456\n",
       "4       -10.276461             0.838619                     -0.838619\n",
       "..             ...                  ...                           ...\n",
       "15      -34.385309             0.019357                     -0.019357\n",
       "16      -34.250243             0.025900                     -0.025900\n",
       "17      -34.010866             0.037454                     -0.037454\n",
       "18      -33.470084             0.063342                     -0.063342\n",
       "19      -31.092149             0.173628                     -0.173628\n",
       "\n",
       "[20 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridSearch_results[\n",
    "    [\"mean_test_Mape\", \"mean_test_R-squared\", \"mean_test_Adjusted R-squared\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.94686309891823"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-gridSearch.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.97860524e+03,  6.19033685e+02,  3.43673727e+03,  8.02797138e+03,\n",
       "        3.05406278e+03,  2.01298660e+03,  2.16727619e+03,  2.74465986e+03,\n",
       "        3.44832290e+03, -5.27746685e+02,  3.27618488e+03, -8.14529608e+02,\n",
       "        3.32525092e+03,  2.04281562e+03,  3.80899125e+03, -2.18134328e+02,\n",
       "        5.32170788e+02, -3.24024910e+02,  3.85416787e+03,  1.27628510e+03,\n",
       "        5.74975410e+03,  3.94521943e+03, -1.75299607e+02,  7.67089061e+03,\n",
       "        2.32841534e+03, -2.58771980e+02,  2.24597904e+03,  1.64404174e+03,\n",
       "       -1.31680845e+02, -1.32833231e+03,  4.06376566e+03,  4.06174697e+03,\n",
       "        2.18369929e+03,  2.45665930e+03, -8.91111102e+02,  1.46885487e+03,\n",
       "        4.04643890e+03,  4.36757430e+03,  4.78693573e+01, -1.09561372e+02,\n",
       "        2.48966763e+03,  1.38955138e+03,  6.49954743e+02,  1.01719618e+03,\n",
       "        1.16195180e+03,  6.03552472e+02, -4.41014700e+02,  3.77819953e+02,\n",
       "       -1.32589318e+02, -2.84213518e+01, -2.00834124e+03,  7.30953419e+02,\n",
       "        2.92877517e+02,  1.05143020e+03, -1.25103357e+03, -5.57214200e+02,\n",
       "        5.57213268e+02,  8.26842308e+01, -2.36073052e+02,  1.35721390e+02,\n",
       "       -1.14483325e+02,  1.12836212e+03, -1.78419872e+02, -2.33112058e+02,\n",
       "       -9.98212946e+02,  1.18928600e+03,  5.70287303e+01, -6.56703263e+01,\n",
       "        5.09945488e+02, -5.09943634e+02, -2.18282904e+01,  1.65212462e+03,\n",
       "       -9.82974016e+02, -5.79000833e+02, -4.15578622e+02, -5.22444328e+02,\n",
       "        9.35377245e+02, -7.92565103e+02, -5.93833556e+02,  2.52468064e+01,\n",
       "        4.28705743e+02,  9.16822613e+02,  2.38637661e+02, -1.46937778e+03,\n",
       "        2.91146273e+03, -2.21419698e+03, -1.80303615e+03, -4.40828119e+02,\n",
       "       -1.50107253e+03, -1.25452754e+03, -2.07129696e+03,  2.95723760e+02,\n",
       "       -1.22808674e+03,  3.79963803e+03,  5.42398994e+03, -1.05460888e+03,\n",
       "       -3.17665562e+02, -5.66298566e+02, -1.15595870e+02,  1.13068577e+03,\n",
       "        3.47268036e+03,  2.49207713e+02,  1.28683412e+03, -1.09935466e+03,\n",
       "       -1.21957585e+03,  1.49475565e+03,  2.71563276e+02, -8.88785585e+01,\n",
       "       -1.11318448e+03,  2.57218537e+02, -3.51776518e+02,  4.45080351e+02,\n",
       "        1.17972933e+02,  3.49163504e+02,  6.72083935e+02,  1.66570934e+03,\n",
       "       -3.84886310e+03, -5.92113368e+02,  1.79986125e+02,  3.93585661e+02,\n",
       "        2.01900330e+03,  1.03855812e+02, -1.82699386e+02, -1.69448308e+03,\n",
       "       -1.64808190e+03,  4.97739602e+02, -7.91086226e+00, -5.20483729e+02,\n",
       "       -3.26367601e+02,  5.79848224e+01,  7.21200517e+02, -6.75472964e+02,\n",
       "       -4.77920030e+02,  5.53257068e+02, -1.22118819e+03,  1.09509748e+02,\n",
       "        1.01141386e+03,  1.75194352e+02,  7.68954012e+02, -7.93872998e+03,\n",
       "        7.58721641e+02,  9.91764276e+02,  1.24341916e+02, -4.49447913e+00,\n",
       "       -6.43416483e+01,  2.10898099e+02,  1.43553535e+03,  1.48746434e+01,\n",
       "        4.85834686e+01, -2.08670360e+02,  2.41399096e+03, -5.00809983e+01,\n",
       "        8.47869588e+02, -1.15613811e+03, -6.21941298e+01,  3.48167070e+02,\n",
       "       -1.39500628e+02,  3.61695793e+02,  5.17088167e+02,  2.64577190e+02,\n",
       "       -1.43644751e+03,  1.40092691e+02, -1.15365216e+02,  1.59577265e+01,\n",
       "       -1.06083850e+02, -4.17798817e+00, -5.00806478e+01,  1.69567011e+03,\n",
       "       -8.71883383e+02,  2.14820591e+02,  1.57947294e+02,  3.14556778e+00,\n",
       "       -8.14852524e+02, -3.07684003e+02, -6.69931566e+02,  4.70947812e+02,\n",
       "        5.81115053e+02, -9.69779516e+02, -9.06888968e+02, -8.78954348e+02,\n",
       "        1.86279560e+02, -1.65442326e+02,  5.31726317e+02, -1.19505814e+03,\n",
       "       -5.74409923e+02,  1.07906907e+03,  1.04591135e+03, -1.08525037e+01,\n",
       "       -5.21093988e+02,  1.03001206e+02, -2.87270348e+02,  4.92936716e+02,\n",
       "       -1.63500529e+00, -6.98534867e+02,  2.11742972e+02, -2.54008019e+02,\n",
       "        2.54015210e+02,  5.48681261e+01,  2.52596154e+02, -2.78568669e+01,\n",
       "        5.03784974e+02,  1.13287661e+02, -3.03773526e+02, -5.68275165e+02,\n",
       "       -1.11466334e+03, -4.07188156e+02, -5.81302687e+02, -8.51576201e+02,\n",
       "       -8.46196782e+02,  1.48302445e+03,  9.45089673e+02, -1.30088987e+03,\n",
       "       -5.54864544e+01,  3.37437727e+01,  9.71049218e+02, -1.94623580e+02,\n",
       "       -7.22748637e+02, -9.58068581e+01, -3.83223634e+02,  2.82836881e+02,\n",
       "        3.19163774e+02, -4.34930643e+02, -9.85639332e+01, -1.61067165e+01,\n",
       "       -1.84326883e+02,  4.46204116e+01, -2.95572191e+02,  3.02385582e+02,\n",
       "       -2.92062247e+00, -3.09804299e+02, -6.18309007e+02,  8.30344502e+02,\n",
       "        8.06081533e+02,  3.20879364e+02, -3.57965306e+02, -1.98013926e+02,\n",
       "        1.79059724e+03,  1.23350727e+02, -1.35921660e+03, -1.56113433e+03,\n",
       "        1.54040403e+02,  6.17228467e+02, -8.05628222e+02,  1.17018428e+02,\n",
       "        1.38456621e+03])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridSearch.best_estimator_.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the coefficients of the best model\n",
    "coefficients = gridSearch.best_estimator_.coef_\n",
    "\n",
    "# Get the feature names\n",
    "feature_names = X_dummies.columns\n",
    "\n",
    "# Create a DataFrame to display the coefficients and corresponding feature names\n",
    "coeff_df = pd.DataFrame(\n",
    "    {\"Feature\": feature_names, \"Coefficient\": coefficients}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OverallQual</td>\n",
       "      <td>8027.971379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>GrLivArea</td>\n",
       "      <td>7670.890607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1stFlrSF</td>\n",
       "      <td>5749.754099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Neighborhood_NridgHt</td>\n",
       "      <td>5423.989944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>GarageArea</td>\n",
       "      <td>4367.574304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>KitchenQual</td>\n",
       "      <td>4063.765664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>TotRmsAbvGrd</td>\n",
       "      <td>4061.746969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>GarageCars</td>\n",
       "      <td>4046.438901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2ndFlrSF</td>\n",
       "      <td>3945.219427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>TotalBsmtSF</td>\n",
       "      <td>3854.167866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>BsmtFinSF1</td>\n",
       "      <td>3808.991246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>Neighborhood_NoRidge</td>\n",
       "      <td>3799.638030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Neighborhood_StoneBr</td>\n",
       "      <td>3472.680362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ExterQual</td>\n",
       "      <td>3448.322896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LotArea</td>\n",
       "      <td>3436.737271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>BsmtExposure</td>\n",
       "      <td>3325.250919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>BsmtQual</td>\n",
       "      <td>3276.184880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OverallCond</td>\n",
       "      <td>3054.062777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Neighborhood_Crawfor</td>\n",
       "      <td>2911.462733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MasVnrArea</td>\n",
       "      <td>2744.659865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>WoodDeckSF</td>\n",
       "      <td>2489.667634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>FireplaceQu</td>\n",
       "      <td>2456.659296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>Exterior1st_BrkFace</td>\n",
       "      <td>2413.990964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>BsmtFullBath</td>\n",
       "      <td>2328.415344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>FullBath</td>\n",
       "      <td>2245.979035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Fireplaces</td>\n",
       "      <td>2183.699294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>YearRemodAdd</td>\n",
       "      <td>2167.276189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>BsmtFinType1</td>\n",
       "      <td>2042.815620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>BldgType_1Fam</td>\n",
       "      <td>2019.003300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>YearBuilt</td>\n",
       "      <td>2012.986604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>SaleType_New</td>\n",
       "      <td>1790.597235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>Exterior2nd_CmentBd</td>\n",
       "      <td>1695.670110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>Condition2_PosA</td>\n",
       "      <td>1665.709341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>LotConfig_CulDSac</td>\n",
       "      <td>1652.124621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>HalfBath</td>\n",
       "      <td>1644.041739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>Condition1_Norm</td>\n",
       "      <td>1494.755655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>Functional_Typ</td>\n",
       "      <td>1483.024450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>GarageFinish</td>\n",
       "      <td>1468.854871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>RoofMatl_WdShngl</td>\n",
       "      <td>1435.535347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>OpenPorchSF</td>\n",
       "      <td>1389.551377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>SaleCondition_Partial</td>\n",
       "      <td>1384.566212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>Neighborhood_Veenker</td>\n",
       "      <td>1286.834120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>HeatingQC</td>\n",
       "      <td>1276.285105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>LandContour_HLS</td>\n",
       "      <td>1189.286005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>ScreenPorch</td>\n",
       "      <td>1161.951798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Neighborhood_Somerst</td>\n",
       "      <td>1130.685771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>LotShape_IR2</td>\n",
       "      <td>1128.362120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>Foundation_PConc</td>\n",
       "      <td>1079.069066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>MSZoning_RL</td>\n",
       "      <td>1051.430200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>Foundation_Slab</td>\n",
       "      <td>1045.911353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>3SsnPorch</td>\n",
       "      <td>1017.196178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>RoofStyle_Hip</td>\n",
       "      <td>1011.413859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>RoofMatl_Membran</td>\n",
       "      <td>991.764276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>GarageType_BuiltIn</td>\n",
       "      <td>971.049218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>GarageType_0</td>\n",
       "      <td>945.089673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>LandSlope_Mod</td>\n",
       "      <td>935.377245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Neighborhood_BrkSide</td>\n",
       "      <td>916.822613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>Exterior1st_CemntBd</td>\n",
       "      <td>847.869588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>SaleType_CWD</td>\n",
       "      <td>830.344502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>SaleType_Con</td>\n",
       "      <td>806.081533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>RoofStyle_Shed</td>\n",
       "      <td>768.954012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>RoofMatl_CompShg</td>\n",
       "      <td>758.721641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>MSZoning_FV</td>\n",
       "      <td>730.953419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>HouseStyle_2Story</td>\n",
       "      <td>721.200517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>Condition2_Norm</td>\n",
       "      <td>672.083935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>EnclosedPorch</td>\n",
       "      <td>649.954743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LotFrontage</td>\n",
       "      <td>619.033685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>SaleCondition_Alloca</td>\n",
       "      <td>617.228467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>PoolArea</td>\n",
       "      <td>603.552472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>Exterior2nd_Wd Sdng</td>\n",
       "      <td>581.115053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Street_Pave</td>\n",
       "      <td>557.213268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>RoofStyle_Flat</td>\n",
       "      <td>553.257068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>BsmtFinSF2</td>\n",
       "      <td>532.170788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>MasVnrType_Stone</td>\n",
       "      <td>531.726317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>Exterior1st_Stucco</td>\n",
       "      <td>517.088167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Utilities_AllPub</td>\n",
       "      <td>509.945488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>Electrical_FuseP</td>\n",
       "      <td>503.784974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>HouseStyle_1.5Fin</td>\n",
       "      <td>497.739602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>Heating_GasW</td>\n",
       "      <td>492.936716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>Exterior2nd_VinylSd</td>\n",
       "      <td>470.947812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>Condition1_RRNn</td>\n",
       "      <td>445.080351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Neighborhood_BrDale</td>\n",
       "      <td>428.705743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>Condition2_RRNn</td>\n",
       "      <td>393.585661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>MiscVal</td>\n",
       "      <td>377.819953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>Exterior1st_Stone</td>\n",
       "      <td>361.695793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>Condition2_Feedr</td>\n",
       "      <td>349.163504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>Exterior1st_MetalSd</td>\n",
       "      <td>348.167070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>SaleType_ConLD</td>\n",
       "      <td>320.879364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>Fence_0</td>\n",
       "      <td>319.163774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>MiscFeature_Othr</td>\n",
       "      <td>302.385582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Neighborhood_NPkVill</td>\n",
       "      <td>295.723760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>MSZoning_RH</td>\n",
       "      <td>292.877517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>PavedDrive_Y</td>\n",
       "      <td>282.836881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>Condition1_PosA</td>\n",
       "      <td>271.563276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>Exterior1st_VinylSd</td>\n",
       "      <td>264.577190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>Condition1_RRAn</td>\n",
       "      <td>257.218537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>CentralAir_Y</td>\n",
       "      <td>254.015210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>Electrical_FuseA</td>\n",
       "      <td>252.596154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Neighborhood_Timber</td>\n",
       "      <td>249.207713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Neighborhood_ClearCr</td>\n",
       "      <td>238.637661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>Exterior2nd_ImStucc</td>\n",
       "      <td>214.820591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>Heating_Wall</td>\n",
       "      <td>211.742972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>RoofMatl_WdShake</td>\n",
       "      <td>210.898099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>MasVnrType_BrkFace</td>\n",
       "      <td>186.279560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>Condition2_RRAn</td>\n",
       "      <td>179.986125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>RoofStyle_Mansard</td>\n",
       "      <td>175.194352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>Exterior2nd_MetalSd</td>\n",
       "      <td>157.947294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>SaleCondition_AdjLand</td>\n",
       "      <td>154.040403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>Exterior1st_WdShing</td>\n",
       "      <td>140.092691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Alley_Pave</td>\n",
       "      <td>135.721390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>RoofMatl_Metal</td>\n",
       "      <td>124.341916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>SaleType_Oth</td>\n",
       "      <td>123.350727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>Condition2_Artery</td>\n",
       "      <td>117.972933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>SaleCondition_Normal</td>\n",
       "      <td>117.018428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>Electrical_Mix</td>\n",
       "      <td>113.287661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>RoofStyle_Gambrel</td>\n",
       "      <td>109.509748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>BldgType_2fmCon</td>\n",
       "      <td>103.855812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>Heating_Floor</td>\n",
       "      <td>103.001206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Alley_0</td>\n",
       "      <td>82.684231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>HouseStyle_2.5Unf</td>\n",
       "      <td>57.984822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>LandContour_Low</td>\n",
       "      <td>57.028730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>Electrical_0</td>\n",
       "      <td>54.868126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>Exterior1st_AsphShn</td>\n",
       "      <td>48.583469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>GarageQual</td>\n",
       "      <td>47.869357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>MiscFeature_0</td>\n",
       "      <td>44.620412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>GarageType_Basment</td>\n",
       "      <td>33.743773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Neighborhood_Blueste</td>\n",
       "      <td>25.246806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>Exterior2nd_AsphShn</td>\n",
       "      <td>15.957726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>Exterior1st_AsbShng</td>\n",
       "      <td>14.874643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>Exterior2nd_Other</td>\n",
       "      <td>3.145568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>Heating_Grav</td>\n",
       "      <td>-1.635005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>MiscFeature_Shed</td>\n",
       "      <td>-2.920622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>Exterior2nd_BrkFace</td>\n",
       "      <td>-4.177988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>RoofMatl_Roll</td>\n",
       "      <td>-4.494479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>HouseStyle_1.5Unf</td>\n",
       "      <td>-7.910862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>Foundation_Stone</td>\n",
       "      <td>-10.852504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>Fence_MnPrv</td>\n",
       "      <td>-16.106717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>LotConfig_Corner</td>\n",
       "      <td>-21.828290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>Electrical_FuseF</td>\n",
       "      <td>-27.856867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>YrSold</td>\n",
       "      <td>-28.421352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>Exterior2nd_CBlock</td>\n",
       "      <td>-50.080648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>Exterior1st_CBlock</td>\n",
       "      <td>-50.080998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>GarageType_Attchd</td>\n",
       "      <td>-55.486454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>Exterior1st_ImStucc</td>\n",
       "      <td>-62.194130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>RoofMatl_Tar&amp;Grv</td>\n",
       "      <td>-64.341648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>LandContour_Lvl</td>\n",
       "      <td>-65.670326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>Condition1_PosN</td>\n",
       "      <td>-88.878559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>PavedDrive_N</td>\n",
       "      <td>-95.806858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>Fence_GdWo</td>\n",
       "      <td>-98.563933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>Exterior2nd_Brk Cmn</td>\n",
       "      <td>-106.083850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>GarageCond</td>\n",
       "      <td>-109.561372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>LotShape_IR1</td>\n",
       "      <td>-114.483325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>Exterior2nd_AsbShng</td>\n",
       "      <td>-115.365216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Neighborhood_SawyerW</td>\n",
       "      <td>-115.595870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>BedroomAbvGr</td>\n",
       "      <td>-131.680845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>MoSold</td>\n",
       "      <td>-132.589318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>Exterior1st_Plywood</td>\n",
       "      <td>-139.500628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>MasVnrType_None</td>\n",
       "      <td>-165.442326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>LowQualFinSF</td>\n",
       "      <td>-175.299607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>LotShape_IR3</td>\n",
       "      <td>-178.419872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>BldgType_Duplex</td>\n",
       "      <td>-182.699386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>Fence_MnWw</td>\n",
       "      <td>-184.326883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>GarageType_CarPort</td>\n",
       "      <td>-194.623580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>SaleType_ConLw</td>\n",
       "      <td>-198.013926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>Exterior1st_BrkComm</td>\n",
       "      <td>-208.670360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>BsmtFinType2</td>\n",
       "      <td>-218.134328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>LotShape_Reg</td>\n",
       "      <td>-233.112058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Alley_Grvl</td>\n",
       "      <td>-236.073052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>CentralAir_N</td>\n",
       "      <td>-254.008019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>BsmtHalfBath</td>\n",
       "      <td>-258.771980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>Heating_GasA</td>\n",
       "      <td>-287.270348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>MiscFeature_Gar2</td>\n",
       "      <td>-295.572191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>Electrical_SBrkr</td>\n",
       "      <td>-303.773526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>Exterior2nd_Stone</td>\n",
       "      <td>-307.684003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>MiscFeature_TenC</td>\n",
       "      <td>-309.804299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Neighborhood_SWISU</td>\n",
       "      <td>-317.665562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>BsmtUnfSF</td>\n",
       "      <td>-324.024910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>HouseStyle_2.5Fin</td>\n",
       "      <td>-326.367601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>Condition1_RRNe</td>\n",
       "      <td>-351.776518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>SaleType_ConLI</td>\n",
       "      <td>-357.965306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>PavedDrive_P</td>\n",
       "      <td>-383.223634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>Functional_Min1</td>\n",
       "      <td>-407.188156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>LotConfig_Inside</td>\n",
       "      <td>-415.578622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>Fence_GdPrv</td>\n",
       "      <td>-434.930643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Neighborhood_IDOTRR</td>\n",
       "      <td>-440.828119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>PoolQC</td>\n",
       "      <td>-441.014700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>HouseStyle_SLvl</td>\n",
       "      <td>-477.920030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>Utilities_NoSeWa</td>\n",
       "      <td>-509.943634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>HouseStyle_1Story</td>\n",
       "      <td>-520.483729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>Foundation_Wood</td>\n",
       "      <td>-521.093988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>LandSlope_Gtl</td>\n",
       "      <td>-522.444328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ExterCond</td>\n",
       "      <td>-527.746685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Street_Grvl</td>\n",
       "      <td>-557.214200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Neighborhood_Sawyer</td>\n",
       "      <td>-566.298566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>Functional_Maj1</td>\n",
       "      <td>-568.275165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>Foundation_CBlock</td>\n",
       "      <td>-574.409923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>LotConfig_FR3</td>\n",
       "      <td>-579.000833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>Functional_Min2</td>\n",
       "      <td>-581.302687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>Condition2_RRAe</td>\n",
       "      <td>-592.113368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Neighborhood_Blmngtn</td>\n",
       "      <td>-593.833556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>SaleType_COD</td>\n",
       "      <td>-618.309007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>Exterior2nd_Stucco</td>\n",
       "      <td>-669.931566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>HouseStyle_SFoyer</td>\n",
       "      <td>-675.472964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>Heating_OthW</td>\n",
       "      <td>-698.534867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>GarageType_Detchd</td>\n",
       "      <td>-722.748637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>LandSlope_Sev</td>\n",
       "      <td>-792.565103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>SaleCondition_Family</td>\n",
       "      <td>-805.628222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>BsmtCond</td>\n",
       "      <td>-814.529608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>Exterior2nd_Plywood</td>\n",
       "      <td>-814.852524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>Functional_Sev</td>\n",
       "      <td>-846.196782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>Functional_Mod</td>\n",
       "      <td>-851.576201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>Exterior2nd_HdBoard</td>\n",
       "      <td>-871.883383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>MasVnrType_BrkCmn</td>\n",
       "      <td>-878.954348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>GarageYrBlt</td>\n",
       "      <td>-891.111102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>MasVnrType_0</td>\n",
       "      <td>-906.888968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>Exterior2nd_Wd Shng</td>\n",
       "      <td>-969.779516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>LotConfig_FR2</td>\n",
       "      <td>-982.974016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>LandContour_Bnk</td>\n",
       "      <td>-998.212946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Neighborhood_OldTown</td>\n",
       "      <td>-1054.608881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>Condition1_Artery</td>\n",
       "      <td>-1099.354658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>Condition1_RRAe</td>\n",
       "      <td>-1113.184481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>Functional_Maj2</td>\n",
       "      <td>-1114.663343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>Exterior1st_HdBoard</td>\n",
       "      <td>-1156.138111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>Foundation_BrkTil</td>\n",
       "      <td>-1195.058140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>Condition1_Feedr</td>\n",
       "      <td>-1219.575854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>RoofStyle_Gable</td>\n",
       "      <td>-1221.188194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Neighborhood_NWAmes</td>\n",
       "      <td>-1228.086738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>MSZoning_RM</td>\n",
       "      <td>-1251.033574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Neighborhood_Mitchel</td>\n",
       "      <td>-1254.527538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>GarageType_2Types</td>\n",
       "      <td>-1300.889869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>KitchenAbvGr</td>\n",
       "      <td>-1328.332312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>SaleType_WD</td>\n",
       "      <td>-1359.216605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>Exterior1st_Wd Sdng</td>\n",
       "      <td>-1436.447507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Neighborhood_CollgCr</td>\n",
       "      <td>-1469.377781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Neighborhood_MeadowV</td>\n",
       "      <td>-1501.072535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>SaleCondition_Abnorml</td>\n",
       "      <td>-1561.134332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>BldgType_TwnhsE</td>\n",
       "      <td>-1648.081902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>BldgType_Twnhs</td>\n",
       "      <td>-1694.483081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Neighborhood_Gilbert</td>\n",
       "      <td>-1803.036151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MSSubClass</td>\n",
       "      <td>-1978.605237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>MSZoning_C (all)</td>\n",
       "      <td>-2008.341245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Neighborhood_NAmes</td>\n",
       "      <td>-2071.296964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Neighborhood_Edwards</td>\n",
       "      <td>-2214.196979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>Condition2_PosN</td>\n",
       "      <td>-3848.863097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>RoofMatl_ClyTile</td>\n",
       "      <td>-7938.729980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Feature  Coefficient\n",
       "3              OverallQual  8027.971379\n",
       "23               GrLivArea  7670.890607\n",
       "20                1stFlrSF  5749.754099\n",
       "94    Neighborhood_NridgHt  5423.989944\n",
       "37              GarageArea  4367.574304\n",
       "30             KitchenQual  4063.765664\n",
       "31            TotRmsAbvGrd  4061.746969\n",
       "36              GarageCars  4046.438901\n",
       "21                2ndFlrSF  3945.219427\n",
       "18             TotalBsmtSF  3854.167866\n",
       "14              BsmtFinSF1  3808.991246\n",
       "93    Neighborhood_NoRidge  3799.638030\n",
       "100   Neighborhood_StoneBr  3472.680362\n",
       "8                ExterQual  3448.322896\n",
       "2                  LotArea  3436.737271\n",
       "12            BsmtExposure  3325.250919\n",
       "10                BsmtQual  3276.184880\n",
       "4              OverallCond  3054.062777\n",
       "84    Neighborhood_Crawfor  2911.462733\n",
       "7               MasVnrArea  2744.659865\n",
       "40              WoodDeckSF  2489.667634\n",
       "33             FireplaceQu  2456.659296\n",
       "150    Exterior1st_BrkFace  2413.990964\n",
       "24            BsmtFullBath  2328.415344\n",
       "26                FullBath  2245.979035\n",
       "32              Fireplaces  2183.699294\n",
       "6             YearRemodAdd  2167.276189\n",
       "13            BsmtFinType1  2042.815620\n",
       "120          BldgType_1Fam  2019.003300\n",
       "5                YearBuilt  2012.986604\n",
       "236           SaleType_New  1790.597235\n",
       "167    Exterior2nd_CmentBd  1695.670110\n",
       "115        Condition2_PosA  1665.709341\n",
       "71       LotConfig_CulDSac  1652.124621\n",
       "27                HalfBath  1644.041739\n",
       "105        Condition1_Norm  1494.755655\n",
       "209         Functional_Typ  1483.024450\n",
       "35            GarageFinish  1468.854871\n",
       "146       RoofMatl_WdShngl  1435.535347\n",
       "41             OpenPorchSF  1389.551377\n",
       "244  SaleCondition_Partial  1384.566212\n",
       "102   Neighborhood_Veenker  1286.834120\n",
       "19               HeatingQC  1276.285105\n",
       "65         LandContour_HLS  1189.286005\n",
       "44             ScreenPorch  1161.951798\n",
       "99    Neighborhood_Somerst  1130.685771\n",
       "61            LotShape_IR2  1128.362120\n",
       "185       Foundation_PConc  1079.069066\n",
       "53             MSZoning_RL  1051.430200\n",
       "186        Foundation_Slab  1045.911353\n",
       "43               3SsnPorch  1017.196178\n",
       "136          RoofStyle_Hip  1011.413859\n",
       "141       RoofMatl_Membran   991.764276\n",
       "214     GarageType_BuiltIn   971.049218\n",
       "210           GarageType_0   945.089673\n",
       "76           LandSlope_Mod   935.377245\n",
       "81    Neighborhood_BrkSide   916.822613\n",
       "152    Exterior1st_CemntBd   847.869588\n",
       "231           SaleType_CWD   830.344502\n",
       "232           SaleType_Con   806.081533\n",
       "138         RoofStyle_Shed   768.954012\n",
       "140       RoofMatl_CompShg   758.721641\n",
       "51             MSZoning_FV   730.953419\n",
       "130      HouseStyle_2Story   721.200517\n",
       "114        Condition2_Norm   672.083935\n",
       "42           EnclosedPorch   649.954743\n",
       "1              LotFrontage   619.033685\n",
       "241   SaleCondition_Alloca   617.228467\n",
       "45                PoolArea   603.552472\n",
       "176    Exterior2nd_Wd Sdng   581.115053\n",
       "56             Street_Pave   557.213268\n",
       "133         RoofStyle_Flat   553.257068\n",
       "16              BsmtFinSF2   532.170788\n",
       "182       MasVnrType_Stone   531.726317\n",
       "158     Exterior1st_Stucco   517.088167\n",
       "68        Utilities_AllPub   509.945488\n",
       "200       Electrical_FuseP   503.784974\n",
       "125      HouseStyle_1.5Fin   497.739602\n",
       "191           Heating_GasW   492.936716\n",
       "175    Exterior2nd_VinylSd   470.947812\n",
       "111        Condition1_RRNn   445.080351\n",
       "80     Neighborhood_BrDale   428.705743\n",
       "119        Condition2_RRNn   393.585661\n",
       "47                 MiscVal   377.819953\n",
       "157      Exterior1st_Stone   361.695793\n",
       "113       Condition2_Feedr   349.163504\n",
       "155    Exterior1st_MetalSd   348.167070\n",
       "233         SaleType_ConLD   320.879364\n",
       "220                Fence_0   319.163774\n",
       "227       MiscFeature_Othr   302.385582\n",
       "91    Neighborhood_NPkVill   295.723760\n",
       "52             MSZoning_RH   292.877517\n",
       "219           PavedDrive_Y   282.836881\n",
       "106        Condition1_PosA   271.563276\n",
       "159    Exterior1st_VinylSd   264.577190\n",
       "109        Condition1_RRAn   257.218537\n",
       "196           CentralAir_Y   254.015210\n",
       "198       Electrical_FuseA   252.596154\n",
       "101    Neighborhood_Timber   249.207713\n",
       "82    Neighborhood_ClearCr   238.637661\n",
       "169    Exterior2nd_ImStucc   214.820591\n",
       "194           Heating_Wall   211.742972\n",
       "145       RoofMatl_WdShake   210.898099\n",
       "180     MasVnrType_BrkFace   186.279560\n",
       "118        Condition2_RRAn   179.986125\n",
       "137      RoofStyle_Mansard   175.194352\n",
       "170    Exterior2nd_MetalSd   157.947294\n",
       "240  SaleCondition_AdjLand   154.040403\n",
       "161    Exterior1st_WdShing   140.092691\n",
       "59              Alley_Pave   135.721390\n",
       "142         RoofMatl_Metal   124.341916\n",
       "237           SaleType_Oth   123.350727\n",
       "112      Condition2_Artery   117.972933\n",
       "243   SaleCondition_Normal   117.018428\n",
       "201         Electrical_Mix   113.287661\n",
       "135      RoofStyle_Gambrel   109.509748\n",
       "121        BldgType_2fmCon   103.855812\n",
       "189          Heating_Floor   103.001206\n",
       "57                 Alley_0    82.684231\n",
       "129      HouseStyle_2.5Unf    57.984822\n",
       "66         LandContour_Low    57.028730\n",
       "197           Electrical_0    54.868126\n",
       "148    Exterior1st_AsphShn    48.583469\n",
       "38              GarageQual    47.869357\n",
       "225          MiscFeature_0    44.620412\n",
       "213     GarageType_Basment    33.743773\n",
       "79    Neighborhood_Blueste    25.246806\n",
       "163    Exterior2nd_AsphShn    15.957726\n",
       "147    Exterior1st_AsbShng    14.874643\n",
       "171      Exterior2nd_Other     3.145568\n",
       "192           Heating_Grav    -1.635005\n",
       "228       MiscFeature_Shed    -2.920622\n",
       "165    Exterior2nd_BrkFace    -4.177988\n",
       "143          RoofMatl_Roll    -4.494479\n",
       "126      HouseStyle_1.5Unf    -7.910862\n",
       "187       Foundation_Stone   -10.852504\n",
       "223            Fence_MnPrv   -16.106717\n",
       "70        LotConfig_Corner   -21.828290\n",
       "199       Electrical_FuseF   -27.856867\n",
       "49                  YrSold   -28.421352\n",
       "166     Exterior2nd_CBlock   -50.080648\n",
       "151     Exterior1st_CBlock   -50.080998\n",
       "212      GarageType_Attchd   -55.486454\n",
       "154    Exterior1st_ImStucc   -62.194130\n",
       "144       RoofMatl_Tar&Grv   -64.341648\n",
       "67         LandContour_Lvl   -65.670326\n",
       "107        Condition1_PosN   -88.878559\n",
       "217           PavedDrive_N   -95.806858\n",
       "222             Fence_GdWo   -98.563933\n",
       "164    Exterior2nd_Brk Cmn  -106.083850\n",
       "39              GarageCond  -109.561372\n",
       "60            LotShape_IR1  -114.483325\n",
       "162    Exterior2nd_AsbShng  -115.365216\n",
       "98    Neighborhood_SawyerW  -115.595870\n",
       "28            BedroomAbvGr  -131.680845\n",
       "48                  MoSold  -132.589318\n",
       "156    Exterior1st_Plywood  -139.500628\n",
       "181        MasVnrType_None  -165.442326\n",
       "22            LowQualFinSF  -175.299607\n",
       "62            LotShape_IR3  -178.419872\n",
       "122        BldgType_Duplex  -182.699386\n",
       "224             Fence_MnWw  -184.326883\n",
       "215     GarageType_CarPort  -194.623580\n",
       "235         SaleType_ConLw  -198.013926\n",
       "149    Exterior1st_BrkComm  -208.670360\n",
       "15            BsmtFinType2  -218.134328\n",
       "63            LotShape_Reg  -233.112058\n",
       "58              Alley_Grvl  -236.073052\n",
       "195           CentralAir_N  -254.008019\n",
       "25            BsmtHalfBath  -258.771980\n",
       "190           Heating_GasA  -287.270348\n",
       "226       MiscFeature_Gar2  -295.572191\n",
       "202       Electrical_SBrkr  -303.773526\n",
       "173      Exterior2nd_Stone  -307.684003\n",
       "229       MiscFeature_TenC  -309.804299\n",
       "96      Neighborhood_SWISU  -317.665562\n",
       "17               BsmtUnfSF  -324.024910\n",
       "128      HouseStyle_2.5Fin  -326.367601\n",
       "110        Condition1_RRNe  -351.776518\n",
       "234         SaleType_ConLI  -357.965306\n",
       "218           PavedDrive_P  -383.223634\n",
       "205        Functional_Min1  -407.188156\n",
       "74        LotConfig_Inside  -415.578622\n",
       "221            Fence_GdPrv  -434.930643\n",
       "87     Neighborhood_IDOTRR  -440.828119\n",
       "46                  PoolQC  -441.014700\n",
       "132        HouseStyle_SLvl  -477.920030\n",
       "69        Utilities_NoSeWa  -509.943634\n",
       "127      HouseStyle_1Story  -520.483729\n",
       "188        Foundation_Wood  -521.093988\n",
       "75           LandSlope_Gtl  -522.444328\n",
       "9                ExterCond  -527.746685\n",
       "55             Street_Grvl  -557.214200\n",
       "97     Neighborhood_Sawyer  -566.298566\n",
       "203        Functional_Maj1  -568.275165\n",
       "184      Foundation_CBlock  -574.409923\n",
       "73           LotConfig_FR3  -579.000833\n",
       "206        Functional_Min2  -581.302687\n",
       "117        Condition2_RRAe  -592.113368\n",
       "78    Neighborhood_Blmngtn  -593.833556\n",
       "230           SaleType_COD  -618.309007\n",
       "174     Exterior2nd_Stucco  -669.931566\n",
       "131      HouseStyle_SFoyer  -675.472964\n",
       "193           Heating_OthW  -698.534867\n",
       "216      GarageType_Detchd  -722.748637\n",
       "77           LandSlope_Sev  -792.565103\n",
       "242   SaleCondition_Family  -805.628222\n",
       "11                BsmtCond  -814.529608\n",
       "172    Exterior2nd_Plywood  -814.852524\n",
       "208         Functional_Sev  -846.196782\n",
       "207         Functional_Mod  -851.576201\n",
       "168    Exterior2nd_HdBoard  -871.883383\n",
       "179      MasVnrType_BrkCmn  -878.954348\n",
       "34             GarageYrBlt  -891.111102\n",
       "178           MasVnrType_0  -906.888968\n",
       "177    Exterior2nd_Wd Shng  -969.779516\n",
       "72           LotConfig_FR2  -982.974016\n",
       "64         LandContour_Bnk  -998.212946\n",
       "95    Neighborhood_OldTown -1054.608881\n",
       "103      Condition1_Artery -1099.354658\n",
       "108        Condition1_RRAe -1113.184481\n",
       "204        Functional_Maj2 -1114.663343\n",
       "153    Exterior1st_HdBoard -1156.138111\n",
       "183      Foundation_BrkTil -1195.058140\n",
       "104       Condition1_Feedr -1219.575854\n",
       "134        RoofStyle_Gable -1221.188194\n",
       "92     Neighborhood_NWAmes -1228.086738\n",
       "54             MSZoning_RM -1251.033574\n",
       "89    Neighborhood_Mitchel -1254.527538\n",
       "211      GarageType_2Types -1300.889869\n",
       "29            KitchenAbvGr -1328.332312\n",
       "238            SaleType_WD -1359.216605\n",
       "160    Exterior1st_Wd Sdng -1436.447507\n",
       "83    Neighborhood_CollgCr -1469.377781\n",
       "88    Neighborhood_MeadowV -1501.072535\n",
       "239  SaleCondition_Abnorml -1561.134332\n",
       "124        BldgType_TwnhsE -1648.081902\n",
       "123         BldgType_Twnhs -1694.483081\n",
       "86    Neighborhood_Gilbert -1803.036151\n",
       "0               MSSubClass -1978.605237\n",
       "50        MSZoning_C (all) -2008.341245\n",
       "90      Neighborhood_NAmes -2071.296964\n",
       "85    Neighborhood_Edwards -2214.196979\n",
       "116        Condition2_PosN -3848.863097\n",
       "139       RoofMatl_ClyTile -7938.729980"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option(\"display.max_rows\", None)\n",
    "coeff_df.sort_values(by=\"Coefficient\", ascending=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression - Kbest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Kbest = X_Kbest.assign(random=np.random.normal(size=X_Kbest.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "KgridSearch = GridSearchCV(\n",
    "    estimator=ElasticNet(max_iter=50000),\n",
    "    param_grid=param_grid,\n",
    "    scoring=scoring,\n",
    "    verbose=3,\n",
    "    n_jobs=-1,\n",
    "    cv=5,\n",
    "    refit=\"Mape\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV 1/5] END alpha=1, l1_ratio=0.1; Adjusted R-squared: (test=-0.833) Mape: (test=-11.950) R-squared: (test=0.833) total time=   0.0s\n",
      "[CV 2/5] END alpha=1, l1_ratio=0.1; Adjusted R-squared: (test=-0.789) Mape: (test=-13.017) R-squared: (test=0.789) total time=   0.0s\n",
      "[CV 3/5] END alpha=1, l1_ratio=0.1; Adjusted R-squared: (test=-0.819) Mape: (test=-11.799) R-squared: (test=0.819) total time=   0.0s\n",
      "[CV 4/5] END alpha=1, l1_ratio=0.1; Adjusted R-squared: (test=-0.832) Mape: (test=-12.481) R-squared: (test=0.832) total time=   0.0s\n",
      "[CV 5/5] END alpha=1, l1_ratio=0.1; Adjusted R-squared: (test=-0.591) Mape: (test=-14.373) R-squared: (test=0.591) total time=   0.0s\n",
      "[CV 1/5] END alpha=1, l1_ratio=0.3; Adjusted R-squared: (test=-0.836) Mape: (test=-11.894) R-squared: (test=0.836) total time=   0.0s\n",
      "[CV 2/5] END alpha=1, l1_ratio=0.3; Adjusted R-squared: (test=-0.791) Mape: (test=-13.109) R-squared: (test=0.791) total time=   0.0s\n",
      "[CV 3/5] END alpha=1, l1_ratio=0.3; Adjusted R-squared: (test=-0.821) Mape: (test=-11.768) R-squared: (test=0.821) total time=   0.0s\n",
      "[CV 4/5] END alpha=1, l1_ratio=0.3; Adjusted R-squared: (test=-0.834) Mape: (test=-12.403) R-squared: (test=0.834) total time=   0.0s\n",
      "[CV 5/5] END alpha=1, l1_ratio=0.3; Adjusted R-squared: (test=-0.600) Mape: (test=-14.236) R-squared: (test=0.600) total time=   0.0s\n",
      "[CV 1/5] END alpha=1, l1_ratio=0.5; Adjusted R-squared: (test=-0.838) Mape: (test=-11.861) R-squared: (test=0.838) total time=   0.0s\n",
      "[CV 2/5] END alpha=1, l1_ratio=0.5; Adjusted R-squared: (test=-0.794) Mape: (test=-13.238) R-squared: (test=0.794) total time=   0.0s\n",
      "[CV 3/5] END alpha=1, l1_ratio=0.5; Adjusted R-squared: (test=-0.823) Mape: (test=-11.759) R-squared: (test=0.823) total time=   0.0s\n",
      "[CV 4/5] END alpha=1, l1_ratio=0.5; Adjusted R-squared: (test=-0.836) Mape: (test=-12.328) R-squared: (test=0.836) total time=   0.0s\n",
      "[CV 5/5] END alpha=1, l1_ratio=0.5; Adjusted R-squared: (test=-0.611) Mape: (test=-14.081) R-squared: (test=0.611) total time=   0.0s\n",
      "[CV 1/5] END alpha=1, l1_ratio=0.7; Adjusted R-squared: (test=-0.841) Mape: (test=-11.953) R-squared: (test=0.841) total time=   0.0s\n",
      "[CV 2/5] END alpha=1, l1_ratio=0.7; Adjusted R-squared: (test=-0.796) Mape: (test=-13.468) R-squared: (test=0.796) total time=   0.0s\n",
      "[CV 4/5] END alpha=1, l1_ratio=0.7; Adjusted R-squared: (test=-0.838) Mape: (test=-12.299) R-squared: (test=0.838) total time=   0.0s\n",
      "[CV 3/5] END alpha=1, l1_ratio=0.7; Adjusted R-squared: (test=-0.824) Mape: (test=-11.847) R-squared: (test=0.824) total time=   0.0s\n",
      "[CV 1/5] END alpha=1, l1_ratio=0.9; Adjusted R-squared: (test=-0.845) Mape: (test=-12.138) R-squared: (test=0.845) total time=   0.0s\n",
      "[CV 5/5] END alpha=1, l1_ratio=0.7; Adjusted R-squared: (test=-0.624) Mape: (test=-13.887) R-squared: (test=0.624) total time=   0.0s\n",
      "[CV 2/5] END alpha=1, l1_ratio=0.9; Adjusted R-squared: (test=-0.799) Mape: (test=-13.838) R-squared: (test=0.799) total time=   0.0s\n",
      "[CV 3/5] END alpha=1, l1_ratio=0.9; Adjusted R-squared: (test=-0.823) Mape: (test=-12.103) R-squared: (test=0.823) total time=   0.0s\n",
      "[CV 5/5] END alpha=1, l1_ratio=0.9; Adjusted R-squared: (test=-0.641) Mape: (test=-13.641) R-squared: (test=0.641) total time=   0.0s\n",
      "[CV 4/5] END alpha=1, l1_ratio=0.9; Adjusted R-squared: (test=-0.838) Mape: (test=-12.415) R-squared: (test=0.838) total time=   0.0s\n",
      "[CV 1/5] END alpha=10, l1_ratio=0.1; Adjusted R-squared: (test=-0.804) Mape: (test=-13.069) R-squared: (test=0.804) total time=   0.0s\n",
      "[CV 2/5] END alpha=10, l1_ratio=0.1; Adjusted R-squared: (test=-0.760) Mape: (test=-13.287) R-squared: (test=0.760) total time=   0.0s\n",
      "[CV 4/5] END alpha=10, l1_ratio=0.1; Adjusted R-squared: (test=-0.798) Mape: (test=-13.866) R-squared: (test=0.798) total time=   0.0s\n",
      "[CV 1/5] END alpha=10, l1_ratio=0.3; Adjusted R-squared: (test=-0.807) Mape: (test=-12.972) R-squared: (test=0.807) total time=   0.0s\n",
      "[CV 3/5] END alpha=10, l1_ratio=0.1; Adjusted R-squared: (test=-0.793) Mape: (test=-12.698) R-squared: (test=0.793) total time=   0.0s\n",
      "[CV 5/5] END alpha=10, l1_ratio=0.1; Adjusted R-squared: (test=-0.508) Mape: (test=-15.778) R-squared: (test=0.508) total time=   0.0s\n",
      "[CV 3/5] END alpha=10, l1_ratio=0.3; Adjusted R-squared: (test=-0.796) Mape: (test=-12.600) R-squared: (test=0.796) total time=   0.0s\n",
      "[CV 2/5] END alpha=10, l1_ratio=0.3; Adjusted R-squared: (test=-0.763) Mape: (test=-13.230) R-squared: (test=0.763) total time=   0.0s\n",
      "[CV 4/5] END alpha=10, l1_ratio=0.3; Adjusted R-squared: (test=-0.802) Mape: (test=-13.745) R-squared: (test=0.802) total time=   0.0s\n",
      "[CV 5/5] END alpha=10, l1_ratio=0.3; Adjusted R-squared: (test=-0.515) Mape: (test=-15.672) R-squared: (test=0.515) total time=   0.0s\n",
      "[CV 1/5] END alpha=10, l1_ratio=0.5; Adjusted R-squared: (test=-0.811) Mape: (test=-12.810) R-squared: (test=0.811) total time=   0.0s\n",
      "[CV 2/5] END alpha=10, l1_ratio=0.5; Adjusted R-squared: (test=-0.767) Mape: (test=-13.139) R-squared: (test=0.767) total time=   0.0s\n",
      "[CV 4/5] END alpha=10, l1_ratio=0.5; Adjusted R-squared: (test=-0.807) Mape: (test=-13.555) R-squared: (test=0.807) total time=   0.0s\n",
      "[CV 3/5] END alpha=10, l1_ratio=0.5; Adjusted R-squared: (test=-0.800) Mape: (test=-12.455) R-squared: (test=0.800) total time=   0.0s\n",
      "[CV 1/5] END alpha=10, l1_ratio=0.7; Adjusted R-squared: (test=-0.818) Mape: (test=-12.513) R-squared: (test=0.818) total time=   0.0s\n",
      "[CV 5/5] END alpha=10, l1_ratio=0.5; Adjusted R-squared: (test=-0.525) Mape: (test=-15.502) R-squared: (test=0.525) total time=   0.0s\n",
      "[CV 2/5] END alpha=10, l1_ratio=0.7; Adjusted R-squared: (test=-0.774) Mape: (test=-13.003) R-squared: (test=0.774) total time=   0.0s\n",
      "[CV 3/5] END alpha=10, l1_ratio=0.7; Adjusted R-squared: (test=-0.807) Mape: (test=-12.193) R-squared: (test=0.807) total time=   0.0s\n",
      "[CV 4/5] END alpha=10, l1_ratio=0.7; Adjusted R-squared: (test=-0.816) Mape: (test=-13.213) R-squared: (test=0.816) total time=   0.0s\n",
      "[CV 5/5] END alpha=10, l1_ratio=0.7; Adjusted R-squared: (test=-0.544) Mape: (test=-15.187) R-squared: (test=0.544) total time=   0.0s\n",
      "[CV 1/5] END alpha=10, l1_ratio=0.9; Adjusted R-squared: (test=-0.832) Mape: (test=-11.979) R-squared: (test=0.832) total time=   0.0s\n",
      "[CV 2/5] END alpha=10, l1_ratio=0.9; Adjusted R-squared: (test=-0.788) Mape: (test=-12.982) R-squared: (test=0.788) total time=   0.0s\n",
      "[CV 4/5] END alpha=10, l1_ratio=0.9; Adjusted R-squared: (test=-0.831) Mape: (test=-12.525) R-squared: (test=0.831) total time=   0.0s\n",
      "[CV 3/5] END alpha=100, l1_ratio=0.1; Adjusted R-squared: (test=-0.777) Mape: (test=-13.263) R-squared: (test=0.777) total time=   0.0s\n",
      "[CV 3/5] END alpha=10, l1_ratio=0.9; Adjusted R-squared: (test=-0.819) Mape: (test=-11.819) R-squared: (test=0.819) total time=   0.0s\n",
      "[CV 5/5] END alpha=10, l1_ratio=0.9; Adjusted R-squared: (test=-0.587) Mape: (test=-14.443) R-squared: (test=0.587) total time=   0.0s\n",
      "[CV 4/5] END alpha=100, l1_ratio=0.1; Adjusted R-squared: (test=-0.781) Mape: (test=-14.278) R-squared: (test=0.781) total time=   0.0s\n",
      "[CV 2/5] END alpha=100, l1_ratio=0.3; Adjusted R-squared: (test=-0.747) Mape: (test=-13.546) R-squared: (test=0.747) total time=   0.0s\n",
      "[CV 1/5] END alpha=100, l1_ratio=0.1; Adjusted R-squared: (test=-0.792) Mape: (test=-13.256) R-squared: (test=0.792) total time=   0.0s\n",
      "[CV 5/5] END alpha=100, l1_ratio=0.1; Adjusted R-squared: (test=-0.473) Mape: (test=-16.061) R-squared: (test=0.473) total time=   0.0s\n",
      "[CV 3/5] END alpha=100, l1_ratio=0.3; Adjusted R-squared: (test=-0.778) Mape: (test=-13.225) R-squared: (test=0.778) total time=   0.0s\n",
      "[CV 2/5] END alpha=100, l1_ratio=0.1; Adjusted R-squared: (test=-0.747) Mape: (test=-13.561) R-squared: (test=0.747) total time=   0.0s\n",
      "[CV 1/5] END alpha=100, l1_ratio=0.3; Adjusted R-squared: (test=-0.792) Mape: (test=-13.286) R-squared: (test=0.792) total time=   0.0s\n",
      "[CV 4/5] END alpha=100, l1_ratio=0.3; Adjusted R-squared: (test=-0.782) Mape: (test=-14.275) R-squared: (test=0.782) total time=   0.0s\n",
      "[CV 1/5] END alpha=100, l1_ratio=0.5; Adjusted R-squared: (test=-0.793) Mape: (test=-13.309) R-squared: (test=0.793) total time=   0.0s\n",
      "[CV 5/5] END alpha=100, l1_ratio=0.5; Adjusted R-squared: (test=-0.479) Mape: (test=-16.075) R-squared: (test=0.479) total time=   0.0s\n",
      "[CV 5/5] END alpha=100, l1_ratio=0.3; Adjusted R-squared: (test=-0.476) Mape: (test=-16.070) R-squared: (test=0.476) total time=   0.0s\n",
      "[CV 2/5] END alpha=100, l1_ratio=0.5; Adjusted R-squared: (test=-0.748) Mape: (test=-13.526) R-squared: (test=0.748) total time=   0.0s\n",
      "[CV 1/5] END alpha=100, l1_ratio=0.7; Adjusted R-squared: (test=-0.794) Mape: (test=-13.308) R-squared: (test=0.794) total time=   0.0s\n",
      "[CV 4/5] END alpha=100, l1_ratio=0.7; Adjusted R-squared: (test=-0.786) Mape: (test=-14.209) R-squared: (test=0.786) total time=   0.0s\n",
      "[CV 3/5] END alpha=100, l1_ratio=0.5; Adjusted R-squared: (test=-0.780) Mape: (test=-13.170) R-squared: (test=0.780) total time=   0.0s\n",
      "[CV 5/5] END alpha=100, l1_ratio=0.7; Adjusted R-squared: (test=-0.485) Mape: (test=-16.057) R-squared: (test=0.485) total time=   0.0s\n",
      "[CV 3/5] END alpha=100, l1_ratio=0.9; Adjusted R-squared: (test=-0.792) Mape: (test=-12.741) R-squared: (test=0.792) total time=   0.0s\n",
      "[CV 4/5] END alpha=100, l1_ratio=0.5; Adjusted R-squared: (test=-0.783) Mape: (test=-14.264) R-squared: (test=0.783) total time=   0.0s\n",
      "[CV 1/5] END alpha=100, l1_ratio=0.9; Adjusted R-squared: (test=-0.803) Mape: (test=-13.108) R-squared: (test=0.803) total time=   0.0s\n",
      "[CV 2/5] END alpha=100, l1_ratio=0.7; Adjusted R-squared: (test=-0.751) Mape: (test=-13.486) R-squared: (test=0.751) total time=   0.0s\n",
      "[CV 4/5] END alpha=100, l1_ratio=0.9; Adjusted R-squared: (test=-0.797) Mape: (test=-13.916) R-squared: (test=0.797) total time=   0.0s\n",
      "[CV 2/5] END alpha=1000, l1_ratio=0.1; Adjusted R-squared: (test=-0.729) Mape: (test=-14.370) R-squared: (test=0.729) total time=   0.0s\n",
      "[CV 2/5] END alpha=100, l1_ratio=0.9; Adjusted R-squared: (test=-0.759) Mape: (test=-13.313) R-squared: (test=0.759) total time=   0.0s\n",
      "[CV 5/5] END alpha=100, l1_ratio=0.9; Adjusted R-squared: (test=-0.505) Mape: (test=-15.825) R-squared: (test=0.505) total time=   0.0s\n",
      "[CV 3/5] END alpha=100, l1_ratio=0.7; Adjusted R-squared: (test=-0.783) Mape: (test=-13.065) R-squared: (test=0.783) total time=   0.0s\n",
      "[CV 3/5] END alpha=1000, l1_ratio=0.1; Adjusted R-squared: (test=-0.749) Mape: (test=-14.332) R-squared: (test=0.749) total time=   0.0s\n",
      "[CV 2/5] END alpha=1000, l1_ratio=0.3; Adjusted R-squared: (test=-0.733) Mape: (test=-14.129) R-squared: (test=0.733) total time=   0.0s\n",
      "[CV 4/5] END alpha=1000, l1_ratio=0.3; Adjusted R-squared: (test=-0.761) Mape: (test=-14.676) R-squared: (test=0.761) total time=   0.0s\n",
      "[CV 5/5] END alpha=1000, l1_ratio=0.3; Adjusted R-squared: (test=-0.428) Mape: (test=-16.323) R-squared: (test=0.428) total time=   0.0s\n",
      "[CV 3/5] END alpha=1000, l1_ratio=0.3; Adjusted R-squared: (test=-0.754) Mape: (test=-14.119) R-squared: (test=0.754) total time=   0.0s\n",
      "[CV 1/5] END alpha=1000, l1_ratio=0.3; Adjusted R-squared: (test=-0.782) Mape: (test=-13.200) R-squared: (test=0.782) total time=   0.0s\n",
      "[CV 1/5] END alpha=1000, l1_ratio=0.5; Adjusted R-squared: (test=-0.786) Mape: (test=-13.070) R-squared: (test=0.786) total time=   0.0s\n",
      "[CV 2/5] END alpha=1000, l1_ratio=0.5; Adjusted R-squared: (test=-0.737) Mape: (test=-13.896) R-squared: (test=0.737) total time=   0.0s\n",
      "[CV 1/5] END alpha=1000, l1_ratio=0.1; Adjusted R-squared: (test=-0.779) Mape: (test=-13.368) R-squared: (test=0.779) total time=   0.0s\n",
      "[CV 4/5] END alpha=1000, l1_ratio=0.1; Adjusted R-squared: (test=-0.756) Mape: (test=-14.811) R-squared: (test=0.756) total time=   0.0s\n",
      "[CV 3/5] END alpha=1000, l1_ratio=0.5; Adjusted R-squared: (test=-0.761) Mape: (test=-13.842) R-squared: (test=0.761) total time=   0.0s\n",
      "[CV 4/5] END alpha=1000, l1_ratio=0.5; Adjusted R-squared: (test=-0.768) Mape: (test=-14.511) R-squared: (test=0.768) total time=   0.0s\n",
      "[CV 2/5] END alpha=1000, l1_ratio=0.7; Adjusted R-squared: (test=-0.742) Mape: (test=-13.693) R-squared: (test=0.742) total time=   0.0s\n",
      "[CV 3/5] END alpha=1000, l1_ratio=0.7; Adjusted R-squared: (test=-0.768) Mape: (test=-13.544) R-squared: (test=0.768) total time=   0.0s\n",
      "[CV 5/5] END alpha=1000, l1_ratio=0.1; Adjusted R-squared: (test=-0.418) Mape: (test=-16.471) R-squared: (test=0.418) total time=   0.0s\n",
      "[CV 4/5] END alpha=1000, l1_ratio=0.7; Adjusted R-squared: (test=-0.774) Mape: (test=-14.360) R-squared: (test=0.774) total time=   0.0s\n",
      "[CV 1/5] END alpha=1000, l1_ratio=0.7; Adjusted R-squared: (test=-0.789) Mape: (test=-13.065) R-squared: (test=0.789) total time=   0.0s\n",
      "[CV 5/5] END alpha=1000, l1_ratio=0.5; Adjusted R-squared: (test=-0.439) Mape: (test=-16.169) R-squared: (test=0.439) total time=   0.0s\n",
      "[CV 5/5] END alpha=1000, l1_ratio=0.7; Adjusted R-squared: (test=-0.454) Mape: (test=-16.066) R-squared: (test=0.454) total time=   0.0s\n",
      "[CV 1/5] END alpha=1000, l1_ratio=0.9; Adjusted R-squared: (test=-0.791) Mape: (test=-13.241) R-squared: (test=0.791) total time=   0.0s\n",
      "[CV 2/5] END alpha=1000, l1_ratio=0.9; Adjusted R-squared: (test=-0.746) Mape: (test=-13.573) R-squared: (test=0.746) total time=   0.0s\n",
      "[CV 3/5] END alpha=1000, l1_ratio=0.9; Adjusted R-squared: (test=-0.776) Mape: (test=-13.287) R-squared: (test=0.776) total time=   0.0s\n",
      "[CV 4/5] END alpha=1000, l1_ratio=0.9; Adjusted R-squared: (test=-0.781) Mape: (test=-14.285) R-squared: (test=0.781) total time=   0.0s\n",
      "[CV 5/5] END alpha=1000, l1_ratio=0.9; Adjusted R-squared: (test=-0.472) Mape: (test=-16.064) R-squared: (test=0.472) total time=   0.0s\n"
     ]
    }
   ],
   "source": [
    "KgridSearch.fit(X_Kbest, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-12.653586219504751"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KgridSearch.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>param_l1_ratio</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_R-squared</th>\n",
       "      <th>split1_test_R-squared</th>\n",
       "      <th>split2_test_R-squared</th>\n",
       "      <th>split3_test_R-squared</th>\n",
       "      <th>split4_test_R-squared</th>\n",
       "      <th>mean_test_R-squared</th>\n",
       "      <th>std_test_R-squared</th>\n",
       "      <th>rank_test_R-squared</th>\n",
       "      <th>split0_test_Adjusted R-squared</th>\n",
       "      <th>split1_test_Adjusted R-squared</th>\n",
       "      <th>split2_test_Adjusted R-squared</th>\n",
       "      <th>split3_test_Adjusted R-squared</th>\n",
       "      <th>split4_test_Adjusted R-squared</th>\n",
       "      <th>mean_test_Adjusted R-squared</th>\n",
       "      <th>std_test_Adjusted R-squared</th>\n",
       "      <th>rank_test_Adjusted R-squared</th>\n",
       "      <th>split0_test_Mape</th>\n",
       "      <th>split1_test_Mape</th>\n",
       "      <th>split2_test_Mape</th>\n",
       "      <th>split3_test_Mape</th>\n",
       "      <th>split4_test_Mape</th>\n",
       "      <th>mean_test_Mape</th>\n",
       "      <th>std_test_Mape</th>\n",
       "      <th>rank_test_Mape</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.003539</td>\n",
       "      <td>0.000366</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'alpha': 1, 'l1_ratio': 0.1}</td>\n",
       "      <td>0.833312</td>\n",
       "      <td>0.788706</td>\n",
       "      <td>0.819406</td>\n",
       "      <td>0.832329</td>\n",
       "      <td>0.591274</td>\n",
       "      <td>0.773006</td>\n",
       "      <td>0.092285</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.833312</td>\n",
       "      <td>-0.788706</td>\n",
       "      <td>-0.819406</td>\n",
       "      <td>-0.832329</td>\n",
       "      <td>-0.591274</td>\n",
       "      <td>-0.773006</td>\n",
       "      <td>0.092285</td>\n",
       "      <td>16</td>\n",
       "      <td>-11.949772</td>\n",
       "      <td>-13.016661</td>\n",
       "      <td>-11.798584</td>\n",
       "      <td>-12.481237</td>\n",
       "      <td>-14.373252</td>\n",
       "      <td>-12.723901</td>\n",
       "      <td>0.929564</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002716</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>0.001559</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'alpha': 1, 'l1_ratio': 0.3}</td>\n",
       "      <td>0.835642</td>\n",
       "      <td>0.791078</td>\n",
       "      <td>0.821103</td>\n",
       "      <td>0.834465</td>\n",
       "      <td>0.600196</td>\n",
       "      <td>0.776497</td>\n",
       "      <td>0.089602</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.835642</td>\n",
       "      <td>-0.791078</td>\n",
       "      <td>-0.821103</td>\n",
       "      <td>-0.834465</td>\n",
       "      <td>-0.600196</td>\n",
       "      <td>-0.776497</td>\n",
       "      <td>0.089602</td>\n",
       "      <td>17</td>\n",
       "      <td>-11.894331</td>\n",
       "      <td>-13.109115</td>\n",
       "      <td>-11.767631</td>\n",
       "      <td>-12.402782</td>\n",
       "      <td>-14.236300</td>\n",
       "      <td>-12.682032</td>\n",
       "      <td>0.909146</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002750</td>\n",
       "      <td>0.000402</td>\n",
       "      <td>0.001518</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'alpha': 1, 'l1_ratio': 0.5}</td>\n",
       "      <td>0.838222</td>\n",
       "      <td>0.793688</td>\n",
       "      <td>0.822739</td>\n",
       "      <td>0.836492</td>\n",
       "      <td>0.610971</td>\n",
       "      <td>0.780422</td>\n",
       "      <td>0.086215</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.838222</td>\n",
       "      <td>-0.793688</td>\n",
       "      <td>-0.822739</td>\n",
       "      <td>-0.836492</td>\n",
       "      <td>-0.610971</td>\n",
       "      <td>-0.780422</td>\n",
       "      <td>0.086215</td>\n",
       "      <td>18</td>\n",
       "      <td>-11.861115</td>\n",
       "      <td>-13.238214</td>\n",
       "      <td>-11.759039</td>\n",
       "      <td>-12.328451</td>\n",
       "      <td>-14.081113</td>\n",
       "      <td>-12.653586</td>\n",
       "      <td>0.884710</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002496</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>0.001469</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>{'alpha': 1, 'l1_ratio': 0.7}</td>\n",
       "      <td>0.841134</td>\n",
       "      <td>0.796462</td>\n",
       "      <td>0.823942</td>\n",
       "      <td>0.837980</td>\n",
       "      <td>0.624345</td>\n",
       "      <td>0.784773</td>\n",
       "      <td>0.081750</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.841134</td>\n",
       "      <td>-0.796462</td>\n",
       "      <td>-0.823942</td>\n",
       "      <td>-0.837980</td>\n",
       "      <td>-0.624345</td>\n",
       "      <td>-0.784773</td>\n",
       "      <td>0.081750</td>\n",
       "      <td>19</td>\n",
       "      <td>-11.953381</td>\n",
       "      <td>-13.468294</td>\n",
       "      <td>-11.846595</td>\n",
       "      <td>-12.299294</td>\n",
       "      <td>-13.887178</td>\n",
       "      <td>-12.690948</td>\n",
       "      <td>0.830128</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002805</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.001921</td>\n",
       "      <td>0.000767</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>{'alpha': 1, 'l1_ratio': 0.9}</td>\n",
       "      <td>0.845265</td>\n",
       "      <td>0.799262</td>\n",
       "      <td>0.822847</td>\n",
       "      <td>0.837577</td>\n",
       "      <td>0.641469</td>\n",
       "      <td>0.789284</td>\n",
       "      <td>0.075553</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.845265</td>\n",
       "      <td>-0.799262</td>\n",
       "      <td>-0.822847</td>\n",
       "      <td>-0.837577</td>\n",
       "      <td>-0.641469</td>\n",
       "      <td>-0.789284</td>\n",
       "      <td>0.075553</td>\n",
       "      <td>20</td>\n",
       "      <td>-12.138245</td>\n",
       "      <td>-13.837982</td>\n",
       "      <td>-12.103193</td>\n",
       "      <td>-12.414796</td>\n",
       "      <td>-13.641420</td>\n",
       "      <td>-12.827127</td>\n",
       "      <td>0.755454</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.010238</td>\n",
       "      <td>0.013277</td>\n",
       "      <td>0.011718</td>\n",
       "      <td>0.011461</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'alpha': 1000, 'l1_ratio': 0.1}</td>\n",
       "      <td>0.779095</td>\n",
       "      <td>0.729498</td>\n",
       "      <td>0.748916</td>\n",
       "      <td>0.755583</td>\n",
       "      <td>0.418364</td>\n",
       "      <td>0.686291</td>\n",
       "      <td>0.134898</td>\n",
       "      <td>20</td>\n",
       "      <td>-0.779095</td>\n",
       "      <td>-0.729498</td>\n",
       "      <td>-0.748916</td>\n",
       "      <td>-0.755583</td>\n",
       "      <td>-0.418364</td>\n",
       "      <td>-0.686291</td>\n",
       "      <td>0.134898</td>\n",
       "      <td>1</td>\n",
       "      <td>-13.367750</td>\n",
       "      <td>-14.369703</td>\n",
       "      <td>-14.332106</td>\n",
       "      <td>-14.811334</td>\n",
       "      <td>-16.471302</td>\n",
       "      <td>-14.670439</td>\n",
       "      <td>1.016353</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.006348</td>\n",
       "      <td>0.002024</td>\n",
       "      <td>0.007681</td>\n",
       "      <td>0.008801</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'alpha': 1000, 'l1_ratio': 0.3}</td>\n",
       "      <td>0.782445</td>\n",
       "      <td>0.733098</td>\n",
       "      <td>0.754277</td>\n",
       "      <td>0.761293</td>\n",
       "      <td>0.427836</td>\n",
       "      <td>0.691790</td>\n",
       "      <td>0.132915</td>\n",
       "      <td>19</td>\n",
       "      <td>-0.782445</td>\n",
       "      <td>-0.733098</td>\n",
       "      <td>-0.754277</td>\n",
       "      <td>-0.761293</td>\n",
       "      <td>-0.427836</td>\n",
       "      <td>-0.691790</td>\n",
       "      <td>0.132915</td>\n",
       "      <td>2</td>\n",
       "      <td>-13.200225</td>\n",
       "      <td>-14.128888</td>\n",
       "      <td>-14.118527</td>\n",
       "      <td>-14.676170</td>\n",
       "      <td>-16.323496</td>\n",
       "      <td>-14.489461</td>\n",
       "      <td>1.032306</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.006770</td>\n",
       "      <td>0.006795</td>\n",
       "      <td>0.001558</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'alpha': 1000, 'l1_ratio': 0.5}</td>\n",
       "      <td>0.785936</td>\n",
       "      <td>0.737152</td>\n",
       "      <td>0.760518</td>\n",
       "      <td>0.767686</td>\n",
       "      <td>0.439439</td>\n",
       "      <td>0.698146</td>\n",
       "      <td>0.130295</td>\n",
       "      <td>18</td>\n",
       "      <td>-0.785936</td>\n",
       "      <td>-0.737152</td>\n",
       "      <td>-0.760518</td>\n",
       "      <td>-0.767686</td>\n",
       "      <td>-0.439439</td>\n",
       "      <td>-0.698146</td>\n",
       "      <td>0.130295</td>\n",
       "      <td>3</td>\n",
       "      <td>-13.070426</td>\n",
       "      <td>-13.896120</td>\n",
       "      <td>-13.841625</td>\n",
       "      <td>-14.510670</td>\n",
       "      <td>-16.168705</td>\n",
       "      <td>-14.297509</td>\n",
       "      <td>1.041296</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.005584</td>\n",
       "      <td>0.006092</td>\n",
       "      <td>0.001525</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>{'alpha': 1000, 'l1_ratio': 0.7}</td>\n",
       "      <td>0.789159</td>\n",
       "      <td>0.741555</td>\n",
       "      <td>0.767707</td>\n",
       "      <td>0.774445</td>\n",
       "      <td>0.453727</td>\n",
       "      <td>0.705319</td>\n",
       "      <td>0.126737</td>\n",
       "      <td>17</td>\n",
       "      <td>-0.789159</td>\n",
       "      <td>-0.741555</td>\n",
       "      <td>-0.767707</td>\n",
       "      <td>-0.774445</td>\n",
       "      <td>-0.453727</td>\n",
       "      <td>-0.705319</td>\n",
       "      <td>0.126737</td>\n",
       "      <td>4</td>\n",
       "      <td>-13.065011</td>\n",
       "      <td>-13.692970</td>\n",
       "      <td>-13.544225</td>\n",
       "      <td>-14.359759</td>\n",
       "      <td>-16.066449</td>\n",
       "      <td>-14.145683</td>\n",
       "      <td>1.045918</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.002364</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.001535</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>{'alpha': 1000, 'l1_ratio': 0.9}</td>\n",
       "      <td>0.791280</td>\n",
       "      <td>0.746151</td>\n",
       "      <td>0.776195</td>\n",
       "      <td>0.780691</td>\n",
       "      <td>0.471695</td>\n",
       "      <td>0.713202</td>\n",
       "      <td>0.121680</td>\n",
       "      <td>16</td>\n",
       "      <td>-0.791280</td>\n",
       "      <td>-0.746151</td>\n",
       "      <td>-0.776195</td>\n",
       "      <td>-0.780691</td>\n",
       "      <td>-0.471695</td>\n",
       "      <td>-0.713202</td>\n",
       "      <td>0.121680</td>\n",
       "      <td>5</td>\n",
       "      <td>-13.241142</td>\n",
       "      <td>-13.572905</td>\n",
       "      <td>-13.287394</td>\n",
       "      <td>-14.285354</td>\n",
       "      <td>-16.064486</td>\n",
       "      <td>-14.090256</td>\n",
       "      <td>1.055356</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_alpha  \\\n",
       "0        0.003539      0.000366         0.001600        0.000063           1   \n",
       "1        0.002716      0.000143         0.001559        0.000045           1   \n",
       "2        0.002750      0.000402         0.001518        0.000039           1   \n",
       "3        0.002496      0.000219         0.001469        0.000080           1   \n",
       "4        0.002805      0.000183         0.001921        0.000767           1   \n",
       "..            ...           ...              ...             ...         ...   \n",
       "15       0.010238      0.013277         0.011718        0.011461        1000   \n",
       "16       0.006348      0.002024         0.007681        0.008801        1000   \n",
       "17       0.006770      0.006795         0.001558        0.000120        1000   \n",
       "18       0.005584      0.006092         0.001525        0.000121        1000   \n",
       "19       0.002364      0.000074         0.001535        0.000095        1000   \n",
       "\n",
       "   param_l1_ratio                            params  split0_test_R-squared  \\\n",
       "0             0.1     {'alpha': 1, 'l1_ratio': 0.1}               0.833312   \n",
       "1             0.3     {'alpha': 1, 'l1_ratio': 0.3}               0.835642   \n",
       "2             0.5     {'alpha': 1, 'l1_ratio': 0.5}               0.838222   \n",
       "3             0.7     {'alpha': 1, 'l1_ratio': 0.7}               0.841134   \n",
       "4             0.9     {'alpha': 1, 'l1_ratio': 0.9}               0.845265   \n",
       "..            ...                               ...                    ...   \n",
       "15            0.1  {'alpha': 1000, 'l1_ratio': 0.1}               0.779095   \n",
       "16            0.3  {'alpha': 1000, 'l1_ratio': 0.3}               0.782445   \n",
       "17            0.5  {'alpha': 1000, 'l1_ratio': 0.5}               0.785936   \n",
       "18            0.7  {'alpha': 1000, 'l1_ratio': 0.7}               0.789159   \n",
       "19            0.9  {'alpha': 1000, 'l1_ratio': 0.9}               0.791280   \n",
       "\n",
       "    split1_test_R-squared  split2_test_R-squared  split3_test_R-squared  \\\n",
       "0                0.788706               0.819406               0.832329   \n",
       "1                0.791078               0.821103               0.834465   \n",
       "2                0.793688               0.822739               0.836492   \n",
       "3                0.796462               0.823942               0.837980   \n",
       "4                0.799262               0.822847               0.837577   \n",
       "..                    ...                    ...                    ...   \n",
       "15               0.729498               0.748916               0.755583   \n",
       "16               0.733098               0.754277               0.761293   \n",
       "17               0.737152               0.760518               0.767686   \n",
       "18               0.741555               0.767707               0.774445   \n",
       "19               0.746151               0.776195               0.780691   \n",
       "\n",
       "    split4_test_R-squared  mean_test_R-squared  std_test_R-squared  \\\n",
       "0                0.591274             0.773006            0.092285   \n",
       "1                0.600196             0.776497            0.089602   \n",
       "2                0.610971             0.780422            0.086215   \n",
       "3                0.624345             0.784773            0.081750   \n",
       "4                0.641469             0.789284            0.075553   \n",
       "..                    ...                  ...                 ...   \n",
       "15               0.418364             0.686291            0.134898   \n",
       "16               0.427836             0.691790            0.132915   \n",
       "17               0.439439             0.698146            0.130295   \n",
       "18               0.453727             0.705319            0.126737   \n",
       "19               0.471695             0.713202            0.121680   \n",
       "\n",
       "    rank_test_R-squared  split0_test_Adjusted R-squared  \\\n",
       "0                     5                       -0.833312   \n",
       "1                     4                       -0.835642   \n",
       "2                     3                       -0.838222   \n",
       "3                     2                       -0.841134   \n",
       "4                     1                       -0.845265   \n",
       "..                  ...                             ...   \n",
       "15                   20                       -0.779095   \n",
       "16                   19                       -0.782445   \n",
       "17                   18                       -0.785936   \n",
       "18                   17                       -0.789159   \n",
       "19                   16                       -0.791280   \n",
       "\n",
       "    split1_test_Adjusted R-squared  split2_test_Adjusted R-squared  \\\n",
       "0                        -0.788706                       -0.819406   \n",
       "1                        -0.791078                       -0.821103   \n",
       "2                        -0.793688                       -0.822739   \n",
       "3                        -0.796462                       -0.823942   \n",
       "4                        -0.799262                       -0.822847   \n",
       "..                             ...                             ...   \n",
       "15                       -0.729498                       -0.748916   \n",
       "16                       -0.733098                       -0.754277   \n",
       "17                       -0.737152                       -0.760518   \n",
       "18                       -0.741555                       -0.767707   \n",
       "19                       -0.746151                       -0.776195   \n",
       "\n",
       "    split3_test_Adjusted R-squared  split4_test_Adjusted R-squared  \\\n",
       "0                        -0.832329                       -0.591274   \n",
       "1                        -0.834465                       -0.600196   \n",
       "2                        -0.836492                       -0.610971   \n",
       "3                        -0.837980                       -0.624345   \n",
       "4                        -0.837577                       -0.641469   \n",
       "..                             ...                             ...   \n",
       "15                       -0.755583                       -0.418364   \n",
       "16                       -0.761293                       -0.427836   \n",
       "17                       -0.767686                       -0.439439   \n",
       "18                       -0.774445                       -0.453727   \n",
       "19                       -0.780691                       -0.471695   \n",
       "\n",
       "    mean_test_Adjusted R-squared  std_test_Adjusted R-squared  \\\n",
       "0                      -0.773006                     0.092285   \n",
       "1                      -0.776497                     0.089602   \n",
       "2                      -0.780422                     0.086215   \n",
       "3                      -0.784773                     0.081750   \n",
       "4                      -0.789284                     0.075553   \n",
       "..                           ...                          ...   \n",
       "15                     -0.686291                     0.134898   \n",
       "16                     -0.691790                     0.132915   \n",
       "17                     -0.698146                     0.130295   \n",
       "18                     -0.705319                     0.126737   \n",
       "19                     -0.713202                     0.121680   \n",
       "\n",
       "    rank_test_Adjusted R-squared  split0_test_Mape  split1_test_Mape  \\\n",
       "0                             16        -11.949772        -13.016661   \n",
       "1                             17        -11.894331        -13.109115   \n",
       "2                             18        -11.861115        -13.238214   \n",
       "3                             19        -11.953381        -13.468294   \n",
       "4                             20        -12.138245        -13.837982   \n",
       "..                           ...               ...               ...   \n",
       "15                             1        -13.367750        -14.369703   \n",
       "16                             2        -13.200225        -14.128888   \n",
       "17                             3        -13.070426        -13.896120   \n",
       "18                             4        -13.065011        -13.692970   \n",
       "19                             5        -13.241142        -13.572905   \n",
       "\n",
       "    split2_test_Mape  split3_test_Mape  split4_test_Mape  mean_test_Mape  \\\n",
       "0         -11.798584        -12.481237        -14.373252      -12.723901   \n",
       "1         -11.767631        -12.402782        -14.236300      -12.682032   \n",
       "2         -11.759039        -12.328451        -14.081113      -12.653586   \n",
       "3         -11.846595        -12.299294        -13.887178      -12.690948   \n",
       "4         -12.103193        -12.414796        -13.641420      -12.827127   \n",
       "..               ...               ...               ...             ...   \n",
       "15        -14.332106        -14.811334        -16.471302      -14.670439   \n",
       "16        -14.118527        -14.676170        -16.323496      -14.489461   \n",
       "17        -13.841625        -14.510670        -16.168705      -14.297509   \n",
       "18        -13.544225        -14.359759        -16.066449      -14.145683   \n",
       "19        -13.287394        -14.285354        -16.064486      -14.090256   \n",
       "\n",
       "    std_test_Mape  rank_test_Mape  \n",
       "0        0.929564               4  \n",
       "1        0.909146               2  \n",
       "2        0.884710               1  \n",
       "3        0.830128               3  \n",
       "4        0.755454               6  \n",
       "..            ...             ...  \n",
       "15       1.016353              20  \n",
       "16       1.032306              19  \n",
       "17       1.041296              18  \n",
       "18       1.045918              17  \n",
       "19       1.055356              16  \n",
       "\n",
       "[20 rows x 31 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option(\"display.max_rows\", 10)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "\n",
    "KgridSearch_results = pd.DataFrame(KgridSearch.cv_results_)\n",
    "KgridSearch_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_Mape</th>\n",
       "      <th>mean_test_R-squared</th>\n",
       "      <th>mean_test_Adjusted R-squared</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-12.723901</td>\n",
       "      <td>0.773006</td>\n",
       "      <td>-0.773006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-12.682032</td>\n",
       "      <td>0.776497</td>\n",
       "      <td>-0.776497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-12.653586</td>\n",
       "      <td>0.780422</td>\n",
       "      <td>-0.780422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-12.690948</td>\n",
       "      <td>0.784773</td>\n",
       "      <td>-0.784773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-12.827127</td>\n",
       "      <td>0.789284</td>\n",
       "      <td>-0.789284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-13.739536</td>\n",
       "      <td>0.732477</td>\n",
       "      <td>-0.732477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-13.643677</td>\n",
       "      <td>0.736326</td>\n",
       "      <td>-0.736326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-13.492324</td>\n",
       "      <td>0.742057</td>\n",
       "      <td>-0.742057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-13.221669</td>\n",
       "      <td>0.751591</td>\n",
       "      <td>-0.751591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-12.749628</td>\n",
       "      <td>0.771366</td>\n",
       "      <td>-0.771366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-14.083935</td>\n",
       "      <td>0.713980</td>\n",
       "      <td>-0.713980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-14.080479</td>\n",
       "      <td>0.715147</td>\n",
       "      <td>-0.715147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-14.068816</td>\n",
       "      <td>0.716772</td>\n",
       "      <td>-0.716772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-14.024723</td>\n",
       "      <td>0.719786</td>\n",
       "      <td>-0.719786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-13.780543</td>\n",
       "      <td>0.730825</td>\n",
       "      <td>-0.730825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-14.670439</td>\n",
       "      <td>0.686291</td>\n",
       "      <td>-0.686291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-14.489461</td>\n",
       "      <td>0.691790</td>\n",
       "      <td>-0.691790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-14.297509</td>\n",
       "      <td>0.698146</td>\n",
       "      <td>-0.698146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-14.145683</td>\n",
       "      <td>0.705319</td>\n",
       "      <td>-0.705319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-14.090256</td>\n",
       "      <td>0.713202</td>\n",
       "      <td>-0.713202</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_test_Mape  mean_test_R-squared  mean_test_Adjusted R-squared\n",
       "0       -12.723901             0.773006                     -0.773006\n",
       "1       -12.682032             0.776497                     -0.776497\n",
       "2       -12.653586             0.780422                     -0.780422\n",
       "3       -12.690948             0.784773                     -0.784773\n",
       "4       -12.827127             0.789284                     -0.789284\n",
       "5       -13.739536             0.732477                     -0.732477\n",
       "6       -13.643677             0.736326                     -0.736326\n",
       "7       -13.492324             0.742057                     -0.742057\n",
       "8       -13.221669             0.751591                     -0.751591\n",
       "9       -12.749628             0.771366                     -0.771366\n",
       "10      -14.083935             0.713980                     -0.713980\n",
       "11      -14.080479             0.715147                     -0.715147\n",
       "12      -14.068816             0.716772                     -0.716772\n",
       "13      -14.024723             0.719786                     -0.719786\n",
       "14      -13.780543             0.730825                     -0.730825\n",
       "15      -14.670439             0.686291                     -0.686291\n",
       "16      -14.489461             0.691790                     -0.691790\n",
       "17      -14.297509             0.698146                     -0.698146\n",
       "18      -14.145683             0.705319                     -0.705319\n",
       "19      -14.090256             0.713202                     -0.713202"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option(\"display.max_rows\", None)\n",
    "\n",
    "KgridSearch_results[\n",
    "    [\"mean_test_Mape\", \"mean_test_R-squared\", \"mean_test_Adjusted R-squared\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the coefficients of the best model\n",
    "Kcoefficients = KgridSearch.best_estimator_.coef_\n",
    "\n",
    "# Get the feature names\n",
    "Kfeature_names = X_Kbest.columns\n",
    "\n",
    "# Create a DataFrame to display the coefficients and corresponding feature names\n",
    "Kcoeff_df = pd.DataFrame(\n",
    "    {\"Feature\": Kfeature_names, \"Coefficient\": Kcoefficients}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Coefficient</th>\n",
       "      <th>absolute_coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TotalBsmtSF</td>\n",
       "      <td>12.532515</td>\n",
       "      <td>12.532515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1stFlrSF</td>\n",
       "      <td>13.007197</td>\n",
       "      <td>13.007197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MasVnrArea</td>\n",
       "      <td>22.087272</td>\n",
       "      <td>22.087272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GrLivArea</td>\n",
       "      <td>38.272475</td>\n",
       "      <td>38.272475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GarageArea</td>\n",
       "      <td>40.985647</td>\n",
       "      <td>40.985647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>random</td>\n",
       "      <td>-144.584682</td>\n",
       "      <td>144.584682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>YearBuilt</td>\n",
       "      <td>245.520636</td>\n",
       "      <td>245.520636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>YearRemodAdd</td>\n",
       "      <td>338.336269</td>\n",
       "      <td>338.336269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TotRmsAbvGrd</td>\n",
       "      <td>459.360790</td>\n",
       "      <td>459.360790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>FullBath</td>\n",
       "      <td>-607.363485</td>\n",
       "      <td>607.363485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Foundation_PConc</td>\n",
       "      <td>892.228957</td>\n",
       "      <td>892.228957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>GarageCars</td>\n",
       "      <td>1542.275943</td>\n",
       "      <td>1542.275943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Fireplaces</td>\n",
       "      <td>1547.963594</td>\n",
       "      <td>1547.963594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>HeatingQC</td>\n",
       "      <td>1759.689173</td>\n",
       "      <td>1759.689173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>GarageFinish</td>\n",
       "      <td>1811.118923</td>\n",
       "      <td>1811.118923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Neighborhood_NridgHt</td>\n",
       "      <td>2110.381569</td>\n",
       "      <td>2110.381569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ExterQual</td>\n",
       "      <td>3362.149291</td>\n",
       "      <td>3362.149291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>BsmtQual</td>\n",
       "      <td>3725.047488</td>\n",
       "      <td>3725.047488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>FireplaceQu</td>\n",
       "      <td>3804.584072</td>\n",
       "      <td>3804.584072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>KitchenQual</td>\n",
       "      <td>4134.074885</td>\n",
       "      <td>4134.074885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>OverallQual</td>\n",
       "      <td>8133.732052</td>\n",
       "      <td>8133.732052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Feature  Coefficient  absolute_coefficient\n",
       "0            TotalBsmtSF    12.532515             12.532515\n",
       "1               1stFlrSF    13.007197             13.007197\n",
       "2             MasVnrArea    22.087272             22.087272\n",
       "3              GrLivArea    38.272475             38.272475\n",
       "4             GarageArea    40.985647             40.985647\n",
       "5                 random  -144.584682            144.584682\n",
       "6              YearBuilt   245.520636            245.520636\n",
       "7           YearRemodAdd   338.336269            338.336269\n",
       "8           TotRmsAbvGrd   459.360790            459.360790\n",
       "9               FullBath  -607.363485            607.363485\n",
       "10      Foundation_PConc   892.228957            892.228957\n",
       "11            GarageCars  1542.275943           1542.275943\n",
       "12            Fireplaces  1547.963594           1547.963594\n",
       "13             HeatingQC  1759.689173           1759.689173\n",
       "14          GarageFinish  1811.118923           1811.118923\n",
       "15  Neighborhood_NridgHt  2110.381569           2110.381569\n",
       "16             ExterQual  3362.149291           3362.149291\n",
       "17              BsmtQual  3725.047488           3725.047488\n",
       "18           FireplaceQu  3804.584072           3804.584072\n",
       "19           KitchenQual  4134.074885           4134.074885\n",
       "20           OverallQual  8133.732052           8133.732052"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option(\"display.max_rows\", None)\n",
    "\n",
    "\n",
    "Kcoeff_df \\\n",
    ".assign(absolute_coefficient=lambda df_: df_[\"Coefficient\"].abs()) \\\n",
    ".sort_values(by=\"absolute_coefficient\", ascending=True) \\\n",
    ".reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polynomial Regression - KBest\n",
    "\n",
    "Polynomial Regression is very computionaly intensive. We will be restricting it to the dataset containing only the K-best features. It is also the occasion to use a simple pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_reg = make_pipeline(\n",
    "    PolynomialFeatures(2),\n",
    "    GridSearchCV(\n",
    "        estimator=ElasticNet(max_iter=50000),\n",
    "        param_grid=param_grid,\n",
    "        scoring=scoring,\n",
    "        verbose=3,\n",
    "        n_jobs=-1,\n",
    "        cv=5,\n",
    "        return_train_score=True,\n",
    "        refit=\"Mape\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.020e+11, tolerance: 5.643e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END alpha=1, l1_ratio=0.1; Adjusted R-squared: (train=-0.895, test=-0.870) Mape: (train=-10.238, test=-10.888) R-squared: (train=0.895, test=0.870) total time=  19.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.008e+11, tolerance: 5.643e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END alpha=1, l1_ratio=0.3; Adjusted R-squared: (train=-0.895, test=-0.869) Mape: (train=-10.218, test=-10.931) R-squared: (train=0.895, test=0.869) total time=  19.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.860e+11, tolerance: 5.794e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.917e+11, tolerance: 5.615e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END alpha=1, l1_ratio=0.1; Adjusted R-squared: (train=-0.902, test=-0.811) Mape: (train=-10.000, test=-12.128) R-squared: (train=0.902, test=0.811) total time=  22.5s\n",
      "[CV 3/5] END alpha=1, l1_ratio=0.1; Adjusted R-squared: (train=-0.897, test=-0.862) Mape: (train=-10.145, test=-10.959) R-squared: (train=0.897, test=0.862) total time=  22.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.908e+11, tolerance: 5.615e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END alpha=1, l1_ratio=0.3; Adjusted R-squared: (train=-0.898, test=-0.862) Mape: (train=-10.129, test=-10.962) R-squared: (train=0.898, test=0.862) total time=  22.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.069e+11, tolerance: 5.915e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.672e+11, tolerance: 5.309e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.680e+11, tolerance: 5.309e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END alpha=1, l1_ratio=0.1; Adjusted R-squared: (train=-0.898, test=-0.852) Mape: (train=-10.009, test=-12.008) R-squared: (train=0.898, test=0.852) total time=  23.4s\n",
      "[CV 2/5] END alpha=1, l1_ratio=0.3; Adjusted R-squared: (train=-0.901, test=-0.741) Mape: (train=-9.524, test=-12.676) R-squared: (train=0.901, test=0.741) total time=  23.4s\n",
      "[CV 2/5] END alpha=1, l1_ratio=0.1; Adjusted R-squared: (train=-0.900, test=-0.743) Mape: (train=-9.547, test=-12.648) R-squared: (train=0.900, test=0.743) total time=  23.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.992e+11, tolerance: 5.643e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END alpha=1, l1_ratio=0.5; Adjusted R-squared: (train=-0.896, test=-0.868) Mape: (train=-10.190, test=-10.985) R-squared: (train=0.896, test=0.868) total time=  24.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.057e+11, tolerance: 5.915e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.851e+11, tolerance: 5.794e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END alpha=1, l1_ratio=0.3; Adjusted R-squared: (train=-0.898, test=-0.851) Mape: (train=-9.985, test=-12.018) R-squared: (train=0.898, test=0.851) total time=  27.7s\n",
      "[CV 5/5] END alpha=1, l1_ratio=0.3; Adjusted R-squared: (train=-0.903, test=-0.810) Mape: (train=-9.978, test=-12.146) R-squared: (train=0.903, test=0.810) total time=  27.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.965e+11, tolerance: 5.643e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END alpha=1, l1_ratio=0.7; Adjusted R-squared: (train=-0.897, test=-0.867) Mape: (train=-10.148, test=-11.065) R-squared: (train=0.897, test=0.867) total time=  24.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.660e+11, tolerance: 5.309e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.896e+11, tolerance: 5.615e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END alpha=1, l1_ratio=0.5; Adjusted R-squared: (train=-0.901, test=-0.739) Mape: (train=-9.491, test=-12.712) R-squared: (train=0.901, test=0.739) total time=  28.1s\n",
      "[CV 3/5] END alpha=1, l1_ratio=0.5; Adjusted R-squared: (train=-0.898, test=-0.862) Mape: (train=-10.106, test=-10.974) R-squared: (train=0.898, test=0.862) total time=  27.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.838e+11, tolerance: 5.794e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.040e+11, tolerance: 5.915e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END alpha=1, l1_ratio=0.5; Adjusted R-squared: (train=-0.903, test=-0.807) Mape: (train=-9.947, test=-12.186) R-squared: (train=0.903, test=0.807) total time=  28.0s\n",
      "[CV 4/5] END alpha=1, l1_ratio=0.5; Adjusted R-squared: (train=-0.899, test=-0.850) Mape: (train=-9.951, test=-12.036) R-squared: (train=0.899, test=0.850) total time=  28.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.639e+11, tolerance: 5.309e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END alpha=1, l1_ratio=0.7; Adjusted R-squared: (train=-0.902, test=-0.738) Mape: (train=-9.441, test=-12.779) R-squared: (train=0.902, test=0.738) total time=  28.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.011e+11, tolerance: 5.915e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.875e+11, tolerance: 5.615e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END alpha=1, l1_ratio=0.7; Adjusted R-squared: (train=-0.900, test=-0.849) Mape: (train=-9.894, test=-12.068) R-squared: (train=0.900, test=0.849) total time=  28.5s\n",
      "[CV 3/5] END alpha=1, l1_ratio=0.7; Adjusted R-squared: (train=-0.899, test=-0.862) Mape: (train=-10.072, test=-11.005) R-squared: (train=0.899, test=0.862) total time=  28.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.816e+11, tolerance: 5.794e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END alpha=1, l1_ratio=0.7; Adjusted R-squared: (train=-0.904, test=-0.802) Mape: (train=-9.898, test=-12.262) R-squared: (train=0.904, test=0.802) total time=  28.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.901e+11, tolerance: 5.643e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END alpha=1, l1_ratio=0.9; Adjusted R-squared: (train=-0.899, test=-0.863) Mape: (train=-10.094, test=-11.206) R-squared: (train=0.899, test=0.863) total time=  26.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.822e+11, tolerance: 5.615e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END alpha=1, l1_ratio=0.9; Adjusted R-squared: (train=-0.901, test=-0.861) Mape: (train=-9.998, test=-11.078) R-squared: (train=0.901, test=0.861) total time=  28.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.583e+11, tolerance: 5.309e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END alpha=1, l1_ratio=0.9; Adjusted R-squared: (train=-0.905, test=-0.744) Mape: (train=-9.334, test=-12.947) R-squared: (train=0.905, test=0.744) total time=  29.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.937e+11, tolerance: 5.915e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END alpha=1, l1_ratio=0.9; Adjusted R-squared: (train=-0.903, test=-0.843) Mape: (train=-9.779, test=-12.208) R-squared: (train=0.903, test=0.843) total time=  29.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.099e+11, tolerance: 5.643e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END alpha=10, l1_ratio=0.1; Adjusted R-squared: (train=-0.891, test=-0.875) Mape: (train=-10.394, test=-10.606) R-squared: (train=0.891, test=0.875) total time=  27.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.760e+11, tolerance: 5.794e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END alpha=1, l1_ratio=0.9; Adjusted R-squared: (train=-0.907, test=-0.784) Mape: (train=-9.780, test=-12.521) R-squared: (train=0.907, test=0.784) total time=  30.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.728e+11, tolerance: 5.309e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END alpha=10, l1_ratio=0.1; Adjusted R-squared: (train=-0.898, test=-0.769) Mape: (train=-9.671, test=-12.416) R-squared: (train=0.898, test=0.769) total time=  29.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.972e+11, tolerance: 5.615e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END alpha=10, l1_ratio=0.1; Adjusted R-squared: (train=-0.895, test=-0.862) Mape: (train=-10.266, test=-10.982) R-squared: (train=0.895, test=0.862) total time=  30.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.093e+11, tolerance: 5.643e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.138e+11, tolerance: 5.915e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END alpha=10, l1_ratio=0.3; Adjusted R-squared: (train=-0.891, test=-0.875) Mape: (train=-10.381, test=-10.628) R-squared: (train=0.891, test=0.875) total time=  26.9s\n",
      "[CV 4/5] END alpha=10, l1_ratio=0.1; Adjusted R-squared: (train=-0.895, test=-0.854) Mape: (train=-10.179, test=-11.987) R-squared: (train=0.895, test=0.854) total time=  30.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.915e+11, tolerance: 5.794e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END alpha=10, l1_ratio=0.1; Adjusted R-squared: (train=-0.900, test=-0.819) Mape: (train=-10.141, test=-12.009) R-squared: (train=0.900, test=0.819) total time=  30.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.724e+11, tolerance: 5.309e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END alpha=10, l1_ratio=0.3; Adjusted R-squared: (train=-0.898, test=-0.767) Mape: (train=-9.664, test=-12.435) R-squared: (train=0.898, test=0.767) total time=  30.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.084e+11, tolerance: 5.643e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END alpha=10, l1_ratio=0.5; Adjusted R-squared: (train=-0.892, test=-0.874) Mape: (train=-10.362, test=-10.659) R-squared: (train=0.892, test=0.874) total time=  24.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.968e+11, tolerance: 5.615e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END alpha=10, l1_ratio=0.3; Adjusted R-squared: (train=-0.895, test=-0.862) Mape: (train=-10.256, test=-10.983) R-squared: (train=0.895, test=0.862) total time=  28.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.911e+11, tolerance: 5.794e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.133e+11, tolerance: 5.915e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END alpha=10, l1_ratio=0.3; Adjusted R-squared: (train=-0.900, test=-0.818) Mape: (train=-10.130, test=-12.022) R-squared: (train=0.900, test=0.818) total time=  28.5s\n",
      "[CV 4/5] END alpha=10, l1_ratio=0.3; Adjusted R-squared: (train=-0.895, test=-0.854) Mape: (train=-10.168, test=-11.984) R-squared: (train=0.895, test=0.854) total time=  28.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.961e+11, tolerance: 5.615e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END alpha=10, l1_ratio=0.5; Adjusted R-squared: (train=-0.895, test=-0.862) Mape: (train=-10.241, test=-10.982) R-squared: (train=0.895, test=0.862) total time=  28.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.719e+11, tolerance: 5.309e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END alpha=10, l1_ratio=0.5; Adjusted R-squared: (train=-0.898, test=-0.765) Mape: (train=-9.652, test=-12.464) R-squared: (train=0.898, test=0.765) total time=  29.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.126e+11, tolerance: 5.915e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END alpha=10, l1_ratio=0.5; Adjusted R-squared: (train=-0.895, test=-0.854) Mape: (train=-10.149, test=-11.980) R-squared: (train=0.895, test=0.854) total time=  28.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.905e+11, tolerance: 5.794e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END alpha=10, l1_ratio=0.5; Adjusted R-squared: (train=-0.900, test=-0.818) Mape: (train=-10.113, test=-12.036) R-squared: (train=0.900, test=0.818) total time=  28.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.069e+11, tolerance: 5.643e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END alpha=10, l1_ratio=0.7; Adjusted R-squared: (train=-0.892, test=-0.873) Mape: (train=-10.331, test=-10.715) R-squared: (train=0.892, test=0.873) total time=  25.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.710e+11, tolerance: 5.309e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END alpha=10, l1_ratio=0.7; Adjusted R-squared: (train=-0.899, test=-0.760) Mape: (train=-9.630, test=-12.512) R-squared: (train=0.899, test=0.760) total time=  31.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.027e+11, tolerance: 5.643e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END alpha=10, l1_ratio=0.9; Adjusted R-squared: (train=-0.894, test=-0.870) Mape: (train=-10.248, test=-10.870) R-squared: (train=0.894, test=0.870) total time=  28.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.951e+11, tolerance: 5.615e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.113e+11, tolerance: 5.915e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END alpha=10, l1_ratio=0.7; Adjusted R-squared: (train=-0.896, test=-0.862) Mape: (train=-10.217, test=-10.977) R-squared: (train=0.896, test=0.862) total time=  32.0s\n",
      "[CV 4/5] END alpha=10, l1_ratio=0.7; Adjusted R-squared: (train=-0.896, test=-0.854) Mape: (train=-10.115, test=-11.978) R-squared: (train=0.896, test=0.854) total time=  32.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.894e+11, tolerance: 5.794e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END alpha=10, l1_ratio=0.7; Adjusted R-squared: (train=-0.901, test=-0.816) Mape: (train=-10.085, test=-12.059) R-squared: (train=0.901, test=0.816) total time=  32.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.922e+11, tolerance: 5.615e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.685e+11, tolerance: 5.309e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END alpha=10, l1_ratio=0.9; Adjusted R-squared: (train=-0.897, test=-0.862) Mape: (train=-10.154, test=-10.959) R-squared: (train=0.897, test=0.862) total time=  32.0s\n",
      "[CV 2/5] END alpha=10, l1_ratio=0.9; Adjusted R-squared: (train=-0.900, test=-0.746) Mape: (train=-9.559, test=-12.628) R-squared: (train=0.900, test=0.746) total time=  32.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.076e+11, tolerance: 5.915e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END alpha=10, l1_ratio=0.9; Adjusted R-squared: (train=-0.897, test=-0.852) Mape: (train=-10.022, test=-12.003) R-squared: (train=0.897, test=0.852) total time=  31.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.143e+11, tolerance: 5.643e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END alpha=100, l1_ratio=0.1; Adjusted R-squared: (train=-0.889, test=-0.877) Mape: (train=-10.459, test=-10.406) R-squared: (train=0.889, test=0.877) total time=  26.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.865e+11, tolerance: 5.794e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END alpha=10, l1_ratio=0.9; Adjusted R-squared: (train=-0.902, test=-0.812) Mape: (train=-10.011, test=-12.117) R-squared: (train=0.902, test=0.812) total time=  30.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.014e+11, tolerance: 5.615e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END alpha=100, l1_ratio=0.1; Adjusted R-squared: (train=-0.893, test=-0.863) Mape: (train=-10.291, test=-10.887) R-squared: (train=0.893, test=0.863) total time=  29.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.139e+11, tolerance: 5.643e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.763e+11, tolerance: 5.309e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END alpha=100, l1_ratio=0.3; Adjusted R-squared: (train=-0.890, test=-0.877) Mape: (train=-10.455, test=-10.430) R-squared: (train=0.890, test=0.877) total time=  25.0s\n",
      "[CV 2/5] END alpha=100, l1_ratio=0.1; Adjusted R-squared: (train=-0.897, test=-0.776) Mape: (train=-9.714, test=-12.253) R-squared: (train=0.897, test=0.776) total time=  30.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.189e+11, tolerance: 5.915e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END alpha=100, l1_ratio=0.1; Adjusted R-squared: (train=-0.893, test=-0.855) Mape: (train=-10.210, test=-12.011) R-squared: (train=0.893, test=0.855) total time=  28.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.960e+11, tolerance: 5.794e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END alpha=100, l1_ratio=0.1; Adjusted R-squared: (train=-0.899, test=-0.824) Mape: (train=-10.201, test=-11.799) R-squared: (train=0.899, test=0.824) total time=  29.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.760e+11, tolerance: 5.309e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END alpha=100, l1_ratio=0.3; Adjusted R-squared: (train=-0.897, test=-0.776) Mape: (train=-9.711, test=-12.262) R-squared: (train=0.897, test=0.776) total time=  29.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.010e+11, tolerance: 5.615e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END alpha=100, l1_ratio=0.3; Adjusted R-squared: (train=-0.894, test=-0.862) Mape: (train=-10.291, test=-10.901) R-squared: (train=0.894, test=0.862) total time=  29.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.133e+11, tolerance: 5.643e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END alpha=100, l1_ratio=0.5; Adjusted R-squared: (train=-0.890, test=-0.877) Mape: (train=-10.450, test=-10.462) R-squared: (train=0.890, test=0.877) total time=  24.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.183e+11, tolerance: 5.915e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END alpha=100, l1_ratio=0.3; Adjusted R-squared: (train=-0.893, test=-0.855) Mape: (train=-10.209, test=-12.015) R-squared: (train=0.893, test=0.855) total time=  29.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.954e+11, tolerance: 5.794e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END alpha=100, l1_ratio=0.3; Adjusted R-squared: (train=-0.899, test=-0.824) Mape: (train=-10.196, test=-11.830) R-squared: (train=0.899, test=0.824) total time=  28.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.004e+11, tolerance: 5.615e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.755e+11, tolerance: 5.309e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END alpha=100, l1_ratio=0.5; Adjusted R-squared: (train=-0.894, test=-0.862) Mape: (train=-10.291, test=-10.920) R-squared: (train=0.894, test=0.862) total time=  28.1s\n",
      "[CV 2/5] END alpha=100, l1_ratio=0.5; Adjusted R-squared: (train=-0.897, test=-0.775) Mape: (train=-9.706, test=-12.279) R-squared: (train=0.897, test=0.775) total time=  28.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.175e+11, tolerance: 5.915e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END alpha=100, l1_ratio=0.5; Adjusted R-squared: (train=-0.893, test=-0.855) Mape: (train=-10.208, test=-12.018) R-squared: (train=0.893, test=0.855) total time=  28.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.124e+11, tolerance: 5.643e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END alpha=100, l1_ratio=0.7; Adjusted R-squared: (train=-0.890, test=-0.876) Mape: (train=-10.441, test=-10.504) R-squared: (train=0.890, test=0.876) total time=  24.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.947e+11, tolerance: 5.794e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END alpha=100, l1_ratio=0.5; Adjusted R-squared: (train=-0.899, test=-0.823) Mape: (train=-10.190, test=-11.869) R-squared: (train=0.899, test=0.823) total time=  27.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.748e+11, tolerance: 5.309e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END alpha=100, l1_ratio=0.7; Adjusted R-squared: (train=-0.897, test=-0.774) Mape: (train=-9.697, test=-12.310) R-squared: (train=0.897, test=0.774) total time=  27.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.106e+11, tolerance: 5.643e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END alpha=100, l1_ratio=0.9; Adjusted R-squared: (train=-0.891, test=-0.875) Mape: (train=-10.404, test=-10.590) R-squared: (train=0.891, test=0.875) total time=  24.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.995e+11, tolerance: 5.615e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END alpha=100, l1_ratio=0.7; Adjusted R-squared: (train=-0.894, test=-0.862) Mape: (train=-10.289, test=-10.943) R-squared: (train=0.894, test=0.862) total time=  27.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.165e+11, tolerance: 5.915e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END alpha=100, l1_ratio=0.7; Adjusted R-squared: (train=-0.894, test=-0.854) Mape: (train=-10.208, test=-12.016) R-squared: (train=0.894, test=0.854) total time=  27.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.938e+11, tolerance: 5.794e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END alpha=100, l1_ratio=0.7; Adjusted R-squared: (train=-0.899, test=-0.822) Mape: (train=-10.180, test=-11.915) R-squared: (train=0.899, test=0.822) total time=  27.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.734e+11, tolerance: 5.309e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END alpha=100, l1_ratio=0.9; Adjusted R-squared: (train=-0.898, test=-0.771) Mape: (train=-9.678, test=-12.385) R-squared: (train=0.898, test=0.771) total time=  27.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.145e+11, tolerance: 5.915e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.979e+11, tolerance: 5.615e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END alpha=100, l1_ratio=0.9; Adjusted R-squared: (train=-0.894, test=-0.854) Mape: (train=-10.187, test=-11.988) R-squared: (train=0.894, test=0.854) total time=  27.4s\n",
      "[CV 3/5] END alpha=100, l1_ratio=0.9; Adjusted R-squared: (train=-0.895, test=-0.862) Mape: (train=-10.273, test=-10.976) R-squared: (train=0.895, test=0.862) total time=  28.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.213e+11, tolerance: 5.643e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END alpha=1000, l1_ratio=0.1; Adjusted R-squared: (train=-0.888, test=-0.881) Mape: (train=-10.512, test=-10.215) R-squared: (train=0.888, test=0.881) total time=  24.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.922e+11, tolerance: 5.794e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END alpha=100, l1_ratio=0.9; Adjusted R-squared: (train=-0.900, test=-0.820) Mape: (train=-10.151, test=-11.999) R-squared: (train=0.900, test=0.820) total time=  26.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.811e+11, tolerance: 5.309e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END alpha=1000, l1_ratio=0.1; Adjusted R-squared: (train=-0.895, test=-0.781) Mape: (train=-9.757, test=-12.134) R-squared: (train=0.895, test=0.781) total time=  28.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.074e+11, tolerance: 5.615e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END alpha=1000, l1_ratio=0.1; Adjusted R-squared: (train=-0.892, test=-0.863) Mape: (train=-10.329, test=-10.815) R-squared: (train=0.892, test=0.863) total time=  27.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.267e+11, tolerance: 5.915e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END alpha=1000, l1_ratio=0.1; Adjusted R-squared: (train=-0.891, test=-0.860) Mape: (train=-10.250, test=-11.840) R-squared: (train=0.891, test=0.860) total time=  28.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.045e+11, tolerance: 5.794e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END alpha=1000, l1_ratio=0.1; Adjusted R-squared: (train=-0.897, test=-0.829) Mape: (train=-10.260, test=-11.793) R-squared: (train=0.897, test=0.829) total time=  28.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.203e+11, tolerance: 5.643e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END alpha=1000, l1_ratio=0.3; Adjusted R-squared: (train=-0.888, test=-0.881) Mape: (train=-10.506, test=-10.225) R-squared: (train=0.888, test=0.881) total time=  23.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.804e+11, tolerance: 5.309e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END alpha=1000, l1_ratio=0.3; Adjusted R-squared: (train=-0.895, test=-0.780) Mape: (train=-9.755, test=-12.154) R-squared: (train=0.895, test=0.780) total time=  26.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.067e+11, tolerance: 5.615e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END alpha=1000, l1_ratio=0.3; Adjusted R-squared: (train=-0.892, test=-0.863) Mape: (train=-10.324, test=-10.820) R-squared: (train=0.892, test=0.863) total time=  26.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.192e+11, tolerance: 5.643e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END alpha=1000, l1_ratio=0.5; Adjusted R-squared: (train=-0.888, test=-0.880) Mape: (train=-10.498, test=-10.241) R-squared: (train=0.888, test=0.880) total time=  22.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.256e+11, tolerance: 5.915e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END alpha=1000, l1_ratio=0.3; Adjusted R-squared: (train=-0.891, test=-0.860) Mape: (train=-10.245, test=-11.867) R-squared: (train=0.891, test=0.860) total time=  26.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.796e+11, tolerance: 5.309e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END alpha=1000, l1_ratio=0.5; Adjusted R-squared: (train=-0.896, test=-0.780) Mape: (train=-9.750, test=-12.176) R-squared: (train=0.896, test=0.780) total time=  25.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.033e+11, tolerance: 5.794e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END alpha=1000, l1_ratio=0.3; Adjusted R-squared: (train=-0.897, test=-0.828) Mape: (train=-10.251, test=-11.798) R-squared: (train=0.897, test=0.828) total time=  27.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.057e+11, tolerance: 5.615e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END alpha=1000, l1_ratio=0.5; Adjusted R-squared: (train=-0.892, test=-0.863) Mape: (train=-10.316, test=-10.825) R-squared: (train=0.892, test=0.863) total time=  25.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.244e+11, tolerance: 5.915e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END alpha=1000, l1_ratio=0.5; Adjusted R-squared: (train=-0.892, test=-0.859) Mape: (train=-10.238, test=-11.900) R-squared: (train=0.892, test=0.859) total time=  25.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.178e+11, tolerance: 5.643e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END alpha=1000, l1_ratio=0.7; Adjusted R-squared: (train=-0.889, test=-0.879) Mape: (train=-10.484, test=-10.270) R-squared: (train=0.889, test=0.879) total time=  21.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.018e+11, tolerance: 5.794e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END alpha=1000, l1_ratio=0.5; Adjusted R-squared: (train=-0.897, test=-0.828) Mape: (train=-10.241, test=-11.798) R-squared: (train=0.897, test=0.828) total time=  25.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.785e+11, tolerance: 5.309e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END alpha=1000, l1_ratio=0.7; Adjusted R-squared: (train=-0.896, test=-0.779) Mape: (train=-9.741, test=-12.203) R-squared: (train=0.896, test=0.779) total time=  24.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.045e+11, tolerance: 5.615e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END alpha=1000, l1_ratio=0.7; Adjusted R-squared: (train=-0.892, test=-0.863) Mape: (train=-10.307, test=-10.831) R-squared: (train=0.892, test=0.863) total time=  24.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.228e+11, tolerance: 5.915e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END alpha=1000, l1_ratio=0.7; Adjusted R-squared: (train=-0.892, test=-0.858) Mape: (train=-10.229, test=-11.941) R-squared: (train=0.892, test=0.858) total time=  24.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.000e+11, tolerance: 5.794e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END alpha=1000, l1_ratio=0.7; Adjusted R-squared: (train=-0.898, test=-0.827) Mape: (train=-10.229, test=-11.787) R-squared: (train=0.898, test=0.827) total time=  24.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.154e+11, tolerance: 5.643e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END alpha=1000, l1_ratio=0.9; Adjusted R-squared: (train=-0.889, test=-0.878) Mape: (train=-10.464, test=-10.362) R-squared: (train=0.889, test=0.878) total time=  20.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.772e+11, tolerance: 5.309e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END alpha=1000, l1_ratio=0.9; Adjusted R-squared: (train=-0.896, test=-0.777) Mape: (train=-9.722, test=-12.235) R-squared: (train=0.896, test=0.777) total time=  19.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.024e+11, tolerance: 5.615e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END alpha=1000, l1_ratio=0.9; Adjusted R-squared: (train=-0.893, test=-0.863) Mape: (train=-10.291, test=-10.870) R-squared: (train=0.893, test=0.863) total time=  19.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.200e+11, tolerance: 5.915e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.970e+11, tolerance: 5.794e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END alpha=1000, l1_ratio=0.9; Adjusted R-squared: (train=-0.893, test=-0.856) Mape: (train=-10.211, test=-11.997) R-squared: (train=0.893, test=0.856) total time=  18.1s\n",
      "[CV 5/5] END alpha=1000, l1_ratio=0.9; Adjusted R-squared: (train=-0.898, test=-0.825) Mape: (train=-10.212, test=-11.778) R-squared: (train=0.898, test=0.825) total time=  17.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.987e+11, tolerance: 7.070e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;polynomialfeatures&#x27;, PolynomialFeatures()),\n",
       "                (&#x27;gridsearchcv&#x27;,\n",
       "                 GridSearchCV(cv=5, estimator=ElasticNet(max_iter=50000),\n",
       "                              n_jobs=-1,\n",
       "                              param_grid={&#x27;alpha&#x27;: [1, 10, 100, 1000],\n",
       "                                          &#x27;l1_ratio&#x27;: [0.1, 0.3, 0.5, 0.7,\n",
       "                                                       0.9]},\n",
       "                              refit=&#x27;Mape&#x27;, return_train_score=True,\n",
       "                              scoring={&#x27;Adjusted R-squared&#x27;: make_scorer(r2_score, greater_is_better=False),\n",
       "                                       &#x27;Mape&#x27;: make_scorer(mape, greater_is_better=False),\n",
       "                                       &#x27;R-squared&#x27;: make_scorer(r2_score)},\n",
       "                              verbose=3))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;polynomialfeatures&#x27;, PolynomialFeatures()),\n",
       "                (&#x27;gridsearchcv&#x27;,\n",
       "                 GridSearchCV(cv=5, estimator=ElasticNet(max_iter=50000),\n",
       "                              n_jobs=-1,\n",
       "                              param_grid={&#x27;alpha&#x27;: [1, 10, 100, 1000],\n",
       "                                          &#x27;l1_ratio&#x27;: [0.1, 0.3, 0.5, 0.7,\n",
       "                                                       0.9]},\n",
       "                              refit=&#x27;Mape&#x27;, return_train_score=True,\n",
       "                              scoring={&#x27;Adjusted R-squared&#x27;: make_scorer(r2_score, greater_is_better=False),\n",
       "                                       &#x27;Mape&#x27;: make_scorer(mape, greater_is_better=False),\n",
       "                                       &#x27;R-squared&#x27;: make_scorer(r2_score)},\n",
       "                              verbose=3))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PolynomialFeatures</label><div class=\"sk-toggleable__content\"><pre>PolynomialFeatures()</pre></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">gridsearchcv: GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=ElasticNet(max_iter=50000), n_jobs=-1,\n",
       "             param_grid={&#x27;alpha&#x27;: [1, 10, 100, 1000],\n",
       "                         &#x27;l1_ratio&#x27;: [0.1, 0.3, 0.5, 0.7, 0.9]},\n",
       "             refit=&#x27;Mape&#x27;, return_train_score=True,\n",
       "             scoring={&#x27;Adjusted R-squared&#x27;: make_scorer(r2_score, greater_is_better=False),\n",
       "                      &#x27;Mape&#x27;: make_scorer(mape, greater_is_better=False),\n",
       "                      &#x27;R-squared&#x27;: make_scorer(r2_score)},\n",
       "             verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: ElasticNet</label><div class=\"sk-toggleable__content\"><pre>ElasticNet(max_iter=50000)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ElasticNet</label><div class=\"sk-toggleable__content\"><pre>ElasticNet(max_iter=50000)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('polynomialfeatures', PolynomialFeatures()),\n",
       "                ('gridsearchcv',\n",
       "                 GridSearchCV(cv=5, estimator=ElasticNet(max_iter=50000),\n",
       "                              n_jobs=-1,\n",
       "                              param_grid={'alpha': [1, 10, 100, 1000],\n",
       "                                          'l1_ratio': [0.1, 0.3, 0.5, 0.7,\n",
       "                                                       0.9]},\n",
       "                              refit='Mape', return_train_score=True,\n",
       "                              scoring={'Adjusted R-squared': make_scorer(r2_score, greater_is_better=False),\n",
       "                                       'Mape': make_scorer(mape, greater_is_better=False),\n",
       "                                       'R-squared': make_scorer(r2_score)},\n",
       "                              verbose=3))])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly_reg.fit(X_Kbest, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>param_l1_ratio</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_R-squared</th>\n",
       "      <th>split1_test_R-squared</th>\n",
       "      <th>split2_test_R-squared</th>\n",
       "      <th>split3_test_R-squared</th>\n",
       "      <th>split4_test_R-squared</th>\n",
       "      <th>mean_test_R-squared</th>\n",
       "      <th>std_test_R-squared</th>\n",
       "      <th>rank_test_R-squared</th>\n",
       "      <th>split0_train_R-squared</th>\n",
       "      <th>split1_train_R-squared</th>\n",
       "      <th>split2_train_R-squared</th>\n",
       "      <th>split3_train_R-squared</th>\n",
       "      <th>split4_train_R-squared</th>\n",
       "      <th>mean_train_R-squared</th>\n",
       "      <th>std_train_R-squared</th>\n",
       "      <th>split0_test_Adjusted R-squared</th>\n",
       "      <th>split1_test_Adjusted R-squared</th>\n",
       "      <th>split2_test_Adjusted R-squared</th>\n",
       "      <th>split3_test_Adjusted R-squared</th>\n",
       "      <th>split4_test_Adjusted R-squared</th>\n",
       "      <th>mean_test_Adjusted R-squared</th>\n",
       "      <th>std_test_Adjusted R-squared</th>\n",
       "      <th>rank_test_Adjusted R-squared</th>\n",
       "      <th>split0_train_Adjusted R-squared</th>\n",
       "      <th>split1_train_Adjusted R-squared</th>\n",
       "      <th>split2_train_Adjusted R-squared</th>\n",
       "      <th>split3_train_Adjusted R-squared</th>\n",
       "      <th>split4_train_Adjusted R-squared</th>\n",
       "      <th>mean_train_Adjusted R-squared</th>\n",
       "      <th>std_train_Adjusted R-squared</th>\n",
       "      <th>split0_test_Mape</th>\n",
       "      <th>split1_test_Mape</th>\n",
       "      <th>split2_test_Mape</th>\n",
       "      <th>split3_test_Mape</th>\n",
       "      <th>split4_test_Mape</th>\n",
       "      <th>mean_test_Mape</th>\n",
       "      <th>std_test_Mape</th>\n",
       "      <th>rank_test_Mape</th>\n",
       "      <th>split0_train_Mape</th>\n",
       "      <th>split1_train_Mape</th>\n",
       "      <th>split2_train_Mape</th>\n",
       "      <th>split3_train_Mape</th>\n",
       "      <th>split4_train_Mape</th>\n",
       "      <th>mean_train_Mape</th>\n",
       "      <th>std_train_Mape</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.316146</td>\n",
       "      <td>1.463502</td>\n",
       "      <td>0.010546</td>\n",
       "      <td>0.003140</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'alpha': 1, 'l1_ratio': 0.1}</td>\n",
       "      <td>0.869888</td>\n",
       "      <td>0.743469</td>\n",
       "      <td>0.861695</td>\n",
       "      <td>0.852084</td>\n",
       "      <td>0.811486</td>\n",
       "      <td>0.827724</td>\n",
       "      <td>0.046665</td>\n",
       "      <td>16</td>\n",
       "      <td>0.894580</td>\n",
       "      <td>0.900298</td>\n",
       "      <td>0.897308</td>\n",
       "      <td>0.897762</td>\n",
       "      <td>0.902489</td>\n",
       "      <td>0.898488</td>\n",
       "      <td>0.002701</td>\n",
       "      <td>-0.869888</td>\n",
       "      <td>-0.743469</td>\n",
       "      <td>-0.861695</td>\n",
       "      <td>-0.852084</td>\n",
       "      <td>-0.811486</td>\n",
       "      <td>-0.827724</td>\n",
       "      <td>0.046665</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.894580</td>\n",
       "      <td>-0.900298</td>\n",
       "      <td>-0.897308</td>\n",
       "      <td>-0.897762</td>\n",
       "      <td>-0.902489</td>\n",
       "      <td>-0.898488</td>\n",
       "      <td>0.002701</td>\n",
       "      <td>-10.888462</td>\n",
       "      <td>-12.648174</td>\n",
       "      <td>-10.958588</td>\n",
       "      <td>-12.007608</td>\n",
       "      <td>-12.127554</td>\n",
       "      <td>-11.726077</td>\n",
       "      <td>0.690122</td>\n",
       "      <td>16</td>\n",
       "      <td>-10.237858</td>\n",
       "      <td>-9.547106</td>\n",
       "      <td>-10.145319</td>\n",
       "      <td>-10.009370</td>\n",
       "      <td>-9.999993</td>\n",
       "      <td>-9.987929</td>\n",
       "      <td>0.237557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24.268496</td>\n",
       "      <td>3.033492</td>\n",
       "      <td>0.006834</td>\n",
       "      <td>0.001421</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'alpha': 1, 'l1_ratio': 0.3}</td>\n",
       "      <td>0.869113</td>\n",
       "      <td>0.741084</td>\n",
       "      <td>0.861684</td>\n",
       "      <td>0.851456</td>\n",
       "      <td>0.809980</td>\n",
       "      <td>0.826663</td>\n",
       "      <td>0.047424</td>\n",
       "      <td>17</td>\n",
       "      <td>0.895082</td>\n",
       "      <td>0.900721</td>\n",
       "      <td>0.897700</td>\n",
       "      <td>0.898291</td>\n",
       "      <td>0.902889</td>\n",
       "      <td>0.898937</td>\n",
       "      <td>0.002669</td>\n",
       "      <td>-0.869113</td>\n",
       "      <td>-0.741084</td>\n",
       "      <td>-0.861684</td>\n",
       "      <td>-0.851456</td>\n",
       "      <td>-0.809980</td>\n",
       "      <td>-0.826663</td>\n",
       "      <td>0.047424</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.895082</td>\n",
       "      <td>-0.900721</td>\n",
       "      <td>-0.897700</td>\n",
       "      <td>-0.898291</td>\n",
       "      <td>-0.902889</td>\n",
       "      <td>-0.898937</td>\n",
       "      <td>0.002669</td>\n",
       "      <td>-10.930817</td>\n",
       "      <td>-12.676096</td>\n",
       "      <td>-10.961710</td>\n",
       "      <td>-12.018378</td>\n",
       "      <td>-12.145872</td>\n",
       "      <td>-11.746574</td>\n",
       "      <td>0.689754</td>\n",
       "      <td>17</td>\n",
       "      <td>-10.217546</td>\n",
       "      <td>-9.524290</td>\n",
       "      <td>-10.129064</td>\n",
       "      <td>-9.985047</td>\n",
       "      <td>-9.978091</td>\n",
       "      <td>-9.966808</td>\n",
       "      <td>0.238947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27.193180</td>\n",
       "      <td>1.582184</td>\n",
       "      <td>0.010249</td>\n",
       "      <td>0.004123</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'alpha': 1, 'l1_ratio': 0.5}</td>\n",
       "      <td>0.868076</td>\n",
       "      <td>0.738926</td>\n",
       "      <td>0.861647</td>\n",
       "      <td>0.850447</td>\n",
       "      <td>0.807500</td>\n",
       "      <td>0.825319</td>\n",
       "      <td>0.048084</td>\n",
       "      <td>18</td>\n",
       "      <td>0.895785</td>\n",
       "      <td>0.901345</td>\n",
       "      <td>0.898265</td>\n",
       "      <td>0.899051</td>\n",
       "      <td>0.903467</td>\n",
       "      <td>0.899583</td>\n",
       "      <td>0.002632</td>\n",
       "      <td>-0.868076</td>\n",
       "      <td>-0.738926</td>\n",
       "      <td>-0.861647</td>\n",
       "      <td>-0.850447</td>\n",
       "      <td>-0.807500</td>\n",
       "      <td>-0.825319</td>\n",
       "      <td>0.048084</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.895785</td>\n",
       "      <td>-0.901345</td>\n",
       "      <td>-0.898265</td>\n",
       "      <td>-0.899051</td>\n",
       "      <td>-0.903467</td>\n",
       "      <td>-0.899583</td>\n",
       "      <td>0.002632</td>\n",
       "      <td>-10.984671</td>\n",
       "      <td>-12.711757</td>\n",
       "      <td>-10.973548</td>\n",
       "      <td>-12.036072</td>\n",
       "      <td>-12.186334</td>\n",
       "      <td>-11.778476</td>\n",
       "      <td>0.690181</td>\n",
       "      <td>18</td>\n",
       "      <td>-10.189542</td>\n",
       "      <td>-9.490559</td>\n",
       "      <td>-10.106382</td>\n",
       "      <td>-9.951031</td>\n",
       "      <td>-9.947120</td>\n",
       "      <td>-9.936927</td>\n",
       "      <td>0.241693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.714059</td>\n",
       "      <td>1.808749</td>\n",
       "      <td>0.012888</td>\n",
       "      <td>0.006467</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>{'alpha': 1, 'l1_ratio': 0.7}</td>\n",
       "      <td>0.866537</td>\n",
       "      <td>0.738057</td>\n",
       "      <td>0.861521</td>\n",
       "      <td>0.848559</td>\n",
       "      <td>0.802402</td>\n",
       "      <td>0.823415</td>\n",
       "      <td>0.048314</td>\n",
       "      <td>19</td>\n",
       "      <td>0.896905</td>\n",
       "      <td>0.902402</td>\n",
       "      <td>0.899199</td>\n",
       "      <td>0.900305</td>\n",
       "      <td>0.904426</td>\n",
       "      <td>0.900647</td>\n",
       "      <td>0.002592</td>\n",
       "      <td>-0.866537</td>\n",
       "      <td>-0.738057</td>\n",
       "      <td>-0.861521</td>\n",
       "      <td>-0.848559</td>\n",
       "      <td>-0.802402</td>\n",
       "      <td>-0.823415</td>\n",
       "      <td>0.048314</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.896905</td>\n",
       "      <td>-0.902402</td>\n",
       "      <td>-0.899199</td>\n",
       "      <td>-0.900305</td>\n",
       "      <td>-0.904426</td>\n",
       "      <td>-0.900647</td>\n",
       "      <td>0.002592</td>\n",
       "      <td>-11.065453</td>\n",
       "      <td>-12.778770</td>\n",
       "      <td>-11.005034</td>\n",
       "      <td>-12.067780</td>\n",
       "      <td>-12.262275</td>\n",
       "      <td>-11.835862</td>\n",
       "      <td>0.694045</td>\n",
       "      <td>19</td>\n",
       "      <td>-10.147777</td>\n",
       "      <td>-9.440836</td>\n",
       "      <td>-10.071942</td>\n",
       "      <td>-9.893877</td>\n",
       "      <td>-9.898389</td>\n",
       "      <td>-9.890564</td>\n",
       "      <td>0.245513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28.559908</td>\n",
       "      <td>1.408317</td>\n",
       "      <td>0.016582</td>\n",
       "      <td>0.010552</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>{'alpha': 1, 'l1_ratio': 0.9}</td>\n",
       "      <td>0.863487</td>\n",
       "      <td>0.743911</td>\n",
       "      <td>0.860902</td>\n",
       "      <td>0.843338</td>\n",
       "      <td>0.784047</td>\n",
       "      <td>0.819137</td>\n",
       "      <td>0.047301</td>\n",
       "      <td>20</td>\n",
       "      <td>0.899348</td>\n",
       "      <td>0.904956</td>\n",
       "      <td>0.901349</td>\n",
       "      <td>0.903219</td>\n",
       "      <td>0.906691</td>\n",
       "      <td>0.903113</td>\n",
       "      <td>0.002588</td>\n",
       "      <td>-0.863487</td>\n",
       "      <td>-0.743911</td>\n",
       "      <td>-0.860902</td>\n",
       "      <td>-0.843338</td>\n",
       "      <td>-0.784047</td>\n",
       "      <td>-0.819137</td>\n",
       "      <td>0.047301</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.899348</td>\n",
       "      <td>-0.904956</td>\n",
       "      <td>-0.901349</td>\n",
       "      <td>-0.903219</td>\n",
       "      <td>-0.906691</td>\n",
       "      <td>-0.903113</td>\n",
       "      <td>0.002588</td>\n",
       "      <td>-11.205710</td>\n",
       "      <td>-12.947205</td>\n",
       "      <td>-11.078321</td>\n",
       "      <td>-12.207591</td>\n",
       "      <td>-12.521246</td>\n",
       "      <td>-11.992015</td>\n",
       "      <td>0.733765</td>\n",
       "      <td>20</td>\n",
       "      <td>-10.093616</td>\n",
       "      <td>-9.333925</td>\n",
       "      <td>-9.997867</td>\n",
       "      <td>-9.778610</td>\n",
       "      <td>-9.779838</td>\n",
       "      <td>-9.796771</td>\n",
       "      <td>0.262069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>29.727783</td>\n",
       "      <td>1.112045</td>\n",
       "      <td>0.011597</td>\n",
       "      <td>0.003427</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'alpha': 10, 'l1_ratio': 0.1}</td>\n",
       "      <td>0.875116</td>\n",
       "      <td>0.769033</td>\n",
       "      <td>0.861538</td>\n",
       "      <td>0.853966</td>\n",
       "      <td>0.819105</td>\n",
       "      <td>0.835752</td>\n",
       "      <td>0.038144</td>\n",
       "      <td>11</td>\n",
       "      <td>0.891086</td>\n",
       "      <td>0.897988</td>\n",
       "      <td>0.894816</td>\n",
       "      <td>0.894574</td>\n",
       "      <td>0.900053</td>\n",
       "      <td>0.895704</td>\n",
       "      <td>0.003083</td>\n",
       "      <td>-0.875116</td>\n",
       "      <td>-0.769033</td>\n",
       "      <td>-0.861538</td>\n",
       "      <td>-0.853966</td>\n",
       "      <td>-0.819105</td>\n",
       "      <td>-0.835752</td>\n",
       "      <td>0.038144</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.891086</td>\n",
       "      <td>-0.897988</td>\n",
       "      <td>-0.894816</td>\n",
       "      <td>-0.894574</td>\n",
       "      <td>-0.900053</td>\n",
       "      <td>-0.895704</td>\n",
       "      <td>0.003083</td>\n",
       "      <td>-10.606303</td>\n",
       "      <td>-12.415531</td>\n",
       "      <td>-10.981596</td>\n",
       "      <td>-11.987377</td>\n",
       "      <td>-12.008709</td>\n",
       "      <td>-11.599903</td>\n",
       "      <td>0.685865</td>\n",
       "      <td>11</td>\n",
       "      <td>-10.393838</td>\n",
       "      <td>-9.670573</td>\n",
       "      <td>-10.265538</td>\n",
       "      <td>-10.178883</td>\n",
       "      <td>-10.141452</td>\n",
       "      <td>-10.130057</td>\n",
       "      <td>0.245591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>28.609742</td>\n",
       "      <td>0.975069</td>\n",
       "      <td>0.005391</td>\n",
       "      <td>0.003325</td>\n",
       "      <td>10</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'alpha': 10, 'l1_ratio': 0.3}</td>\n",
       "      <td>0.874781</td>\n",
       "      <td>0.767475</td>\n",
       "      <td>0.861532</td>\n",
       "      <td>0.853967</td>\n",
       "      <td>0.818484</td>\n",
       "      <td>0.835248</td>\n",
       "      <td>0.038674</td>\n",
       "      <td>12</td>\n",
       "      <td>0.891354</td>\n",
       "      <td>0.898139</td>\n",
       "      <td>0.894999</td>\n",
       "      <td>0.894785</td>\n",
       "      <td>0.900226</td>\n",
       "      <td>0.895901</td>\n",
       "      <td>0.003048</td>\n",
       "      <td>-0.874781</td>\n",
       "      <td>-0.767475</td>\n",
       "      <td>-0.861532</td>\n",
       "      <td>-0.853967</td>\n",
       "      <td>-0.818484</td>\n",
       "      <td>-0.835248</td>\n",
       "      <td>0.038674</td>\n",
       "      <td>9</td>\n",
       "      <td>-0.891354</td>\n",
       "      <td>-0.898139</td>\n",
       "      <td>-0.894999</td>\n",
       "      <td>-0.894785</td>\n",
       "      <td>-0.900226</td>\n",
       "      <td>-0.895901</td>\n",
       "      <td>0.003048</td>\n",
       "      <td>-10.628265</td>\n",
       "      <td>-12.435372</td>\n",
       "      <td>-10.982956</td>\n",
       "      <td>-11.983949</td>\n",
       "      <td>-12.021570</td>\n",
       "      <td>-11.610423</td>\n",
       "      <td>0.685194</td>\n",
       "      <td>12</td>\n",
       "      <td>-10.380504</td>\n",
       "      <td>-9.663794</td>\n",
       "      <td>-10.255920</td>\n",
       "      <td>-10.167538</td>\n",
       "      <td>-10.130212</td>\n",
       "      <td>-10.119594</td>\n",
       "      <td>0.243649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>27.993489</td>\n",
       "      <td>1.623372</td>\n",
       "      <td>0.003525</td>\n",
       "      <td>0.001253</td>\n",
       "      <td>10</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'alpha': 10, 'l1_ratio': 0.5}</td>\n",
       "      <td>0.874249</td>\n",
       "      <td>0.764877</td>\n",
       "      <td>0.861554</td>\n",
       "      <td>0.853927</td>\n",
       "      <td>0.817644</td>\n",
       "      <td>0.834450</td>\n",
       "      <td>0.039550</td>\n",
       "      <td>13</td>\n",
       "      <td>0.891755</td>\n",
       "      <td>0.898361</td>\n",
       "      <td>0.895273</td>\n",
       "      <td>0.895110</td>\n",
       "      <td>0.900483</td>\n",
       "      <td>0.896196</td>\n",
       "      <td>0.002994</td>\n",
       "      <td>-0.874249</td>\n",
       "      <td>-0.764877</td>\n",
       "      <td>-0.861554</td>\n",
       "      <td>-0.853927</td>\n",
       "      <td>-0.817644</td>\n",
       "      <td>-0.834450</td>\n",
       "      <td>0.039550</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.891755</td>\n",
       "      <td>-0.898361</td>\n",
       "      <td>-0.895273</td>\n",
       "      <td>-0.895110</td>\n",
       "      <td>-0.900483</td>\n",
       "      <td>-0.896196</td>\n",
       "      <td>0.002994</td>\n",
       "      <td>-10.658794</td>\n",
       "      <td>-12.463572</td>\n",
       "      <td>-10.981871</td>\n",
       "      <td>-11.980356</td>\n",
       "      <td>-12.036462</td>\n",
       "      <td>-11.624211</td>\n",
       "      <td>0.684974</td>\n",
       "      <td>13</td>\n",
       "      <td>-10.362078</td>\n",
       "      <td>-9.652292</td>\n",
       "      <td>-10.241311</td>\n",
       "      <td>-10.148910</td>\n",
       "      <td>-10.113441</td>\n",
       "      <td>-10.103606</td>\n",
       "      <td>0.241497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>30.704868</td>\n",
       "      <td>2.421424</td>\n",
       "      <td>0.019817</td>\n",
       "      <td>0.018404</td>\n",
       "      <td>10</td>\n",
       "      <td>0.7</td>\n",
       "      <td>{'alpha': 10, 'l1_ratio': 0.7}</td>\n",
       "      <td>0.873231</td>\n",
       "      <td>0.759620</td>\n",
       "      <td>0.861622</td>\n",
       "      <td>0.853732</td>\n",
       "      <td>0.816289</td>\n",
       "      <td>0.832899</td>\n",
       "      <td>0.041307</td>\n",
       "      <td>14</td>\n",
       "      <td>0.892461</td>\n",
       "      <td>0.898769</td>\n",
       "      <td>0.895758</td>\n",
       "      <td>0.895710</td>\n",
       "      <td>0.900943</td>\n",
       "      <td>0.896728</td>\n",
       "      <td>0.002902</td>\n",
       "      <td>-0.873231</td>\n",
       "      <td>-0.759620</td>\n",
       "      <td>-0.861622</td>\n",
       "      <td>-0.853732</td>\n",
       "      <td>-0.816289</td>\n",
       "      <td>-0.832899</td>\n",
       "      <td>0.041307</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.892461</td>\n",
       "      <td>-0.898769</td>\n",
       "      <td>-0.895758</td>\n",
       "      <td>-0.895710</td>\n",
       "      <td>-0.900943</td>\n",
       "      <td>-0.896728</td>\n",
       "      <td>0.002902</td>\n",
       "      <td>-10.714812</td>\n",
       "      <td>-12.512367</td>\n",
       "      <td>-10.977357</td>\n",
       "      <td>-11.977587</td>\n",
       "      <td>-12.059396</td>\n",
       "      <td>-11.648304</td>\n",
       "      <td>0.684924</td>\n",
       "      <td>14</td>\n",
       "      <td>-10.331224</td>\n",
       "      <td>-9.629612</td>\n",
       "      <td>-10.217223</td>\n",
       "      <td>-10.115130</td>\n",
       "      <td>-10.084841</td>\n",
       "      <td>-10.075606</td>\n",
       "      <td>0.239146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>31.068554</td>\n",
       "      <td>1.344864</td>\n",
       "      <td>0.012343</td>\n",
       "      <td>0.003621</td>\n",
       "      <td>10</td>\n",
       "      <td>0.9</td>\n",
       "      <td>{'alpha': 10, 'l1_ratio': 0.9}</td>\n",
       "      <td>0.870259</td>\n",
       "      <td>0.745739</td>\n",
       "      <td>0.861723</td>\n",
       "      <td>0.852329</td>\n",
       "      <td>0.812289</td>\n",
       "      <td>0.828468</td>\n",
       "      <td>0.045886</td>\n",
       "      <td>15</td>\n",
       "      <td>0.894326</td>\n",
       "      <td>0.900082</td>\n",
       "      <td>0.897105</td>\n",
       "      <td>0.897496</td>\n",
       "      <td>0.902283</td>\n",
       "      <td>0.898258</td>\n",
       "      <td>0.002717</td>\n",
       "      <td>-0.870259</td>\n",
       "      <td>-0.745739</td>\n",
       "      <td>-0.861723</td>\n",
       "      <td>-0.852329</td>\n",
       "      <td>-0.812289</td>\n",
       "      <td>-0.828468</td>\n",
       "      <td>0.045886</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.894326</td>\n",
       "      <td>-0.900082</td>\n",
       "      <td>-0.897105</td>\n",
       "      <td>-0.897496</td>\n",
       "      <td>-0.902283</td>\n",
       "      <td>-0.898258</td>\n",
       "      <td>0.002717</td>\n",
       "      <td>-10.869553</td>\n",
       "      <td>-12.627837</td>\n",
       "      <td>-10.958682</td>\n",
       "      <td>-12.003078</td>\n",
       "      <td>-12.117465</td>\n",
       "      <td>-11.715323</td>\n",
       "      <td>0.687755</td>\n",
       "      <td>15</td>\n",
       "      <td>-10.248481</td>\n",
       "      <td>-9.558544</td>\n",
       "      <td>-10.154227</td>\n",
       "      <td>-10.021519</td>\n",
       "      <td>-10.011098</td>\n",
       "      <td>-9.998773</td>\n",
       "      <td>0.237061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>28.947742</td>\n",
       "      <td>1.392783</td>\n",
       "      <td>0.005306</td>\n",
       "      <td>0.002603</td>\n",
       "      <td>100</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'alpha': 100, 'l1_ratio': 0.1}</td>\n",
       "      <td>0.877172</td>\n",
       "      <td>0.776316</td>\n",
       "      <td>0.862564</td>\n",
       "      <td>0.855264</td>\n",
       "      <td>0.824350</td>\n",
       "      <td>0.839133</td>\n",
       "      <td>0.035835</td>\n",
       "      <td>6</td>\n",
       "      <td>0.889444</td>\n",
       "      <td>0.896674</td>\n",
       "      <td>0.893444</td>\n",
       "      <td>0.893072</td>\n",
       "      <td>0.898759</td>\n",
       "      <td>0.894279</td>\n",
       "      <td>0.003204</td>\n",
       "      <td>-0.877172</td>\n",
       "      <td>-0.776316</td>\n",
       "      <td>-0.862564</td>\n",
       "      <td>-0.855264</td>\n",
       "      <td>-0.824350</td>\n",
       "      <td>-0.839133</td>\n",
       "      <td>0.035835</td>\n",
       "      <td>15</td>\n",
       "      <td>-0.889444</td>\n",
       "      <td>-0.896674</td>\n",
       "      <td>-0.893444</td>\n",
       "      <td>-0.893072</td>\n",
       "      <td>-0.898759</td>\n",
       "      <td>-0.894279</td>\n",
       "      <td>0.003204</td>\n",
       "      <td>-10.406040</td>\n",
       "      <td>-12.252555</td>\n",
       "      <td>-10.886742</td>\n",
       "      <td>-12.011003</td>\n",
       "      <td>-11.799308</td>\n",
       "      <td>-11.471129</td>\n",
       "      <td>0.705084</td>\n",
       "      <td>6</td>\n",
       "      <td>-10.458670</td>\n",
       "      <td>-9.713682</td>\n",
       "      <td>-10.290872</td>\n",
       "      <td>-10.210034</td>\n",
       "      <td>-10.200615</td>\n",
       "      <td>-10.174774</td>\n",
       "      <td>0.248432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>28.185881</td>\n",
       "      <td>1.637837</td>\n",
       "      <td>0.004849</td>\n",
       "      <td>0.004736</td>\n",
       "      <td>100</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'alpha': 100, 'l1_ratio': 0.3}</td>\n",
       "      <td>0.876916</td>\n",
       "      <td>0.775827</td>\n",
       "      <td>0.862373</td>\n",
       "      <td>0.854921</td>\n",
       "      <td>0.823834</td>\n",
       "      <td>0.838774</td>\n",
       "      <td>0.035939</td>\n",
       "      <td>7</td>\n",
       "      <td>0.889575</td>\n",
       "      <td>0.896807</td>\n",
       "      <td>0.893589</td>\n",
       "      <td>0.893231</td>\n",
       "      <td>0.898897</td>\n",
       "      <td>0.894420</td>\n",
       "      <td>0.003204</td>\n",
       "      <td>-0.876916</td>\n",
       "      <td>-0.775827</td>\n",
       "      <td>-0.862373</td>\n",
       "      <td>-0.854921</td>\n",
       "      <td>-0.823834</td>\n",
       "      <td>-0.838774</td>\n",
       "      <td>0.035939</td>\n",
       "      <td>14</td>\n",
       "      <td>-0.889575</td>\n",
       "      <td>-0.896807</td>\n",
       "      <td>-0.893589</td>\n",
       "      <td>-0.893231</td>\n",
       "      <td>-0.898897</td>\n",
       "      <td>-0.894420</td>\n",
       "      <td>0.003204</td>\n",
       "      <td>-10.430227</td>\n",
       "      <td>-12.262382</td>\n",
       "      <td>-10.901339</td>\n",
       "      <td>-12.015351</td>\n",
       "      <td>-11.830274</td>\n",
       "      <td>-11.487915</td>\n",
       "      <td>0.701138</td>\n",
       "      <td>7</td>\n",
       "      <td>-10.454924</td>\n",
       "      <td>-9.711147</td>\n",
       "      <td>-10.291211</td>\n",
       "      <td>-10.209188</td>\n",
       "      <td>-10.195639</td>\n",
       "      <td>-10.172422</td>\n",
       "      <td>0.248429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>27.496819</td>\n",
       "      <td>1.401368</td>\n",
       "      <td>0.005313</td>\n",
       "      <td>0.004572</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'alpha': 100, 'l1_ratio': 0.5}</td>\n",
       "      <td>0.876631</td>\n",
       "      <td>0.775170</td>\n",
       "      <td>0.862137</td>\n",
       "      <td>0.854533</td>\n",
       "      <td>0.823137</td>\n",
       "      <td>0.838322</td>\n",
       "      <td>0.036101</td>\n",
       "      <td>8</td>\n",
       "      <td>0.889750</td>\n",
       "      <td>0.896984</td>\n",
       "      <td>0.893774</td>\n",
       "      <td>0.893433</td>\n",
       "      <td>0.899068</td>\n",
       "      <td>0.894602</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>-0.876631</td>\n",
       "      <td>-0.775170</td>\n",
       "      <td>-0.862137</td>\n",
       "      <td>-0.854533</td>\n",
       "      <td>-0.823137</td>\n",
       "      <td>-0.838322</td>\n",
       "      <td>0.036101</td>\n",
       "      <td>13</td>\n",
       "      <td>-0.889750</td>\n",
       "      <td>-0.896984</td>\n",
       "      <td>-0.893774</td>\n",
       "      <td>-0.893433</td>\n",
       "      <td>-0.899068</td>\n",
       "      <td>-0.894602</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>-10.461589</td>\n",
       "      <td>-12.278561</td>\n",
       "      <td>-10.919811</td>\n",
       "      <td>-12.017774</td>\n",
       "      <td>-11.868594</td>\n",
       "      <td>-11.509266</td>\n",
       "      <td>0.696361</td>\n",
       "      <td>8</td>\n",
       "      <td>-10.450076</td>\n",
       "      <td>-9.706385</td>\n",
       "      <td>-10.291003</td>\n",
       "      <td>-10.208123</td>\n",
       "      <td>-10.189929</td>\n",
       "      <td>-10.169103</td>\n",
       "      <td>0.248945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>26.849783</td>\n",
       "      <td>1.192519</td>\n",
       "      <td>0.004463</td>\n",
       "      <td>0.002208</td>\n",
       "      <td>100</td>\n",
       "      <td>0.7</td>\n",
       "      <td>{'alpha': 100, 'l1_ratio': 0.7}</td>\n",
       "      <td>0.876272</td>\n",
       "      <td>0.774123</td>\n",
       "      <td>0.861872</td>\n",
       "      <td>0.854111</td>\n",
       "      <td>0.822071</td>\n",
       "      <td>0.837690</td>\n",
       "      <td>0.036408</td>\n",
       "      <td>9</td>\n",
       "      <td>0.890040</td>\n",
       "      <td>0.897253</td>\n",
       "      <td>0.894041</td>\n",
       "      <td>0.893727</td>\n",
       "      <td>0.899315</td>\n",
       "      <td>0.894875</td>\n",
       "      <td>0.003186</td>\n",
       "      <td>-0.876272</td>\n",
       "      <td>-0.774123</td>\n",
       "      <td>-0.861872</td>\n",
       "      <td>-0.854111</td>\n",
       "      <td>-0.822071</td>\n",
       "      <td>-0.837690</td>\n",
       "      <td>0.036408</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.890040</td>\n",
       "      <td>-0.897253</td>\n",
       "      <td>-0.894041</td>\n",
       "      <td>-0.893727</td>\n",
       "      <td>-0.899315</td>\n",
       "      <td>-0.894875</td>\n",
       "      <td>0.003186</td>\n",
       "      <td>-10.504003</td>\n",
       "      <td>-12.310026</td>\n",
       "      <td>-10.942594</td>\n",
       "      <td>-12.016361</td>\n",
       "      <td>-11.915484</td>\n",
       "      <td>-11.537693</td>\n",
       "      <td>0.691521</td>\n",
       "      <td>9</td>\n",
       "      <td>-10.440578</td>\n",
       "      <td>-9.697469</td>\n",
       "      <td>-10.289319</td>\n",
       "      <td>-10.207693</td>\n",
       "      <td>-10.180311</td>\n",
       "      <td>-10.163074</td>\n",
       "      <td>0.249809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>26.631329</td>\n",
       "      <td>1.323109</td>\n",
       "      <td>0.003088</td>\n",
       "      <td>0.001014</td>\n",
       "      <td>100</td>\n",
       "      <td>0.9</td>\n",
       "      <td>{'alpha': 100, 'l1_ratio': 0.9}</td>\n",
       "      <td>0.875338</td>\n",
       "      <td>0.770945</td>\n",
       "      <td>0.861592</td>\n",
       "      <td>0.853985</td>\n",
       "      <td>0.819604</td>\n",
       "      <td>0.836293</td>\n",
       "      <td>0.037487</td>\n",
       "      <td>10</td>\n",
       "      <td>0.890872</td>\n",
       "      <td>0.897829</td>\n",
       "      <td>0.894639</td>\n",
       "      <td>0.894383</td>\n",
       "      <td>0.899888</td>\n",
       "      <td>0.895522</td>\n",
       "      <td>0.003101</td>\n",
       "      <td>-0.875338</td>\n",
       "      <td>-0.770945</td>\n",
       "      <td>-0.861592</td>\n",
       "      <td>-0.853985</td>\n",
       "      <td>-0.819604</td>\n",
       "      <td>-0.836293</td>\n",
       "      <td>0.037487</td>\n",
       "      <td>11</td>\n",
       "      <td>-0.890872</td>\n",
       "      <td>-0.897829</td>\n",
       "      <td>-0.894639</td>\n",
       "      <td>-0.894383</td>\n",
       "      <td>-0.899888</td>\n",
       "      <td>-0.895522</td>\n",
       "      <td>0.003101</td>\n",
       "      <td>-10.589703</td>\n",
       "      <td>-12.385375</td>\n",
       "      <td>-10.975829</td>\n",
       "      <td>-11.988284</td>\n",
       "      <td>-11.998675</td>\n",
       "      <td>-11.587573</td>\n",
       "      <td>0.683526</td>\n",
       "      <td>10</td>\n",
       "      <td>-10.403564</td>\n",
       "      <td>-9.677536</td>\n",
       "      <td>-10.273204</td>\n",
       "      <td>-10.186826</td>\n",
       "      <td>-10.151090</td>\n",
       "      <td>-10.138444</td>\n",
       "      <td>0.246328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>27.297922</td>\n",
       "      <td>1.524243</td>\n",
       "      <td>0.003145</td>\n",
       "      <td>0.000892</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'alpha': 1000, 'l1_ratio': 0.1}</td>\n",
       "      <td>0.881103</td>\n",
       "      <td>0.780570</td>\n",
       "      <td>0.862657</td>\n",
       "      <td>0.860358</td>\n",
       "      <td>0.829009</td>\n",
       "      <td>0.842739</td>\n",
       "      <td>0.035306</td>\n",
       "      <td>1</td>\n",
       "      <td>0.887641</td>\n",
       "      <td>0.895216</td>\n",
       "      <td>0.891690</td>\n",
       "      <td>0.891115</td>\n",
       "      <td>0.896691</td>\n",
       "      <td>0.892471</td>\n",
       "      <td>0.003197</td>\n",
       "      <td>-0.881103</td>\n",
       "      <td>-0.780570</td>\n",
       "      <td>-0.862657</td>\n",
       "      <td>-0.860358</td>\n",
       "      <td>-0.829009</td>\n",
       "      <td>-0.842739</td>\n",
       "      <td>0.035306</td>\n",
       "      <td>20</td>\n",
       "      <td>-0.887641</td>\n",
       "      <td>-0.895216</td>\n",
       "      <td>-0.891690</td>\n",
       "      <td>-0.891115</td>\n",
       "      <td>-0.896691</td>\n",
       "      <td>-0.892471</td>\n",
       "      <td>0.003197</td>\n",
       "      <td>-10.215434</td>\n",
       "      <td>-12.134230</td>\n",
       "      <td>-10.814859</td>\n",
       "      <td>-11.840212</td>\n",
       "      <td>-11.793485</td>\n",
       "      <td>-11.359644</td>\n",
       "      <td>0.724590</td>\n",
       "      <td>1</td>\n",
       "      <td>-10.512168</td>\n",
       "      <td>-9.757449</td>\n",
       "      <td>-10.328513</td>\n",
       "      <td>-10.249917</td>\n",
       "      <td>-10.260341</td>\n",
       "      <td>-10.221678</td>\n",
       "      <td>0.250439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>25.907259</td>\n",
       "      <td>1.507298</td>\n",
       "      <td>0.005478</td>\n",
       "      <td>0.003130</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'alpha': 1000, 'l1_ratio': 0.3}</td>\n",
       "      <td>0.880664</td>\n",
       "      <td>0.780185</td>\n",
       "      <td>0.862770</td>\n",
       "      <td>0.859718</td>\n",
       "      <td>0.828342</td>\n",
       "      <td>0.842336</td>\n",
       "      <td>0.035348</td>\n",
       "      <td>2</td>\n",
       "      <td>0.887872</td>\n",
       "      <td>0.895370</td>\n",
       "      <td>0.891874</td>\n",
       "      <td>0.891347</td>\n",
       "      <td>0.896963</td>\n",
       "      <td>0.892685</td>\n",
       "      <td>0.003198</td>\n",
       "      <td>-0.880664</td>\n",
       "      <td>-0.780185</td>\n",
       "      <td>-0.862770</td>\n",
       "      <td>-0.859718</td>\n",
       "      <td>-0.828342</td>\n",
       "      <td>-0.842336</td>\n",
       "      <td>0.035348</td>\n",
       "      <td>19</td>\n",
       "      <td>-0.887872</td>\n",
       "      <td>-0.895370</td>\n",
       "      <td>-0.891874</td>\n",
       "      <td>-0.891347</td>\n",
       "      <td>-0.896963</td>\n",
       "      <td>-0.892685</td>\n",
       "      <td>0.003198</td>\n",
       "      <td>-10.224995</td>\n",
       "      <td>-12.153582</td>\n",
       "      <td>-10.820066</td>\n",
       "      <td>-11.866885</td>\n",
       "      <td>-11.798234</td>\n",
       "      <td>-11.372752</td>\n",
       "      <td>0.729068</td>\n",
       "      <td>2</td>\n",
       "      <td>-10.505985</td>\n",
       "      <td>-9.754609</td>\n",
       "      <td>-10.323569</td>\n",
       "      <td>-10.245061</td>\n",
       "      <td>-10.250711</td>\n",
       "      <td>-10.215987</td>\n",
       "      <td>0.249236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>24.815848</td>\n",
       "      <td>1.375348</td>\n",
       "      <td>0.009024</td>\n",
       "      <td>0.004021</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'alpha': 1000, 'l1_ratio': 0.5}</td>\n",
       "      <td>0.880065</td>\n",
       "      <td>0.779660</td>\n",
       "      <td>0.862872</td>\n",
       "      <td>0.858888</td>\n",
       "      <td>0.827601</td>\n",
       "      <td>0.841817</td>\n",
       "      <td>0.035393</td>\n",
       "      <td>3</td>\n",
       "      <td>0.888156</td>\n",
       "      <td>0.895559</td>\n",
       "      <td>0.892111</td>\n",
       "      <td>0.891637</td>\n",
       "      <td>0.897295</td>\n",
       "      <td>0.892952</td>\n",
       "      <td>0.003197</td>\n",
       "      <td>-0.880065</td>\n",
       "      <td>-0.779660</td>\n",
       "      <td>-0.862872</td>\n",
       "      <td>-0.858888</td>\n",
       "      <td>-0.827601</td>\n",
       "      <td>-0.841817</td>\n",
       "      <td>0.035393</td>\n",
       "      <td>18</td>\n",
       "      <td>-0.888156</td>\n",
       "      <td>-0.895559</td>\n",
       "      <td>-0.892111</td>\n",
       "      <td>-0.891637</td>\n",
       "      <td>-0.897295</td>\n",
       "      <td>-0.892952</td>\n",
       "      <td>0.003197</td>\n",
       "      <td>-10.241262</td>\n",
       "      <td>-12.176207</td>\n",
       "      <td>-10.825425</td>\n",
       "      <td>-11.900131</td>\n",
       "      <td>-11.797802</td>\n",
       "      <td>-11.388165</td>\n",
       "      <td>0.732528</td>\n",
       "      <td>3</td>\n",
       "      <td>-10.498115</td>\n",
       "      <td>-9.749590</td>\n",
       "      <td>-10.316238</td>\n",
       "      <td>-10.238063</td>\n",
       "      <td>-10.241480</td>\n",
       "      <td>-10.208697</td>\n",
       "      <td>0.248211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>23.970709</td>\n",
       "      <td>1.134403</td>\n",
       "      <td>0.003888</td>\n",
       "      <td>0.002303</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>{'alpha': 1000, 'l1_ratio': 0.7}</td>\n",
       "      <td>0.879172</td>\n",
       "      <td>0.778921</td>\n",
       "      <td>0.862943</td>\n",
       "      <td>0.857706</td>\n",
       "      <td>0.826742</td>\n",
       "      <td>0.841097</td>\n",
       "      <td>0.035425</td>\n",
       "      <td>4</td>\n",
       "      <td>0.888537</td>\n",
       "      <td>0.895840</td>\n",
       "      <td>0.892464</td>\n",
       "      <td>0.892047</td>\n",
       "      <td>0.897739</td>\n",
       "      <td>0.893326</td>\n",
       "      <td>0.003197</td>\n",
       "      <td>-0.879172</td>\n",
       "      <td>-0.778921</td>\n",
       "      <td>-0.862943</td>\n",
       "      <td>-0.857706</td>\n",
       "      <td>-0.826742</td>\n",
       "      <td>-0.841097</td>\n",
       "      <td>0.035425</td>\n",
       "      <td>17</td>\n",
       "      <td>-0.888537</td>\n",
       "      <td>-0.895840</td>\n",
       "      <td>-0.892464</td>\n",
       "      <td>-0.892047</td>\n",
       "      <td>-0.897739</td>\n",
       "      <td>-0.893326</td>\n",
       "      <td>0.003197</td>\n",
       "      <td>-10.269596</td>\n",
       "      <td>-12.202708</td>\n",
       "      <td>-10.830718</td>\n",
       "      <td>-11.941113</td>\n",
       "      <td>-11.786610</td>\n",
       "      <td>-11.406149</td>\n",
       "      <td>0.733255</td>\n",
       "      <td>4</td>\n",
       "      <td>-10.484313</td>\n",
       "      <td>-9.741170</td>\n",
       "      <td>-10.306923</td>\n",
       "      <td>-10.229475</td>\n",
       "      <td>-10.229489</td>\n",
       "      <td>-10.198274</td>\n",
       "      <td>0.246785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19.010476</td>\n",
       "      <td>1.059762</td>\n",
       "      <td>0.001546</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>{'alpha': 1000, 'l1_ratio': 0.9}</td>\n",
       "      <td>0.877709</td>\n",
       "      <td>0.777258</td>\n",
       "      <td>0.862712</td>\n",
       "      <td>0.855790</td>\n",
       "      <td>0.825147</td>\n",
       "      <td>0.839723</td>\n",
       "      <td>0.035620</td>\n",
       "      <td>5</td>\n",
       "      <td>0.889184</td>\n",
       "      <td>0.896426</td>\n",
       "      <td>0.893148</td>\n",
       "      <td>0.892793</td>\n",
       "      <td>0.898493</td>\n",
       "      <td>0.894009</td>\n",
       "      <td>0.003208</td>\n",
       "      <td>-0.877709</td>\n",
       "      <td>-0.777258</td>\n",
       "      <td>-0.862712</td>\n",
       "      <td>-0.855790</td>\n",
       "      <td>-0.825147</td>\n",
       "      <td>-0.839723</td>\n",
       "      <td>0.035620</td>\n",
       "      <td>16</td>\n",
       "      <td>-0.889184</td>\n",
       "      <td>-0.896426</td>\n",
       "      <td>-0.893148</td>\n",
       "      <td>-0.892793</td>\n",
       "      <td>-0.898493</td>\n",
       "      <td>-0.894009</td>\n",
       "      <td>0.003208</td>\n",
       "      <td>-10.362060</td>\n",
       "      <td>-12.235327</td>\n",
       "      <td>-10.870089</td>\n",
       "      <td>-11.997353</td>\n",
       "      <td>-11.777668</td>\n",
       "      <td>-11.448500</td>\n",
       "      <td>0.713246</td>\n",
       "      <td>5</td>\n",
       "      <td>-10.463809</td>\n",
       "      <td>-9.722404</td>\n",
       "      <td>-10.290751</td>\n",
       "      <td>-10.210914</td>\n",
       "      <td>-10.212372</td>\n",
       "      <td>-10.180050</td>\n",
       "      <td>0.246662</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_alpha  \\\n",
       "0       22.316146      1.463502         0.010546        0.003140           1   \n",
       "1       24.268496      3.033492         0.006834        0.001421           1   \n",
       "2       27.193180      1.582184         0.010249        0.004123           1   \n",
       "3       27.714059      1.808749         0.012888        0.006467           1   \n",
       "4       28.559908      1.408317         0.016582        0.010552           1   \n",
       "5       29.727783      1.112045         0.011597        0.003427          10   \n",
       "6       28.609742      0.975069         0.005391        0.003325          10   \n",
       "7       27.993489      1.623372         0.003525        0.001253          10   \n",
       "8       30.704868      2.421424         0.019817        0.018404          10   \n",
       "9       31.068554      1.344864         0.012343        0.003621          10   \n",
       "10      28.947742      1.392783         0.005306        0.002603         100   \n",
       "11      28.185881      1.637837         0.004849        0.004736         100   \n",
       "12      27.496819      1.401368         0.005313        0.004572         100   \n",
       "13      26.849783      1.192519         0.004463        0.002208         100   \n",
       "14      26.631329      1.323109         0.003088        0.001014         100   \n",
       "15      27.297922      1.524243         0.003145        0.000892        1000   \n",
       "16      25.907259      1.507298         0.005478        0.003130        1000   \n",
       "17      24.815848      1.375348         0.009024        0.004021        1000   \n",
       "18      23.970709      1.134403         0.003888        0.002303        1000   \n",
       "19      19.010476      1.059762         0.001546        0.000307        1000   \n",
       "\n",
       "   param_l1_ratio                            params  split0_test_R-squared  \\\n",
       "0             0.1     {'alpha': 1, 'l1_ratio': 0.1}               0.869888   \n",
       "1             0.3     {'alpha': 1, 'l1_ratio': 0.3}               0.869113   \n",
       "2             0.5     {'alpha': 1, 'l1_ratio': 0.5}               0.868076   \n",
       "3             0.7     {'alpha': 1, 'l1_ratio': 0.7}               0.866537   \n",
       "4             0.9     {'alpha': 1, 'l1_ratio': 0.9}               0.863487   \n",
       "5             0.1    {'alpha': 10, 'l1_ratio': 0.1}               0.875116   \n",
       "6             0.3    {'alpha': 10, 'l1_ratio': 0.3}               0.874781   \n",
       "7             0.5    {'alpha': 10, 'l1_ratio': 0.5}               0.874249   \n",
       "8             0.7    {'alpha': 10, 'l1_ratio': 0.7}               0.873231   \n",
       "9             0.9    {'alpha': 10, 'l1_ratio': 0.9}               0.870259   \n",
       "10            0.1   {'alpha': 100, 'l1_ratio': 0.1}               0.877172   \n",
       "11            0.3   {'alpha': 100, 'l1_ratio': 0.3}               0.876916   \n",
       "12            0.5   {'alpha': 100, 'l1_ratio': 0.5}               0.876631   \n",
       "13            0.7   {'alpha': 100, 'l1_ratio': 0.7}               0.876272   \n",
       "14            0.9   {'alpha': 100, 'l1_ratio': 0.9}               0.875338   \n",
       "15            0.1  {'alpha': 1000, 'l1_ratio': 0.1}               0.881103   \n",
       "16            0.3  {'alpha': 1000, 'l1_ratio': 0.3}               0.880664   \n",
       "17            0.5  {'alpha': 1000, 'l1_ratio': 0.5}               0.880065   \n",
       "18            0.7  {'alpha': 1000, 'l1_ratio': 0.7}               0.879172   \n",
       "19            0.9  {'alpha': 1000, 'l1_ratio': 0.9}               0.877709   \n",
       "\n",
       "    split1_test_R-squared  split2_test_R-squared  split3_test_R-squared  \\\n",
       "0                0.743469               0.861695               0.852084   \n",
       "1                0.741084               0.861684               0.851456   \n",
       "2                0.738926               0.861647               0.850447   \n",
       "3                0.738057               0.861521               0.848559   \n",
       "4                0.743911               0.860902               0.843338   \n",
       "5                0.769033               0.861538               0.853966   \n",
       "6                0.767475               0.861532               0.853967   \n",
       "7                0.764877               0.861554               0.853927   \n",
       "8                0.759620               0.861622               0.853732   \n",
       "9                0.745739               0.861723               0.852329   \n",
       "10               0.776316               0.862564               0.855264   \n",
       "11               0.775827               0.862373               0.854921   \n",
       "12               0.775170               0.862137               0.854533   \n",
       "13               0.774123               0.861872               0.854111   \n",
       "14               0.770945               0.861592               0.853985   \n",
       "15               0.780570               0.862657               0.860358   \n",
       "16               0.780185               0.862770               0.859718   \n",
       "17               0.779660               0.862872               0.858888   \n",
       "18               0.778921               0.862943               0.857706   \n",
       "19               0.777258               0.862712               0.855790   \n",
       "\n",
       "    split4_test_R-squared  mean_test_R-squared  std_test_R-squared  \\\n",
       "0                0.811486             0.827724            0.046665   \n",
       "1                0.809980             0.826663            0.047424   \n",
       "2                0.807500             0.825319            0.048084   \n",
       "3                0.802402             0.823415            0.048314   \n",
       "4                0.784047             0.819137            0.047301   \n",
       "5                0.819105             0.835752            0.038144   \n",
       "6                0.818484             0.835248            0.038674   \n",
       "7                0.817644             0.834450            0.039550   \n",
       "8                0.816289             0.832899            0.041307   \n",
       "9                0.812289             0.828468            0.045886   \n",
       "10               0.824350             0.839133            0.035835   \n",
       "11               0.823834             0.838774            0.035939   \n",
       "12               0.823137             0.838322            0.036101   \n",
       "13               0.822071             0.837690            0.036408   \n",
       "14               0.819604             0.836293            0.037487   \n",
       "15               0.829009             0.842739            0.035306   \n",
       "16               0.828342             0.842336            0.035348   \n",
       "17               0.827601             0.841817            0.035393   \n",
       "18               0.826742             0.841097            0.035425   \n",
       "19               0.825147             0.839723            0.035620   \n",
       "\n",
       "    rank_test_R-squared  split0_train_R-squared  split1_train_R-squared  \\\n",
       "0                    16                0.894580                0.900298   \n",
       "1                    17                0.895082                0.900721   \n",
       "2                    18                0.895785                0.901345   \n",
       "3                    19                0.896905                0.902402   \n",
       "4                    20                0.899348                0.904956   \n",
       "5                    11                0.891086                0.897988   \n",
       "6                    12                0.891354                0.898139   \n",
       "7                    13                0.891755                0.898361   \n",
       "8                    14                0.892461                0.898769   \n",
       "9                    15                0.894326                0.900082   \n",
       "10                    6                0.889444                0.896674   \n",
       "11                    7                0.889575                0.896807   \n",
       "12                    8                0.889750                0.896984   \n",
       "13                    9                0.890040                0.897253   \n",
       "14                   10                0.890872                0.897829   \n",
       "15                    1                0.887641                0.895216   \n",
       "16                    2                0.887872                0.895370   \n",
       "17                    3                0.888156                0.895559   \n",
       "18                    4                0.888537                0.895840   \n",
       "19                    5                0.889184                0.896426   \n",
       "\n",
       "    split2_train_R-squared  split3_train_R-squared  split4_train_R-squared  \\\n",
       "0                 0.897308                0.897762                0.902489   \n",
       "1                 0.897700                0.898291                0.902889   \n",
       "2                 0.898265                0.899051                0.903467   \n",
       "3                 0.899199                0.900305                0.904426   \n",
       "4                 0.901349                0.903219                0.906691   \n",
       "5                 0.894816                0.894574                0.900053   \n",
       "6                 0.894999                0.894785                0.900226   \n",
       "7                 0.895273                0.895110                0.900483   \n",
       "8                 0.895758                0.895710                0.900943   \n",
       "9                 0.897105                0.897496                0.902283   \n",
       "10                0.893444                0.893072                0.898759   \n",
       "11                0.893589                0.893231                0.898897   \n",
       "12                0.893774                0.893433                0.899068   \n",
       "13                0.894041                0.893727                0.899315   \n",
       "14                0.894639                0.894383                0.899888   \n",
       "15                0.891690                0.891115                0.896691   \n",
       "16                0.891874                0.891347                0.896963   \n",
       "17                0.892111                0.891637                0.897295   \n",
       "18                0.892464                0.892047                0.897739   \n",
       "19                0.893148                0.892793                0.898493   \n",
       "\n",
       "    mean_train_R-squared  std_train_R-squared  split0_test_Adjusted R-squared  \\\n",
       "0               0.898488             0.002701                       -0.869888   \n",
       "1               0.898937             0.002669                       -0.869113   \n",
       "2               0.899583             0.002632                       -0.868076   \n",
       "3               0.900647             0.002592                       -0.866537   \n",
       "4               0.903113             0.002588                       -0.863487   \n",
       "5               0.895704             0.003083                       -0.875116   \n",
       "6               0.895901             0.003048                       -0.874781   \n",
       "7               0.896196             0.002994                       -0.874249   \n",
       "8               0.896728             0.002902                       -0.873231   \n",
       "9               0.898258             0.002717                       -0.870259   \n",
       "10              0.894279             0.003204                       -0.877172   \n",
       "11              0.894420             0.003204                       -0.876916   \n",
       "12              0.894602             0.003200                       -0.876631   \n",
       "13              0.894875             0.003186                       -0.876272   \n",
       "14              0.895522             0.003101                       -0.875338   \n",
       "15              0.892471             0.003197                       -0.881103   \n",
       "16              0.892685             0.003198                       -0.880664   \n",
       "17              0.892952             0.003197                       -0.880065   \n",
       "18              0.893326             0.003197                       -0.879172   \n",
       "19              0.894009             0.003208                       -0.877709   \n",
       "\n",
       "    split1_test_Adjusted R-squared  split2_test_Adjusted R-squared  \\\n",
       "0                        -0.743469                       -0.861695   \n",
       "1                        -0.741084                       -0.861684   \n",
       "2                        -0.738926                       -0.861647   \n",
       "3                        -0.738057                       -0.861521   \n",
       "4                        -0.743911                       -0.860902   \n",
       "5                        -0.769033                       -0.861538   \n",
       "6                        -0.767475                       -0.861532   \n",
       "7                        -0.764877                       -0.861554   \n",
       "8                        -0.759620                       -0.861622   \n",
       "9                        -0.745739                       -0.861723   \n",
       "10                       -0.776316                       -0.862564   \n",
       "11                       -0.775827                       -0.862373   \n",
       "12                       -0.775170                       -0.862137   \n",
       "13                       -0.774123                       -0.861872   \n",
       "14                       -0.770945                       -0.861592   \n",
       "15                       -0.780570                       -0.862657   \n",
       "16                       -0.780185                       -0.862770   \n",
       "17                       -0.779660                       -0.862872   \n",
       "18                       -0.778921                       -0.862943   \n",
       "19                       -0.777258                       -0.862712   \n",
       "\n",
       "    split3_test_Adjusted R-squared  split4_test_Adjusted R-squared  \\\n",
       "0                        -0.852084                       -0.811486   \n",
       "1                        -0.851456                       -0.809980   \n",
       "2                        -0.850447                       -0.807500   \n",
       "3                        -0.848559                       -0.802402   \n",
       "4                        -0.843338                       -0.784047   \n",
       "5                        -0.853966                       -0.819105   \n",
       "6                        -0.853967                       -0.818484   \n",
       "7                        -0.853927                       -0.817644   \n",
       "8                        -0.853732                       -0.816289   \n",
       "9                        -0.852329                       -0.812289   \n",
       "10                       -0.855264                       -0.824350   \n",
       "11                       -0.854921                       -0.823834   \n",
       "12                       -0.854533                       -0.823137   \n",
       "13                       -0.854111                       -0.822071   \n",
       "14                       -0.853985                       -0.819604   \n",
       "15                       -0.860358                       -0.829009   \n",
       "16                       -0.859718                       -0.828342   \n",
       "17                       -0.858888                       -0.827601   \n",
       "18                       -0.857706                       -0.826742   \n",
       "19                       -0.855790                       -0.825147   \n",
       "\n",
       "    mean_test_Adjusted R-squared  std_test_Adjusted R-squared  \\\n",
       "0                      -0.827724                     0.046665   \n",
       "1                      -0.826663                     0.047424   \n",
       "2                      -0.825319                     0.048084   \n",
       "3                      -0.823415                     0.048314   \n",
       "4                      -0.819137                     0.047301   \n",
       "5                      -0.835752                     0.038144   \n",
       "6                      -0.835248                     0.038674   \n",
       "7                      -0.834450                     0.039550   \n",
       "8                      -0.832899                     0.041307   \n",
       "9                      -0.828468                     0.045886   \n",
       "10                     -0.839133                     0.035835   \n",
       "11                     -0.838774                     0.035939   \n",
       "12                     -0.838322                     0.036101   \n",
       "13                     -0.837690                     0.036408   \n",
       "14                     -0.836293                     0.037487   \n",
       "15                     -0.842739                     0.035306   \n",
       "16                     -0.842336                     0.035348   \n",
       "17                     -0.841817                     0.035393   \n",
       "18                     -0.841097                     0.035425   \n",
       "19                     -0.839723                     0.035620   \n",
       "\n",
       "    rank_test_Adjusted R-squared  split0_train_Adjusted R-squared  \\\n",
       "0                              5                        -0.894580   \n",
       "1                              4                        -0.895082   \n",
       "2                              3                        -0.895785   \n",
       "3                              2                        -0.896905   \n",
       "4                              1                        -0.899348   \n",
       "5                             10                        -0.891086   \n",
       "6                              9                        -0.891354   \n",
       "7                              8                        -0.891755   \n",
       "8                              7                        -0.892461   \n",
       "9                              6                        -0.894326   \n",
       "10                            15                        -0.889444   \n",
       "11                            14                        -0.889575   \n",
       "12                            13                        -0.889750   \n",
       "13                            12                        -0.890040   \n",
       "14                            11                        -0.890872   \n",
       "15                            20                        -0.887641   \n",
       "16                            19                        -0.887872   \n",
       "17                            18                        -0.888156   \n",
       "18                            17                        -0.888537   \n",
       "19                            16                        -0.889184   \n",
       "\n",
       "    split1_train_Adjusted R-squared  split2_train_Adjusted R-squared  \\\n",
       "0                         -0.900298                        -0.897308   \n",
       "1                         -0.900721                        -0.897700   \n",
       "2                         -0.901345                        -0.898265   \n",
       "3                         -0.902402                        -0.899199   \n",
       "4                         -0.904956                        -0.901349   \n",
       "5                         -0.897988                        -0.894816   \n",
       "6                         -0.898139                        -0.894999   \n",
       "7                         -0.898361                        -0.895273   \n",
       "8                         -0.898769                        -0.895758   \n",
       "9                         -0.900082                        -0.897105   \n",
       "10                        -0.896674                        -0.893444   \n",
       "11                        -0.896807                        -0.893589   \n",
       "12                        -0.896984                        -0.893774   \n",
       "13                        -0.897253                        -0.894041   \n",
       "14                        -0.897829                        -0.894639   \n",
       "15                        -0.895216                        -0.891690   \n",
       "16                        -0.895370                        -0.891874   \n",
       "17                        -0.895559                        -0.892111   \n",
       "18                        -0.895840                        -0.892464   \n",
       "19                        -0.896426                        -0.893148   \n",
       "\n",
       "    split3_train_Adjusted R-squared  split4_train_Adjusted R-squared  \\\n",
       "0                         -0.897762                        -0.902489   \n",
       "1                         -0.898291                        -0.902889   \n",
       "2                         -0.899051                        -0.903467   \n",
       "3                         -0.900305                        -0.904426   \n",
       "4                         -0.903219                        -0.906691   \n",
       "5                         -0.894574                        -0.900053   \n",
       "6                         -0.894785                        -0.900226   \n",
       "7                         -0.895110                        -0.900483   \n",
       "8                         -0.895710                        -0.900943   \n",
       "9                         -0.897496                        -0.902283   \n",
       "10                        -0.893072                        -0.898759   \n",
       "11                        -0.893231                        -0.898897   \n",
       "12                        -0.893433                        -0.899068   \n",
       "13                        -0.893727                        -0.899315   \n",
       "14                        -0.894383                        -0.899888   \n",
       "15                        -0.891115                        -0.896691   \n",
       "16                        -0.891347                        -0.896963   \n",
       "17                        -0.891637                        -0.897295   \n",
       "18                        -0.892047                        -0.897739   \n",
       "19                        -0.892793                        -0.898493   \n",
       "\n",
       "    mean_train_Adjusted R-squared  std_train_Adjusted R-squared  \\\n",
       "0                       -0.898488                      0.002701   \n",
       "1                       -0.898937                      0.002669   \n",
       "2                       -0.899583                      0.002632   \n",
       "3                       -0.900647                      0.002592   \n",
       "4                       -0.903113                      0.002588   \n",
       "5                       -0.895704                      0.003083   \n",
       "6                       -0.895901                      0.003048   \n",
       "7                       -0.896196                      0.002994   \n",
       "8                       -0.896728                      0.002902   \n",
       "9                       -0.898258                      0.002717   \n",
       "10                      -0.894279                      0.003204   \n",
       "11                      -0.894420                      0.003204   \n",
       "12                      -0.894602                      0.003200   \n",
       "13                      -0.894875                      0.003186   \n",
       "14                      -0.895522                      0.003101   \n",
       "15                      -0.892471                      0.003197   \n",
       "16                      -0.892685                      0.003198   \n",
       "17                      -0.892952                      0.003197   \n",
       "18                      -0.893326                      0.003197   \n",
       "19                      -0.894009                      0.003208   \n",
       "\n",
       "    split0_test_Mape  split1_test_Mape  split2_test_Mape  split3_test_Mape  \\\n",
       "0         -10.888462        -12.648174        -10.958588        -12.007608   \n",
       "1         -10.930817        -12.676096        -10.961710        -12.018378   \n",
       "2         -10.984671        -12.711757        -10.973548        -12.036072   \n",
       "3         -11.065453        -12.778770        -11.005034        -12.067780   \n",
       "4         -11.205710        -12.947205        -11.078321        -12.207591   \n",
       "5         -10.606303        -12.415531        -10.981596        -11.987377   \n",
       "6         -10.628265        -12.435372        -10.982956        -11.983949   \n",
       "7         -10.658794        -12.463572        -10.981871        -11.980356   \n",
       "8         -10.714812        -12.512367        -10.977357        -11.977587   \n",
       "9         -10.869553        -12.627837        -10.958682        -12.003078   \n",
       "10        -10.406040        -12.252555        -10.886742        -12.011003   \n",
       "11        -10.430227        -12.262382        -10.901339        -12.015351   \n",
       "12        -10.461589        -12.278561        -10.919811        -12.017774   \n",
       "13        -10.504003        -12.310026        -10.942594        -12.016361   \n",
       "14        -10.589703        -12.385375        -10.975829        -11.988284   \n",
       "15        -10.215434        -12.134230        -10.814859        -11.840212   \n",
       "16        -10.224995        -12.153582        -10.820066        -11.866885   \n",
       "17        -10.241262        -12.176207        -10.825425        -11.900131   \n",
       "18        -10.269596        -12.202708        -10.830718        -11.941113   \n",
       "19        -10.362060        -12.235327        -10.870089        -11.997353   \n",
       "\n",
       "    split4_test_Mape  mean_test_Mape  std_test_Mape  rank_test_Mape  \\\n",
       "0         -12.127554      -11.726077       0.690122              16   \n",
       "1         -12.145872      -11.746574       0.689754              17   \n",
       "2         -12.186334      -11.778476       0.690181              18   \n",
       "3         -12.262275      -11.835862       0.694045              19   \n",
       "4         -12.521246      -11.992015       0.733765              20   \n",
       "5         -12.008709      -11.599903       0.685865              11   \n",
       "6         -12.021570      -11.610423       0.685194              12   \n",
       "7         -12.036462      -11.624211       0.684974              13   \n",
       "8         -12.059396      -11.648304       0.684924              14   \n",
       "9         -12.117465      -11.715323       0.687755              15   \n",
       "10        -11.799308      -11.471129       0.705084               6   \n",
       "11        -11.830274      -11.487915       0.701138               7   \n",
       "12        -11.868594      -11.509266       0.696361               8   \n",
       "13        -11.915484      -11.537693       0.691521               9   \n",
       "14        -11.998675      -11.587573       0.683526              10   \n",
       "15        -11.793485      -11.359644       0.724590               1   \n",
       "16        -11.798234      -11.372752       0.729068               2   \n",
       "17        -11.797802      -11.388165       0.732528               3   \n",
       "18        -11.786610      -11.406149       0.733255               4   \n",
       "19        -11.777668      -11.448500       0.713246               5   \n",
       "\n",
       "    split0_train_Mape  split1_train_Mape  split2_train_Mape  \\\n",
       "0          -10.237858          -9.547106         -10.145319   \n",
       "1          -10.217546          -9.524290         -10.129064   \n",
       "2          -10.189542          -9.490559         -10.106382   \n",
       "3          -10.147777          -9.440836         -10.071942   \n",
       "4          -10.093616          -9.333925          -9.997867   \n",
       "5          -10.393838          -9.670573         -10.265538   \n",
       "6          -10.380504          -9.663794         -10.255920   \n",
       "7          -10.362078          -9.652292         -10.241311   \n",
       "8          -10.331224          -9.629612         -10.217223   \n",
       "9          -10.248481          -9.558544         -10.154227   \n",
       "10         -10.458670          -9.713682         -10.290872   \n",
       "11         -10.454924          -9.711147         -10.291211   \n",
       "12         -10.450076          -9.706385         -10.291003   \n",
       "13         -10.440578          -9.697469         -10.289319   \n",
       "14         -10.403564          -9.677536         -10.273204   \n",
       "15         -10.512168          -9.757449         -10.328513   \n",
       "16         -10.505985          -9.754609         -10.323569   \n",
       "17         -10.498115          -9.749590         -10.316238   \n",
       "18         -10.484313          -9.741170         -10.306923   \n",
       "19         -10.463809          -9.722404         -10.290751   \n",
       "\n",
       "    split3_train_Mape  split4_train_Mape  mean_train_Mape  std_train_Mape  \n",
       "0          -10.009370          -9.999993        -9.987929        0.237557  \n",
       "1           -9.985047          -9.978091        -9.966808        0.238947  \n",
       "2           -9.951031          -9.947120        -9.936927        0.241693  \n",
       "3           -9.893877          -9.898389        -9.890564        0.245513  \n",
       "4           -9.778610          -9.779838        -9.796771        0.262069  \n",
       "5          -10.178883         -10.141452       -10.130057        0.245591  \n",
       "6          -10.167538         -10.130212       -10.119594        0.243649  \n",
       "7          -10.148910         -10.113441       -10.103606        0.241497  \n",
       "8          -10.115130         -10.084841       -10.075606        0.239146  \n",
       "9          -10.021519         -10.011098        -9.998773        0.237061  \n",
       "10         -10.210034         -10.200615       -10.174774        0.248432  \n",
       "11         -10.209188         -10.195639       -10.172422        0.248429  \n",
       "12         -10.208123         -10.189929       -10.169103        0.248945  \n",
       "13         -10.207693         -10.180311       -10.163074        0.249809  \n",
       "14         -10.186826         -10.151090       -10.138444        0.246328  \n",
       "15         -10.249917         -10.260341       -10.221678        0.250439  \n",
       "16         -10.245061         -10.250711       -10.215987        0.249236  \n",
       "17         -10.238063         -10.241480       -10.208697        0.248211  \n",
       "18         -10.229475         -10.229489       -10.198274        0.246785  \n",
       "19         -10.210914         -10.212372       -10.180050        0.246662  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator = poly_reg.named_steps[\"gridsearchcv\"]\n",
    "pd.DataFrame(estimator.cv_results_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When considering only the K-best features, there is a significant improvement (~10%) in the mape score ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.359644069994243"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-estimator.best_score_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matheus/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but ElasticNet was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 21 features, but ElasticNet is expecting 245 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m result \u001b[39m=\u001b[39m permutation_importance(\n\u001b[1;32m      2\u001b[0m     gridSearch\u001b[39m.\u001b[39;49mbest_estimator_,\n\u001b[1;32m      3\u001b[0m     X_Kbest,\n\u001b[1;32m      4\u001b[0m     y_train,\n\u001b[1;32m      5\u001b[0m     n_repeats\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m,\n\u001b[1;32m      6\u001b[0m     random_state\u001b[39m=\u001b[39;49m\u001b[39m42\u001b[39;49m,\n\u001b[1;32m      7\u001b[0m )\n",
      "File \u001b[0;32m~/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/inspection/_permutation_importance.py:257\u001b[0m, in \u001b[0;36mpermutation_importance\u001b[0;34m(estimator, X, y, scoring, n_repeats, n_jobs, random_state, sample_weight, max_samples)\u001b[0m\n\u001b[1;32m    254\u001b[0m     scorers_dict \u001b[39m=\u001b[39m _check_multimetric_scoring(estimator, scoring)\n\u001b[1;32m    255\u001b[0m     scorer \u001b[39m=\u001b[39m _MultimetricScorer(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mscorers_dict)\n\u001b[0;32m--> 257\u001b[0m baseline_score \u001b[39m=\u001b[39m _weights_scorer(scorer, estimator, X, y, sample_weight)\n\u001b[1;32m    259\u001b[0m scores \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs)(\n\u001b[1;32m    260\u001b[0m     delayed(_calculate_permutation_scores)(\n\u001b[1;32m    261\u001b[0m         estimator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[39mfor\u001b[39;00m col_idx \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(X\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m])\n\u001b[1;32m    272\u001b[0m )\n\u001b[1;32m    274\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(baseline_score, \u001b[39mdict\u001b[39m):\n",
      "File \u001b[0;32m~/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/inspection/_permutation_importance.py:19\u001b[0m, in \u001b[0;36m_weights_scorer\u001b[0;34m(scorer, estimator, X, y, sample_weight)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     18\u001b[0m     \u001b[39mreturn\u001b[39;00m scorer(estimator, X, y, sample_weight)\n\u001b[0;32m---> 19\u001b[0m \u001b[39mreturn\u001b[39;00m scorer(estimator, X, y)\n",
      "File \u001b[0;32m~/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py:429\u001b[0m, in \u001b[0;36m_passthrough_scorer\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_passthrough_scorer\u001b[39m(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    428\u001b[0m     \u001b[39m\"\"\"Function that wraps estimator.score\"\"\"\u001b[39;00m\n\u001b[0;32m--> 429\u001b[0m     \u001b[39mreturn\u001b[39;00m estimator\u001b[39m.\u001b[39;49mscore(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/base.py:720\u001b[0m, in \u001b[0;36mRegressorMixin.score\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[39m\"\"\"Return the coefficient of determination of the prediction.\u001b[39;00m\n\u001b[1;32m    679\u001b[0m \n\u001b[1;32m    680\u001b[0m \u001b[39mThe coefficient of determination :math:`R^2` is defined as\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    715\u001b[0m \u001b[39m:class:`~sklearn.multioutput.MultiOutputRegressor`).\u001b[39;00m\n\u001b[1;32m    716\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    718\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m r2_score\n\u001b[0;32m--> 720\u001b[0m y_pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict(X)\n\u001b[1;32m    721\u001b[0m \u001b[39mreturn\u001b[39;00m r2_score(y, y_pred, sample_weight\u001b[39m=\u001b[39msample_weight)\n",
      "File \u001b[0;32m~/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_base.py:386\u001b[0m, in \u001b[0;36mLinearModel.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[1;32m    373\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    374\u001b[0m \u001b[39m    Predict using the linear model.\u001b[39;00m\n\u001b[1;32m    375\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[39m        Returns predicted values.\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 386\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_decision_function(X)\n",
      "File \u001b[0;32m~/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:1127\u001b[0m, in \u001b[0;36mElasticNet._decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1125\u001b[0m     \u001b[39mreturn\u001b[39;00m safe_sparse_dot(X, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcoef_\u001b[39m.\u001b[39mT, dense_output\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintercept_\n\u001b[1;32m   1126\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1127\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m_decision_function(X)\n",
      "File \u001b[0;32m~/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/linear_model/_base.py:369\u001b[0m, in \u001b[0;36mLinearModel._decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_decision_function\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[1;32m    367\u001b[0m     check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[0;32m--> 369\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, accept_sparse\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcsc\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcoo\u001b[39;49m\u001b[39m\"\u001b[39;49m], reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    370\u001b[0m     \u001b[39mreturn\u001b[39;00m safe_sparse_dot(X, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcoef_\u001b[39m.\u001b[39mT, dense_output\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintercept_\n",
      "File \u001b[0;32m~/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/base.py:600\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    597\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[1;32m    599\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m--> 600\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_n_features(X, reset\u001b[39m=\u001b[39;49mreset)\n\u001b[1;32m    602\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/Desktop/ml_project/env/lib/python3.10/site-packages/sklearn/base.py:400\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    399\u001b[0m \u001b[39mif\u001b[39;00m n_features \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_:\n\u001b[0;32m--> 400\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    401\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX has \u001b[39m\u001b[39m{\u001b[39;00mn_features\u001b[39m}\u001b[39;00m\u001b[39m features, but \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    402\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mis expecting \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_\u001b[39m}\u001b[39;00m\u001b[39m features as input.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    403\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: X has 21 features, but ElasticNet is expecting 245 features as input."
     ]
    }
   ],
   "source": [
    "result = permutation_importance(\n",
    "    gridSearch.best_estimator_,\n",
    "    X_Kbest,\n",
    "    y_train,\n",
    "    n_repeats=100,\n",
    "    random_state=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_regressor = lgb.LGBMRegressor()\n",
    "\n",
    "# Define the parameter grid for the grid search\n",
    "param_grid = {\n",
    "    \"n_estimators\": [100, 200, 300],\n",
    "    \"learning_rate\": [0.1, 0.01, 0.001],\n",
    "    \"max_depth\": [3, 5, 7, 10, 15],\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "gbm_search = GridSearchCV(\n",
    "    estimator=lgb_regressor, param_grid=param_grid, cv=5, scoring=scoring, refit=\"Mape\"\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_search.fit(X_dummies, y_train)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "best_params = gbm_search.best_params_\n",
    "best_score = gbm_search.best_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39m-\u001b[39mbest_score\n",
      "\u001b[0;31mNameError\u001b[0m: name 'best_score' is not defined"
     ]
    }
   ],
   "source": [
    "-best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_search.fit(X_Kbest, y_train)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "Kbest_params = gbm_search.best_params_\n",
    "Kbest_score = gbm_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.974757085404292"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-Kbest_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
